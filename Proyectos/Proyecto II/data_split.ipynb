{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw dataset path\n",
    "#datasetPath = 'data/Crudo'\n",
    "datasetPath = 'data/crudo'\n",
    "\n",
    "# Training percentage\n",
    "trainPercentage = 0.8\n",
    "\n",
    "# Output paths\n",
    "rawOutputDir  = 'data/pp/raw'\n",
    "histOutputDir = 'data/pp/hist'\n",
    "bfOutputDir   = 'data/pp/bf'"
   ]
  },
  {
   "source": [
    "### Misc functions used to validate and save the split of the raw data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to validate the distribution of the split.\n",
    "def validateSplit(trainSet, testSet, classNames):\n",
    "    classAmount = len(classNames)\n",
    "\n",
    "    # Arrays to store the amount of samples of each class.\n",
    "    trainSetDist = np.array([0] * classAmount)\n",
    "    testSetDist  = np.array([0] * classAmount)\n",
    "\n",
    "    # Count the samples of each class in the training set.\n",
    "    for train in trainSet:\n",
    "        trainSetDist[train[1]] += 1\n",
    "\n",
    "    # Count the samples of each class in the testing set.\n",
    "    for test in testSet:\n",
    "        testSetDist[test[1]] += 1\n",
    "\n",
    "    # Make the distribution vector (percentages of each class).\n",
    "    trainSetProb = trainSetDist / len(trainSet) * 100\n",
    "    testSetProb  = testSetDist  / len(testSet)  * 100\n",
    "\n",
    "    # Print the data\n",
    "    print('Training set class distribution:')\n",
    "    for i in range(classAmount):\n",
    "        print('\\t{0}: {1} ({2:2.2f}%)'.format(classNames[i], trainSetDist[i], trainSetProb[i]))\n",
    "\n",
    "    print('Testing set class distribution:')\n",
    "    for i in range(classAmount):\n",
    "        print('\\t{0}: {1} ({2:2.2f}%)'.format(classNames[i], testSetDist[i], testSetProb[i]))\n",
    "\n",
    "# Function used to save a split based on a type (training or testing).\n",
    "def saveSplit(dataset, classNames, setType, path):\n",
    "    # Get the dir for each class.\n",
    "    dirs = [os.path.join(os.getcwd(), path, setType, className) for className in classNames]\n",
    "\n",
    "    # Make the dirs.\n",
    "    for _dir in dirs:\n",
    "        Path(_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Array for control the name of the files.\n",
    "    classCounter = [0, 0, 0, 0]\n",
    "\n",
    "    # For printing the progress.\n",
    "    samplesProcessed = 0\n",
    "    samplesStep = 25\n",
    "    step = len(dataset) // 4\n",
    "\n",
    "    # Each set can be iterated getting tuples of (PIL image, label).\n",
    "    for sample in dataset:\n",
    "        # Unpack the sample.\n",
    "        (image, label) = sample\n",
    "        # Save the image in the corresponding dir.\n",
    "        image.save(os.path.join(dirs[label], str(classCounter[label]) + '.png'))\n",
    "        # Increment the counter.\n",
    "        classCounter[label] += 1\n",
    "        \n",
    "        # Progress printing.\n",
    "        samplesProcessed += 1\n",
    "        if (samplesProcessed % step == 0):\n",
    "            print('\\t' + str(samplesStep) + '% saved.')\n",
    "            samplesStep += 25\n",
    "    \n",
    "    return dirs\n",
    "\n",
    "# Function used to save the splits.\n",
    "def saveTrainTestSplit(trainSet, testSet, classNames, path):\n",
    "    # Save the training set.\n",
    "    print('Saving training set')\n",
    "    rawTrainDir = saveSplit(trainSet, classNames, 'train', path)\n",
    "    print()\n",
    "\n",
    "    print('Saving testing set')\n",
    "    # Save the testing set.\n",
    "    rawTestDir = saveSplit(testSet,  classNames, 'test',  path)\n",
    "\n",
    "    return rawTrainDir, rawTestDir"
   ]
  },
  {
   "source": [
    "### Histograms and bilateral filter\n",
    "Functions used to create a version of the dataset based on histogramns an another one based on bilateral filter "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSaveHistogram(imgPath, outPath):\n",
    "    # Open the imagen.\n",
    "    img = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)\n",
    "    # Get the histogram.\n",
    "    histogram, _ = np.histogram(img.ravel(), 256, [0, 256])\n",
    "    # Normalize the histogram.\n",
    "    histogram = histogram / np.sum(histogram)\n",
    "\n",
    "    # Delete the .png extension.\n",
    "    outPath = outPath[:-4]\n",
    "\n",
    "    # Save the numpy\n",
    "    np.save(outPath, histogram)\n",
    "\n",
    "def createSaveBilateralFilter(imgPath, outPath):\n",
    "    img = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)\n",
    "    bilateralFilter = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "    \n",
    "    # Save the new imagen\n",
    "    cv2.imwrite(outPath, bilateralFilter)\n",
    "\n",
    "def makePreprocessing(inputDir, classNames, setType, path, preprocessingFunction):\n",
    "    # Get the dir for each class.\n",
    "    dirs = [os.path.join(os.getcwd(), path, setType, className) for className in classNames]\n",
    "\n",
    "    # Make the dirs.\n",
    "    for _dir in dirs:\n",
    "        Path(_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Process each folder.\n",
    "    for i in range(0, len(inputDir)):\n",
    "\n",
    "        # Get all files from directory \n",
    "        files = [f for f in os.listdir(inputDir[i]) if os.path.isfile(os.path.join(inputDir[i], f))]\n",
    "        print('\\tClass: ' + classNames[i])\n",
    "\n",
    "        # For progress printing.\n",
    "        samplesProcessed = 0\n",
    "        samplesStep = 25\n",
    "        step = len(files) // 4\n",
    "        print('\\t\\t', end='')\n",
    "\n",
    "        # Process all files in the dir.\n",
    "        for fileName in files:\n",
    "            # Create the in path\n",
    "            inPath = inputDir[i] + '/' + fileName\n",
    "\n",
    "            # Create the output path\n",
    "            outPath = dirs[i] + '/' + fileName\n",
    "\n",
    "            # Do the preprocessing.\n",
    "            preprocessingFunction(inPath, outPath)\n",
    "            \n",
    "            # Progress printing.\n",
    "            samplesProcessed += 1\n",
    "            if (samplesProcessed % step == 0 and samplesStep == 100):\n",
    "                print(str(samplesStep) + '% saved.')\n",
    "            elif (samplesProcessed % step == 0):\n",
    "                print(str(samplesStep) + '% saved, ', end='')\n",
    "                samplesStep += 25"
   ]
  },
  {
   "source": [
    "### Split data\n",
    "Function to get the raw data and separate them in a training/testing set and save them. In order to maintain the same sets for all the experiments."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSplits(datasetPath, trainPercentage):\n",
    "    print('/* Making the split *\\\\')\n",
    "\n",
    "    # Get the raw dataset.\n",
    "    dataset = ImageFolder(datasetPath)\n",
    "    classNames = dataset.classes\n",
    "\n",
    "    # Get the size of the training set and the testing set.\n",
    "    trainLen = int(len(dataset) * trainPercentage)\n",
    "    testLen  = len(dataset) - trainLen\n",
    "\n",
    "    print('Len of the dataset:', len(dataset))\n",
    "    print('\\tTraining set: {0} ({1:2.2f}%)'.format(trainLen, trainLen / len(dataset) * 100))\n",
    "    print('\\tTesting set: {0} ({1:2.2f}%)'.format(testLen,  testLen  / len(dataset) * 100))\n",
    "    print()\n",
    "\n",
    "    # Random split the general dataset.\n",
    "    trainSet, testSet = random_split(dataset, [trainLen, testLen])\n",
    "\n",
    "    # For the raw dataset.\n",
    "    # Validate the raw splits.\n",
    "    validateSplit(trainSet, testSet, classNames)\n",
    "    print()\n",
    "\n",
    "    # Save the raw splits.\n",
    "    print('/* Saving the raw splits *\\\\')\n",
    "    (rawTrainDir, rawTestDir) = saveTrainTestSplit(trainSet, testSet, classNames, rawOutputDir)\n",
    "    print()\n",
    "\n",
    "    # For the histograms. createSaveBilateralFilter\n",
    "    print('/* Making and saving the histograms *\\\\')\n",
    "    print('Histograms for training')\n",
    "    makePreprocessing(rawTrainDir, classNames, 'train', histOutputDir, createSaveHistogram)\n",
    "    print('Histograms for testing')\n",
    "    makePreprocessing(rawTestDir,  classNames, 'test',  histOutputDir, createSaveHistogram)\n",
    "    print()\n",
    "\n",
    "    # For the histograms. \n",
    "    print('/* Making and saving the bilateral filter images *\\\\')\n",
    "    print('BF images for training')\n",
    "    makePreprocessing(rawTrainDir, classNames, 'train', bfOutputDir, createSaveBilateralFilter)\n",
    "    print('BF images for testing')\n",
    "    makePreprocessing(rawTestDir,  classNames, 'test',  bfOutputDir, createSaveBilateralFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/* Making the split *\\\n",
      "Len of the dataset: 21165\n",
      "\tTraining set: 16932 (80.00%)\n",
      "\tTesting set: 4233 (20.00%)\n",
      "\n",
      "Training set class distribution:\n",
      "\tCOVID: 2917 (17.23%)\n",
      "\tLung_Opacity: 4831 (28.53%)\n",
      "\tNormal: 8111 (47.90%)\n",
      "\tViral Pneumonia: 1073 (6.34%)\n",
      "Testing set class distribution:\n",
      "\tCOVID: 699 (16.51%)\n",
      "\tLung_Opacity: 1181 (27.90%)\n",
      "\tNormal: 2081 (49.16%)\n",
      "\tViral Pneumonia: 272 (6.43%)\n",
      "\n",
      "/* Saving the raw splits *\\\n",
      "Saving training set\n",
      "\t25% saved.\n",
      "\t50% saved.\n",
      "\t75% saved.\n",
      "\t100% saved.\n",
      "\n",
      "Saving testing set\n",
      "\t25% saved.\n",
      "\t50% saved.\n",
      "\t75% saved.\n",
      "\t100% saved.\n",
      "\n",
      "/* Making and saving the histograms *\\\n",
      "Histograms for training\n",
      "\tClass: COVID\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Lung_Opacity\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Normal\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Viral Pneumonia\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "Histograms for testing\n",
      "\tClass: COVID\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Lung_Opacity\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Normal\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Viral Pneumonia\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\n",
      "/* Making and saving the bilateral filter images *\\\n",
      "BF images for training\n",
      "\tClass: COVID\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Lung_Opacity\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Normal\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Viral Pneumonia\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "BF images for testing\n",
      "\tClass: COVID\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Lung_Opacity\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Normal\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n",
      "\tClass: Viral Pneumonia\n",
      "\t\t25% saved, 50% saved, 75% saved, 100% saved.\n"
     ]
    }
   ],
   "source": [
    "createSplits(datasetPath, trainPercentage)"
   ]
  }
 ]
}