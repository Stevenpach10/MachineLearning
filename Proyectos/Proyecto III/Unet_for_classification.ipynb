{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_for_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mGqKD9Z0qAQU"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa9c6a9953334ebd8ebeeb816c5a6d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9719f3ee58214d1da7f390ab6e01960d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3a5303781df451b9b21013a859b9f73",
              "IPY_MODEL_b60d1dcbd83f4287a0b34781f6ed8a30"
            ]
          }
        },
        "9719f3ee58214d1da7f390ab6e01960d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3a5303781df451b9b21013a859b9f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9afb82d143624e5d8651c4a6298dc85e",
            "_dom_classes": [],
            "description": " 20%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c51043f03444fdeb6cc0f6573707b77"
          }
        },
        "b60d1dcbd83f4287a0b34781f6ed8a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8962ce499376424584cb227f29c1c90e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/5 [01:23&lt;03:27, 51.95s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de8c8c8c8b604828985d04fa8910b407"
          }
        },
        "9afb82d143624e5d8651c4a6298dc85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c51043f03444fdeb6cc0f6573707b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8962ce499376424584cb227f29c1c90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de8c8c8c8b604828985d04fa8910b407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56035a28b4254d6d909fa62f8c7fa15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d0cd50b3afc4d1e9cb1718aeee109ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0919e8dde674e09afb736fde8ceda83",
              "IPY_MODEL_afc7d2f5dad04747b3337924f58bad98"
            ]
          }
        },
        "4d0cd50b3afc4d1e9cb1718aeee109ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0919e8dde674e09afb736fde8ceda83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_964cac9e03884541b7b07c1fdaa94ccd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 49,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_742582ad64fa4dfeac19620413871300"
          }
        },
        "afc7d2f5dad04747b3337924f58bad98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4deec9e6b2e41f5817e25c2c814206a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49/49 [00:19&lt;00:00,  3.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5cb95ee8dd740a780857cdb443c9deb"
          }
        },
        "964cac9e03884541b7b07c1fdaa94ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "742582ad64fa4dfeac19620413871300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4deec9e6b2e41f5817e25c2c814206a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5cb95ee8dd740a780857cdb443c9deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b92d41c4c994f318464e73bd9f02df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01a9a69168db4ce5aa031771b71d3160",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f665079e25a74156b19e40a1ef3c2735",
              "IPY_MODEL_a915632adddc49f69d8a1ed61a7d0bca"
            ]
          }
        },
        "01a9a69168db4ce5aa031771b71d3160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f665079e25a74156b19e40a1ef3c2735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_383dc032a1444f91ab806b354e4858bd",
            "_dom_classes": [],
            "description": " 29%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 49,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f76880133be434c93da9be1134b60a1"
          }
        },
        "a915632adddc49f69d8a1ed61a7d0bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c176d1a371c493e9a9435c600ac978e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14/49 [00:06&lt;00:12,  2.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf0d58c906cb44799bda987c4f0eec48"
          }
        },
        "383dc032a1444f91ab806b354e4858bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f76880133be434c93da9be1134b60a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c176d1a371c493e9a9435c600ac978e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf0d58c906cb44799bda987c4f0eec48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "metadata": {
      "interpreter": {
        "hash": "1119e6db3b611a071a02fedbd618e93718260f90f2b64402566f1a15d771d1ec"
      }
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy2Af0yugdk0"
      },
      "source": [
        "# Is in Colab, this is the config enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w00CT-mPA2rs"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  import os\n",
        "\n",
        "  if ((not os.path.isdir('./corrida1')) and (not os.path.isdir('./corrida2'))):\n",
        "    \n",
        "    !pip install googledrivedownloader\n",
        "    !pip install wandb\n",
        "\n",
        "    os.environ[\"WANDB_API_KEY\"] = \"cd30e32b876086a7c69da7467b0570a036bb6a0d\"\n",
        "\n",
        "    import shutil  \n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    \n",
        "    gdd.download_file_from_google_drive(file_id='1jTG-5XSui9vWlhqE9jzswUDU9vhzburs',\n",
        "                                      dest_path='./corrida2.zip',\n",
        "                                      unzip=True)\n",
        "\n",
        "    gdd.download_file_from_google_drive(file_id='1gBR-TiZIeXu6yM_cI0_iWSdzDpyXNpgw',\n",
        "                                  dest_path='./corrida1.zip',\n",
        "                                  unzip=True)\n",
        "\n",
        "    os.remove('./corrida1.zip')\n",
        "    os.remove('./corrida2.zip')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('Not running on CoLab')"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFC45biMuQdl"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVwha_Y5g4Zl"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or1HS_RH4dbg"
      },
      "source": [
        "# General import of torch.\n",
        "import torch\n",
        "# Import for graph blocks of torch.\n",
        "import torch.nn as nn\n",
        "# Import the models library, to get the model to be used.\n",
        "import torchvision.models as models\n",
        "# Import optim library, to get the optimizer to be used.\n",
        "import torch.optim as optim\n",
        "# Import torchvision, to manage the input data.\n",
        "import torchvision\n",
        "# To apply transformations to the data (when loaded).\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "# To calculate softmax.\n",
        "from torch.nn import Softmax\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# Metrics zero_division\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# General imports.\n",
        "import os\n",
        "import time\n",
        "import wandb\n",
        "import random\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from numpy import float32\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mYN6YQmg8u1"
      },
      "source": [
        "# Enviroment configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUp22wqXUkPX"
      },
      "source": [
        "## Config variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tciCMzP5UkWU"
      },
      "source": [
        "softmax = Softmax(dim=1)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m4sLOE_hFOW"
      },
      "source": [
        "## Config for metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eAy1MX7g_EJ"
      },
      "source": [
        "# Input size of the model.\n",
        "inputSize = 'inputSize'\n",
        "# Output size of the model.\n",
        "outputSize = 'outputSize'\n",
        "# Batch size.\n",
        "batchSize = 'batchSize'\n",
        "# Learning rate.\n",
        "learningRate = 'learningRate'\n",
        "# Class names.\n",
        "classes = 'classes'\n",
        "# Class IDs.\n",
        "classesID = 'classesIDs'\n",
        "# Class IDs.\n",
        "classesIDs = 'classesIDs'\n",
        "# Number of classes to classify.\n",
        "classesLen = 'classesLen'\n",
        "# Device to be used, prefer cuda, if available.\n",
        "device = 'device'\n",
        "# Group type, for wandb.\n",
        "groupType = 'groupType'\n",
        "# Config run.\n",
        "configRun = 'configRun'\n",
        "\n",
        "config = {\n",
        "    inputSize    : 224,\n",
        "    outputSize   : 39,\n",
        "    batchSize    : 128,\n",
        "    learningRate : 0.001,\n",
        "    classes : [\n",
        "        'Apple - Apple scab',\n",
        "        'Apple - Black rot',\n",
        "        'Apple - Cedar apple rust',\n",
        "        'Apple - Healthy',\n",
        "        'Background without leaves',\n",
        "        'Blueberry - Healthy',\n",
        "        'Cherry - Healthy',\n",
        "        'Cherry - Powdery mildew',\n",
        "        'Corn - Cercospora',\n",
        "        'Corn - Common rust',\n",
        "        'Corn - Healthy',\n",
        "        'Corn - Northern Leaf Blight',\n",
        "        'Grape - Black rot',\n",
        "        'Grape - Esca',\n",
        "        'Grape - Healthy',\n",
        "        'Grape - Leaf blight',\n",
        "        'Orange - Haunglongbing',\n",
        "        'Peach - Bacterial spot',\n",
        "        'Peach - Healthy',\n",
        "        'Pepper bell - Bacterial spot',\n",
        "        'Pepper bell - healthy',\n",
        "        'Potato - Early blight',\n",
        "        'Potato - Healthy',\n",
        "        'Potato - Late blight',\n",
        "        'Raspberry - healthy',\n",
        "        'Soybean - Healthy',\n",
        "        'Squash - Powdery mildew',\n",
        "        'Strawberry - Healthy',\n",
        "        'Strawberry - Leaf scorch',\n",
        "        'Tomato - Bacterial spot',\n",
        "        'Tomato - Early blight',\n",
        "        'Tomato - Healthy',\n",
        "        'Tomato - Late blight',\n",
        "        'Tomato - Leaf Mold',\n",
        "        'Tomato - Septoria leaf spot',\n",
        "        'Tomato - Spider mites',\n",
        "        'Tomato - Target Spot',\n",
        "        'Tomato - Mosaic virus',\n",
        "        'Tomato - Yellow Leaf Curl Virus'\n",
        "    ],\n",
        "    classesID : [i + 1 for i in range(39)],\n",
        "    classesLen : 39,\n",
        "    device : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# Wandb enviroment variables\n",
        "os.environ['WANDB_SILENT'] = 'true'"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omp8rUKfh3m6"
      },
      "source": [
        "## Executions config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajwIch28h64e"
      },
      "source": [
        "exe_load_check_point = \"load_check_point\"\n",
        "exe_freeze_check_point = \"freeze_check_point\"\n",
        "exe_check_point_path = \"check_point_path\"\n",
        "exe_can_epochs = \"can_epochs\"\n",
        "exe_save_check_point_path = \"save_check_point_path\"\n",
        "exe_execution_name = \"execution_name\"\n",
        "exe_data_path = \"data_path\"\n",
        "exe_group_type = \"groupType\"\n",
        "\n",
        "\n",
        "# config_freeze = {\n",
        "#     exe_load_check_point: True,\n",
        "#     exe_freeze_check_point: True,\n",
        "#     exe_check_point_path: \"./\"\n",
        "#     exe_can_epochs: 1,\n",
        "#     exe_save_check_point_path: \"./\",\n",
        "#     exe_execution_name: \"name1\",\n",
        "#     exe_data_path: \"./\"\n",
        "# }\n",
        "\n",
        "# config_unfreeze = {\n",
        "#     exe_load_check_point: True,\n",
        "#     exe_freeze_check_point: False,\n",
        "#     exe_check_point_path: \"./\"\n",
        "#     exe_can_epochs: 1,\n",
        "#     exe_save_check_point_path: \"./\",\n",
        "#     exe_execution_name: \"name2\",\n",
        "#     exe_data_path: \"./\"\n",
        "# }\n",
        "\n",
        "config_no_load = {\n",
        "    exe_load_check_point: False,\n",
        "    exe_freeze_check_point: False,\n",
        "    exe_check_point_path: \"\",\n",
        "    exe_can_epochs: 10,\n",
        "    exe_save_check_point_path: \"/content/corridaTest\",\n",
        "    exe_execution_name: \"corridaTest\",\n",
        "    exe_data_path: \"/content/corrida1\",\n",
        "    exe_group_type: \"Corrida 1\"\n",
        "}\n",
        "\n",
        "# executions_configs = [config_freeze,\n",
        "#                       config_unfreeze,\n",
        "#                       config_no_load]\n",
        "\n",
        "executions_configs = [config_no_load]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGqKD9Z0qAQU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdpSI7TmqOks"
      },
      "source": [
        "## Unet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kWMfK0zqD5z"
      },
      "source": [
        "def kernel_size(initial_value, iterations, division_value=2):\n",
        "  for i in range(iterations):\n",
        "    initial_value//=division_value\n",
        "  return initial_value"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk4_rKYGqBcW"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__ (self, in_channels, out_channels):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        #Here we add Batch Normalization to improve the paper's model\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCvjViNQqJHx"
      },
      "source": [
        "class UNET(nn.Module):\n",
        "  #features represent the original paper dimensions.\n",
        "  def __init__(self, \n",
        "               in_channels=3, \n",
        "               out_channels=1, \n",
        "               features=[16, 32, 64, 128, 256, 512], \n",
        "               linearFeature=1024,\n",
        "               isOnlyEncoder=False):\n",
        "    \n",
        "    super(UNET, self).__init__()\n",
        "    \n",
        "    self.linearFeature = linearFeature\n",
        "    self.isOnlyEncoder = isOnlyEncoder\n",
        "    #Encoder part\n",
        "    self.downs = nn.ModuleList()\n",
        "    #Decoder part\n",
        "    self.ups = nn.ModuleList()\n",
        "    #Pool\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    self.features = features\n",
        "    self.kernelHeight = kernel_size(config[inputSize], len(self.features))\n",
        "    self.kernelWidth = kernel_size(config[inputSize], len(self.features))\n",
        "    self.kernelSize = self.kernelHeight * self.kernelWidth\n",
        "\n",
        "   #Create a list of contracting path\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channels, feature))\n",
        "      in_channels = feature\n",
        "\n",
        "   #Create a list of expansive path\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(\n",
        "         #Featur2 * 2 is to create the 1024 dim\n",
        "         nn.ConvTranspose2d(feature *2, feature, kernel_size=2, stride=2,)\n",
        "     )\n",
        "      self.ups.append(DoubleConv(feature * 2, feature))\n",
        "  \n",
        "    self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "\n",
        "    self.linear1 = nn.Linear(self.features[-1]*2*self.kernelSize,  self.linearFeature)\n",
        "    self.linear2 = nn.Linear(self.linearFeature, features[-1]*2*self.kernelSize)\n",
        "\n",
        "    self.final_conv = nn.Conv2d(self.features[0], out_channels, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "   \n",
        "    #For save the connections with the up part\n",
        "    skip_connections = []\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x)\n",
        "      x = self.pool(x)\n",
        "    #Here is the bottom part of the net\n",
        "    x = self.bottleneck(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = self.linear1(x)\n",
        "    #Check if we are using only de encoder part\n",
        "    if self.isOnlyEncoder:\n",
        "      return x\n",
        "    x = self.linear2(x)\n",
        "    x = x.reshape((x.shape[0], self.features[-1] *2 , self.kernelHeight, self.kernelWidth))\n",
        "    #Start the up part\n",
        "    #Reverse list\n",
        "    skip_connections = skip_connections[:: -1]\n",
        "\n",
        "    #Step of two because we use up and doubleconv\n",
        "    #0 is the up\n",
        "    #1 is the double conv\n",
        "    for idx in range (0, len(self.ups), 2):\n",
        "      x = self.ups[idx](x)\n",
        "      #Divide idx by 2 for going liner with the skip connections\n",
        "      skip_connection = skip_connections[idx//2]\n",
        "\n",
        "      #General solutions for image tha not are divisibles\n",
        "      if x.shape != skip_connection.shape:\n",
        "        #Take the H and W, skip the Batch Size and Channels\n",
        "        x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "      #Add the skip connection\n",
        "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "      # (e.g 0 +1 for the doubleconv)\n",
        "      x = self.ups[idx+1](concat_skip)\n",
        "    \n",
        "    return self.final_conv(x)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDFuluIKqQGF"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0INWEWsqJhb"
      },
      "source": [
        "class ClassifierUnet(nn.Module):\n",
        "  #features represent the original paper dimensions.\n",
        "  def __init__(self, \n",
        "               out_channels=1, \n",
        "               linear=[1024, 250, 150, 100, 50], \n",
        "               unetModel=None):\n",
        "    \n",
        "    super(ClassifierUnet, self).__init__()\n",
        "\n",
        "    self.unetModel = unetModel\n",
        "    self.linear_layers = nn.Sequential()\n",
        "\n",
        "    #Create a list of linear classificator\n",
        "    actual_linear = self.unetModel.linearFeature\n",
        "\n",
        "    for i in range(len(linear)):\n",
        "      self.linear_layers.add_module(str(i)+\"_linear\", nn.Linear(actual_linear, linear[i]))\n",
        "      self.linear_layers.add_module(str(i)+\"_activ\", nn.ReLU())\n",
        "      \n",
        "      actual_linear = linear[i]\n",
        "    \n",
        "    self.linear_layers.add_module(str(i+1)+\"_linear\", nn.Linear(actual_linear, out_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.unetModel(x)\n",
        "      return self.linear_layers(x)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SG1SbNAlpe-"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66oE9CfDluYr"
      },
      "source": [
        "## Miscellaneous functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQYEqtJ6ltlQ"
      },
      "source": [
        "# About metrics.\n",
        "# Metric dictionary keys.\n",
        "# For preprocessing.\n",
        "_loss        = 'Loss'\n",
        "_groundtruth = 'Groundtruth'\n",
        "_logits      = 'Logits'\n",
        "# For postprocessing.\n",
        "_probabilities   = 'Probabilities'\n",
        "_predictions     = 'Predictions'\n",
        "_confusionMatrix = 'Confusion matrix'\n",
        "_accuracyClass   = 'Accuracy class'\n",
        "_accuracy        = 'Accuracy'\n",
        "_recall          = 'Recall'\n",
        "_precision       = 'Precision'\n",
        "_f1              = 'F1'\n",
        "_auc             = 'AUC'\n",
        "# For torch save\n",
        "_model           = 'Model State Dic'\n",
        "_optimizer       = 'Optimizer State Dic'\n",
        "_criterion       = 'Criterion'\n",
        "_epoch           = 'Epoch'\n",
        "_runID           = 'RunID'\n",
        "_metricsTrain    = 'Resulting metrics (training)'\n",
        "_metricsTest     = 'Resulting metrics (testing)'\n",
        "\n",
        "_metricsPrint = [_accuracy, _recall, _precision, _f1, _auc]\n",
        "\n",
        "# Get a clean dictionary for the metrics.\n",
        "def getMetricsDict():\n",
        "    return {\n",
        "        _loss          : torch.tensor(0.),\n",
        "        _groundtruth   : torch.tensor([]),\n",
        "        _logits        : torch.tensor([])\n",
        "    }\n",
        "\n",
        "# Function used to update the dictionary of resulting metrics.\n",
        "def updateRunningMetrics(logits, groundtruth, loss, batchAmount, metricsResults):\n",
        "    # Accumulate the loss.\n",
        "    metricsResults[_loss] += loss.cpu() / batchAmount\n",
        "    # Accumulate the groundtruth and the logits.\n",
        "    metricsResults[_groundtruth] = torch.cat((metricsResults[_groundtruth], groundtruth.cpu())) \n",
        "    metricsResults[_logits] = torch.cat((metricsResults[_logits], logits.cpu()))\n",
        "\n",
        "# Function used to process the dictionary of resulting metrics (make final calculations).\n",
        "def processRunningMetrics(metricsResults):\n",
        "    # Detach the other values in the dictionary.\n",
        "    metricsResults[_loss] = metricsResults[_loss].detach()\n",
        "    metricsResults[_groundtruth] = metricsResults[_groundtruth].detach()\n",
        "    metricsResults[_logits] = metricsResults[_logits].detach()\n",
        "    # Save in the dictionary the probabilities and the predictions.\n",
        "    metricsResults[_probabilities] = softmax(metricsResults[_logits]).detach()\n",
        "    metricsResults[_predictions] = torch.argmax(metricsResults[_probabilities], axis=1).detach()\n",
        "\n",
        "    # Get Groundtruth (as numpy).\n",
        "    groundtruth = metricsResults[_groundtruth].detach().numpy()\n",
        "    # Get probabilities (as numpy).\n",
        "    probs = metricsResults[_probabilities].detach().numpy()\n",
        "    # Get predictions (as numpy).\n",
        "    preds = metricsResults[_predictions].detach().numpy()\n",
        "\n",
        "    # Calculate confusion matrix (normalized).\n",
        "    confusionMatrix = confusion_matrix(groundtruth, preds)\n",
        "    metricsResults[_confusionMatrix] = torch.tensor(confusionMatrix)\n",
        "\n",
        "    # Calculate accuracy by class.\n",
        "    confusionMatrix = confusionMatrix.astype('float') / confusionMatrix.sum(axis=1)[:, np.newaxis]\n",
        "    metricsResults[_accuracyClass] = torch.tensor(confusionMatrix.diagonal())\n",
        "\n",
        "    # Calculate accuracy.\n",
        "    metricsResults[_accuracy] = torch.tensor(accuracy_score(groundtruth, preds))\n",
        "    # Calculate recall.\n",
        "    metricsResults[_recall] = torch.tensor(recall_score(groundtruth, preds, average='macro', zero_division=0))\n",
        "    # Calculate precision.\n",
        "    metricsResults[_precision] = torch.tensor(precision_score(groundtruth, preds, average='macro', zero_division=0))\n",
        "    # Calculate F1.\n",
        "    metricsResults[_f1] = torch.tensor(f1_score(groundtruth, preds, average='macro', zero_division=0))\n",
        "    # Calculate AUC.\n",
        "    metricsResults[_auc] = torch.tensor(roc_auc_score(groundtruth, probs, multi_class='ovr'))\n",
        "\n",
        "# Pretty print the metrics dictionaries.\n",
        "def printMetricsDict(metricsResults):\n",
        "    # All metrics to print\n",
        "    metricPrints = []\n",
        "\n",
        "    # Format the loss.\n",
        "    lossPrint = 'Loss: {:.4f}'.format(metricsResults[_loss])\n",
        "    metricPrints.append(lossPrint)\n",
        "\n",
        "    # Format the the remaining metrics.\n",
        "    baseMetricString = '{}: {:1.4f}'\n",
        "    for metric in _metricsPrint:\n",
        "        metricPrints.append(baseMetricString.format(metric, metricsResults[metric]))\n",
        "\n",
        "    print(', '.join(metricPrints))\n",
        "\n",
        "# This functions process an metrics result dictionary for wandb. Is necessary to indicte\n",
        "#   the metrics origin, training or testing.\n",
        "def processMetricsWandb(metricsResults, training=False):\n",
        "    # Get the prefix to log on wandb, the keys must be different.\n",
        "    resultsType = 'training' if training else 'testing'\n",
        "\n",
        "    # Confusion matrix as a heat map.\n",
        "    _confusionMatrixHM = 'Confusion matrix (heat map)'\n",
        "\n",
        "    # All the wandb keys are based in the original metrics results keys.\n",
        "    lossKey = '{} ({})'.format(_loss, resultsType)\n",
        "    metricsKeys = ['{} ({})'.format(_metric, resultsType) for _metric in _metricsPrint]\n",
        "    accuracyClassKeys = ['{} accuracy ({})'.format(_class, resultsType) for _class in config[classes]]\n",
        "    confusionMatrixKey = '{} ({})'.format(_confusionMatrix, resultsType)\n",
        "    confusionMatrixHMKey = '{} ({})'.format(_confusionMatrixHM, resultsType)\n",
        "\n",
        "    # Get the confusion matrix for wandb.\n",
        "    data = []\n",
        "    for i in range(config[classesLen]):\n",
        "        for j in range(config[classesLen]):\n",
        "            data.append([config[classes][i], config[classesID][i], config[classes][j], config[classesID][j], metricsResults[_confusionMatrix][i, j].item()])\n",
        "\n",
        "    confusionMatrix = wandb.Table(columns=[\"Actual\", \"Actual (id)\", \"Predicted\", \"Predicted (id)\", \"nPredictions\"], data=data)\n",
        "\n",
        "    confusionMatrixHM = wandb.plots.HeatMap(config[classes], config[classes], metricsResults[_confusionMatrix].numpy(), show_text=False)\n",
        "\n",
        "    # Make the dictionary for wandb and store the values.\n",
        "    wandbDict = {\n",
        "        lossKey              : metricsResults[_loss].item(),\n",
        "        confusionMatrixKey   : confusionMatrix,\n",
        "        confusionMatrixHMKey : confusionMatrixHM\n",
        "    }\n",
        "    for i in range(len(metricsKeys)):\n",
        "        wandbDict[metricsKeys[i]] = metricsResults[_metricsPrint[i]].item()\n",
        "    for i in range(config[classesLen]):\n",
        "        wandbDict[accuracyClassKeys[i]] = metricsResults[_accuracyClass][i].item()\n",
        "\n",
        "    # Return, to log later.\n",
        "    return wandbDict\n",
        "\n",
        "# Get the metrics dictionaries for wandb and log them.\n",
        "def logMetricsWandb(trainMetricsResults, testMetricsResults):\n",
        "    # Get both dictionaries for wandb.\n",
        "    wandbTrainDict = processMetricsWandb(trainMetricsResults, training=True)\n",
        "    wandbTestDict  = processMetricsWandb(testMetricsResults, training=False)\n",
        "\n",
        "    # Merge the dictionaries.\n",
        "    wandbDict = {**wandbTrainDict, **wandbTestDict}\n",
        "\n",
        "    # Log on wandb\n",
        "    wandb.log(wandbDict)\n",
        "\n",
        "# Function used to save the model and the metrics.\n",
        "def saveEpochData(trainMetricsResults, testMetricsResults, model, optimizer, criterion, epoch, rootPath, runID):\n",
        "    # Create a dir for the current epoch.\n",
        "    runDir = os.path.join(os.getcwd(), rootPath, str(epoch))\n",
        "    Path(runDir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Path\n",
        "    savePath = os.path.join(runDir, 'model.pth')\n",
        "\n",
        "    # Make dict for torch.save\n",
        "    saveDict = {\n",
        "        _model     : model.state_dict(),\n",
        "        _optimizer : optimizer.state_dict(),\n",
        "        _criterion : criterion,\n",
        "        _epoch     : epoch,\n",
        "        _runID     : runID\n",
        "    }\n",
        "\n",
        "    # Save both metrics, for train and test.\n",
        "    metricsResults = {\n",
        "        _metricsTrain : trainMetricsResults,\n",
        "        _metricsTest  : testMetricsResults\n",
        "    }\n",
        "\n",
        "    # Merge the save dict with the metricsResults dict.\n",
        "    saveDict = {**metricsResults, **saveDict}\n",
        "\n",
        "    # Save\n",
        "    torch.save(saveDict, savePath)\n",
        "\n",
        "    for directory in os.listdir(os.path.join(os.getcwd(), rootPath)):\n",
        "      if os.path.join(os.getcwd(), rootPath, directory) != runDir:\n",
        "        shutil.rmtree(os.path.join(os.getcwd(), rootPath, directory))\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-TRE2_emWX8"
      },
      "source": [
        "## Loader function.\n",
        "Should return the training loader and test loader, a iterable object by batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5lvHxddmWf_"
      },
      "source": [
        "# Transformation definitions.\n",
        "transformTrain = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(config[inputSize]),  # This one does a resize (it cuts randomly, it doesn't keep the whole image).\n",
        "        transforms.RandomHorizontalFlip(),                # Flip the image horizontally randomly.\n",
        "        transforms.ToTensor(),                            # Make the image a tensor.\n",
        "        transforms.Normalize(\n",
        "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Expected normalization for pretrained pytorch models.\n",
        "    ])\n",
        "transformTest = transforms.Compose([\n",
        "        transforms.Resize(config[inputSize]),             # Resize the image, keeping all pixels.\n",
        "        transforms.CenterCrop(config[inputSize]),         # Cut the image in the center.\n",
        "        transforms.ToTensor(),                            # Make the image a tensor.\n",
        "        transforms.Normalize(\n",
        "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Expected normalization for pretrained pytorch models.\n",
        "    ])\n",
        "\n",
        "# Function used to get the data loaders.\n",
        "# A folder with two folders inside called train and test is expected as a rootPath.\n",
        "def getLoaders(rootPath):\n",
        "    trainPath = os.path.join(rootPath, 'labelTrain')\n",
        "    testPath  = os.path.join(rootPath, 'labelTest')\n",
        "\n",
        "    # Get the training and test data, apply the transformations.\n",
        "    trainset = torchvision.datasets.ImageFolder(root=trainPath, transform=transformTrain)\n",
        "    testset  = torchvision.datasets.ImageFolder(root=testPath,  transform=transformTest)\n",
        "\n",
        "    # Get the loaders, to iterate the data through batches.\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=config[batchSize], shuffle=True, num_workers=2)\n",
        "    testloader  = torch.utils.data.DataLoader(testset,  batch_size=config[batchSize], shuffle=True, num_workers=2)\n",
        "    \n",
        "    return trainloader, testloader"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTz2fA6Pmm_3"
      },
      "source": [
        "## Training method.\n",
        "This method takes care of a single training pass. Another function call this one multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJJC1B2Cmngr"
      },
      "source": [
        "def trainEpoch(dataloader, model, criterion, optimizer):\n",
        "    # Metrics for training.\n",
        "    metricsResults = getMetricsDict()\n",
        "\n",
        "    # Enable the grad, for training.\n",
        "    with torch.set_grad_enabled(True):\n",
        "\n",
        "        # Indicate that the model is going to be trained.\n",
        "        model.train()\n",
        "\n",
        "        # Loader len, for metrics calculation.\n",
        "        loaderLen = len(dataloader)\n",
        "\n",
        "        # Iterate the batches for training.\n",
        "        for batch in dataloader:\n",
        "            # Train the model.\n",
        "            # Get the inputs and labels, and move them to the selected device.\n",
        "            inputs, labels = batch[0].to(config[device]), batch[1].to(config[device])\n",
        "            # Zero the gradient parameters.\n",
        "            optimizer.zero_grad()\n",
        "            # Get the predictions.\n",
        "            outputs = model(inputs)\n",
        "            # Calculate the error.\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Calculates the derivatives of the parameters that have a gradient.\n",
        "            loss.backward()\n",
        "            # Update the parameters based on the computer gradient.\n",
        "            optimizer.step()\n",
        "            # Metrics for the training set.\n",
        "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults)\n",
        "\n",
        "    return metricsResults"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y0rbmoomr0n"
      },
      "source": [
        "## Evaluation method.\n",
        "This method evaluates the model for a specified dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjLO_n68mtYs"
      },
      "source": [
        "def evaluate(dataloader, model, criterion):\n",
        "    # Metrics for testing.\n",
        "    metricsResults = getMetricsDict()\n",
        "\n",
        "    # Enable the grad, for training.\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # Indicate that the model is going to be evaluated.\n",
        "        model.eval()\n",
        "\n",
        "        # Loader len, for metrics calculation.\n",
        "        loaderLen = len(dataloader)\n",
        "\n",
        "        # Iterate the batches for testing.\n",
        "        for batch in tqdm(dataloader, leave=False):\n",
        "            # Test the model.\n",
        "            # Get the inputs and labels, and move them to the selected device.\n",
        "            inputs, labels = batch[0].to(config[device]), batch[1].to(config[device])\n",
        "            # Get the predictions.\n",
        "            outputs = model(inputs)\n",
        "            # Calculate the error.\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Metrics for the testing set.\n",
        "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults)\n",
        "\n",
        "    return metricsResults"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlnoOBlXnFzC"
      },
      "source": [
        "## Trainining and evaluate method.\n",
        "For the specific purpose of this project, in each epoch we evaluate metrics for each data set (training and testing) in each epoch, this method simplifies the process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlfTRjJWnF6f"
      },
      "source": [
        "def trainAndEvaluate(trainloader, testloader, model, criterion, optimizer, savePath, epochsInit, epochs, runID):\n",
        "\n",
        "    startTimeTotal = time.time()\n",
        "\n",
        "    for epoch in tqdm(range(epochsInit, epochs + 1)):\n",
        "        \n",
        "        # Train the model.\n",
        "        trainMetricsResults = trainEpoch(trainloader, model, criterion, optimizer)\n",
        "        processRunningMetrics(trainMetricsResults)\n",
        "\n",
        "        # Evaluate the model.\n",
        "        testMetricsResults = evaluate(testloader, model, criterion)\n",
        "        processRunningMetrics(testMetricsResults)\n",
        "\n",
        "        # Log on wandb\n",
        "        logMetricsWandb(trainMetricsResults, testMetricsResults)\n",
        "\n",
        "        # Save model and metrics for the epochs.\n",
        "        saveEpochData(trainMetricsResults, testMetricsResults, model, optimizer, criterion, epoch, savePath, runID)\n",
        "\n",
        "        # Print the results.\n",
        "        if epoch % 1 == 0:\n",
        "            print('**', '[', 'Epoch ', epoch, ']', '*' * 48, sep='')\n",
        "            print('\\tTraining results:', end=' ')\n",
        "            printMetricsDict(trainMetricsResults)\n",
        "            print('\\t Testing results:', end=' ')\n",
        "            printMetricsDict(testMetricsResults)\n",
        "        \n",
        "    # Print time\n",
        "    print('Epochs terminados')\n",
        "    print(\"--- %s seconds ---\" % (time.time() - startTimeTotal))"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a3u0Ig62AUH"
      },
      "source": [
        "## General method for execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9IhVH4q2C7-"
      },
      "source": [
        "def loadCheckpoint(model, optimizer, criterion, loadPath):\n",
        "    # Load the checkpoint.\n",
        "    checkpoint = torch.load(loadPath)\n",
        "    # Load model.\n",
        "    model.load_state_dict(checkpoint[_model])\n",
        "    # Load optimizer.\n",
        "    optimizer.load_state_dict(checkpoint[_optimizer])\n",
        "    # Load criterion.\n",
        "    criterion = checkpoint[_criterion]\n",
        "    # Run ID.\n",
        "    runID = checkpoint[_runID]\n",
        "    # Set epoch.\n",
        "    epochsInit = checkpoint[_epoch] + 1\n",
        "\n",
        "    return model, optimizer, criterion, epochsInit+1, runID\n",
        "\n",
        "def executeTest(dataPath, runName, net, savePath, epochs):\n",
        "    if not os.path.exists(savePath):\n",
        "      loadPath = None\n",
        "    else:\n",
        "      if len(os.listdir(savePath)) == 0:\n",
        "        loadPath = None\n",
        "      else:\n",
        "        epochs_check = []\n",
        "\n",
        "        for i in os.listdir(savePath):\n",
        "          epochs_check.append(int(i))\n",
        "\n",
        "        loadPath = os.path.join(savePath, str(min(epochs_check)), \"model.pth\")\n",
        "\n",
        "        \n",
        "    # Get criterion and optimizer.\n",
        "    # Optimizer and the loss funtion used to train the model.\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adagrad(net.parameters(), lr=config[learningRate])\n",
        "\n",
        "    # Check if required to load a checkpoint.\n",
        "    resumeF = False\n",
        "    if loadPath != None:\n",
        "        net, optimizer, criterion, epochsInit, runID = loadCheckpoint(net, optimizer, criterion, loadPath)\n",
        "        net.to(config[device])\n",
        "        resumeF = True\n",
        "    else:\n",
        "      epochsInit = 0\n",
        "      runID = wandb.util.generate_id()\n",
        "\n",
        "    os.environ[\"WANDB_RUN_ID\"] = runID\n",
        "\n",
        "    # Get the loaders.\n",
        "    trainloader, testloader = getLoaders(dataPath)\n",
        "\n",
        "    # Init wandb\n",
        "    run = wandb.init(id=runID, project='Classifier-UNET-RESNET', entity='tecai', config=config, name=runName, resume=resumeF)\n",
        "\n",
        "    # Train and evaluate\n",
        "    trainAndEvaluate(trainloader, testloader, net, criterion, optimizer, savePath, epochsInit, epochs, runID)\n",
        "\n",
        "    # Finish wandb\n",
        "    run.finish()"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX-PBkxLqdbt"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "aa9c6a9953334ebd8ebeeb816c5a6d97",
            "9719f3ee58214d1da7f390ab6e01960d",
            "b3a5303781df451b9b21013a859b9f73",
            "b60d1dcbd83f4287a0b34781f6ed8a30",
            "9afb82d143624e5d8651c4a6298dc85e",
            "2c51043f03444fdeb6cc0f6573707b77",
            "8962ce499376424584cb227f29c1c90e",
            "de8c8c8c8b604828985d04fa8910b407",
            "56035a28b4254d6d909fa62f8c7fa15e",
            "4d0cd50b3afc4d1e9cb1718aeee109ee",
            "f0919e8dde674e09afb736fde8ceda83",
            "afc7d2f5dad04747b3337924f58bad98",
            "964cac9e03884541b7b07c1fdaa94ccd",
            "742582ad64fa4dfeac19620413871300",
            "c4deec9e6b2e41f5817e25c2c814206a",
            "b5cb95ee8dd740a780857cdb443c9deb",
            "3b92d41c4c994f318464e73bd9f02df7",
            "01a9a69168db4ce5aa031771b71d3160",
            "f665079e25a74156b19e40a1ef3c2735",
            "a915632adddc49f69d8a1ed61a7d0bca",
            "383dc032a1444f91ab806b354e4858bd",
            "1f76880133be434c93da9be1134b60a1",
            "0c176d1a371c493e9a9435c600ac978e",
            "cf0d58c906cb44799bda987c4f0eec48"
          ]
        },
        "id": "ixdrTGKBqemU",
        "outputId": "c3e2f507-aa5d-4c7b-c277-32a5b9c22ff0"
      },
      "source": [
        "for execution_config in executions_configs:\n",
        "  \n",
        "  config[groupType] = execution_config[exe_group_type]\n",
        "  config[configRun] = execution_config\n",
        "  \n",
        "  unet = UNET(in_channels=3, out_channels=3, isOnlyEncoder=True).to(config[device])\n",
        "\n",
        "  if execution_config[exe_load_check_point]:\n",
        "    load_checkpoint(torch.load(execution_config[exe_check_point_path]), unetTest)\n",
        "\n",
        "  if execution_config[exe_freeze_check_point]:\n",
        "    unet.eval()\n",
        "    \n",
        "  classifier_UNET = ClassifierUnet(out_channels=config[classesLen], unetModel=unet).to(config[device])\n",
        "  \n",
        "  executeTest(execution_config[exe_data_path],\n",
        "              execution_config[exe_execution_name],\n",
        "              classifier_UNET,\n",
        "              execution_config[exe_save_check_point_path],\n",
        "              execution_config[exe_can_epochs])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa9c6a9953334ebd8ebeeb816c5a6d97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56035a28b4254d6d909fa62f8c7fa15e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "**[Epoch 6]************************************************\n",
            "\tTraining results: Loss: 2.9008, Accuracy: 0.1687, Recall: 0.0729, Precision: 0.0285, F1: 0.0324, AUC: 0.7622\n",
            "\t Testing results: Loss: 3.0905, Accuracy: 0.1777, Recall: 0.0724, Precision: 0.0230, F1: 0.0300, AUC: 0.7430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b92d41c4c994f318464e73bd9f02df7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-e42fb3b54c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m               \u001b[0mclassifier_UNET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mexecution_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexe_save_check_point_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m               execution_config[exe_can_epochs])\n\u001b[0m",
            "\u001b[0;32m<ipython-input-120-3a556f2a6785>\u001b[0m in \u001b[0;36mexecuteTest\u001b[0;34m(dataPath, runName, net, savePath, epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtrainAndEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochsInit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Finish wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-41261bd0b76a>\u001b[0m in \u001b[0;36mtrainAndEvaluate\u001b[0;34m(trainloader, testloader, model, criterion, optimizer, savePath, epochsInit, epochs, runID)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Evaluate the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtestMetricsResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprocessRunningMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestMetricsResults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-31284b68372e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataloader, model, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Iterate the batches for testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Test the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Get the inputs and labels, and move them to the selected device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}