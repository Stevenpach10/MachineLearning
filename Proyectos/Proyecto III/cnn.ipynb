{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd009cf3d5909f3828bf53c46564821f879a9c8405e40e27fb09b54d745264e4a6d",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "09cf3d5909f3828bf53c46564821f879a9c8405e40e27fb09b54d745264e4a6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import of torch.\n",
    "import torch\n",
    "# Import for graph blocks of torch.\n",
    "import torch.nn as nn\n",
    "# Import the models library, to get the model to be used.\n",
    "import torchvision.models as models\n",
    "# Import optim library, to get the optimizer to be used.\n",
    "import torch.optim as optim\n",
    "# Import torchvision, to manage the input data.\n",
    "import torchvision\n",
    "# To apply transformations to the data (when loaded).\n",
    "import torchvision.transforms as transforms\n",
    "# To calculate softmax.\n",
    "from torch.nn import Softmax\n",
    "softmax = Softmax(dim=1)\n",
    "\n",
    "# Metrics.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# General imports.\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "source": [
    "### Enviroment configuration."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size of the model.\n",
    "inputSize = 'inputSize'\n",
    "# Output size of the model.\n",
    "outputSize = 'outputSize'\n",
    "# Batch size.\n",
    "batchSize = 'batchSize'\n",
    "# Epoch init.\n",
    "epochsInit = 'epochInit'\n",
    "# Epochs amount.\n",
    "epochs = 'epochs'\n",
    "# Learning rate.\n",
    "learningRate = 'learningRate'\n",
    "# Class names.\n",
    "classes = 'classes'\n",
    "# Class IDs.\n",
    "classesID = 'classesIDs'\n",
    "# Number of classes to classify.\n",
    "classesLen = 'classesLen'\n",
    "# Group type, for wandb.\n",
    "groupType = 'groupType'\n",
    "\n",
    "config = {\n",
    "    inputSize    : 224,\n",
    "    outputSize   : 39,\n",
    "    batchSize    : 128,\n",
    "    epochsInit   : 1,\n",
    "    epochs       : 100,\n",
    "    learningRate : 0.001,\n",
    "    classes : [\n",
    "        'Apple - Apple scab',\n",
    "        'Apple - Black rot',\n",
    "        'Apple - Cedar apple rust',\n",
    "        'Apple - Healthy',\n",
    "        'Background without leaves',\n",
    "        'Blueberry - Healthy',\n",
    "        'Cherry - Healthy',\n",
    "        'Cherry - Powdery mildew',\n",
    "        'Corn - Cercospora',\n",
    "        'Corn - Common rust',\n",
    "        'Corn - Healthy',\n",
    "        'Corn - Northern Leaf Blight',\n",
    "        'Grape - Black rot',\n",
    "        'Grape - Esca',\n",
    "        'Grape - Healthy',\n",
    "        'Grape - Leaf blight',\n",
    "        'Orange - Haunglongbing',\n",
    "        'Peach - Bacterial spot',\n",
    "        'Peach - Healthy',\n",
    "        'Pepper bell - Bacterial spot',\n",
    "        'Pepper bell - healthy',\n",
    "        'Potato - Early blight',\n",
    "        'Potato - Healthy',\n",
    "        'Potato - Late blight',\n",
    "        'Raspberry - healthy',\n",
    "        'Soybean - Healthy',\n",
    "        'Squash - Powdery mildew',\n",
    "        'Strawberry - Healthy',\n",
    "        'Strawberry - Leaf scorch',\n",
    "        'Tomato - Bacterial spot',\n",
    "        'Tomato - Early blight',\n",
    "        'Tomato - Healthy',\n",
    "        'Tomato - Late blight',\n",
    "        'Tomato - Leaf Mold',\n",
    "        'Tomato - Septoria leaf spot',\n",
    "        'Tomato - Spider mites',\n",
    "        'Tomato - Target Spot',\n",
    "        'Tomato - Mosaic virus',\n",
    "        'Tomato - Yellow Leaf Curl Virus'\n",
    "    ],\n",
    "    classesID : [i + 1 for i in range(39)],\n",
    "    classesLen : 39\n",
    "}\n",
    "\n",
    "# Device to be used, prefer cuda, if available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Wandb enviroment variables\n",
    "os.environ['WANDB_SILENT'] = 'true'"
   ]
  },
  {
   "source": [
    "### Metric functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About metrics.\n",
    "# Metric dictionary keys.\n",
    "# For preprocessing.\n",
    "_loss        = 'Loss'\n",
    "_groundtruth = 'Groundtruth'\n",
    "_logits      = 'Logits'\n",
    "# For postprocessing.\n",
    "_probabilities   = 'Probabilities'\n",
    "_predictions     = 'Predictions'\n",
    "_confusionMatrix = 'Confusion matrix'\n",
    "_accuracyClass   = 'Accuracy class'\n",
    "_accuracy        = 'Accuracy'\n",
    "_recall          = 'Recall'\n",
    "_precision       = 'Precision'\n",
    "_f1              = 'F1'\n",
    "_auc             = 'AUC'\n",
    "# For torch save\n",
    "_model           = 'Model State Dic'\n",
    "_optimizer       = 'Optimizer State Dic'\n",
    "_criterion       = 'Criterion'\n",
    "_epoch           = 'Epoch'\n",
    "_metricsTrain    = 'Resulting metrics (training)'\n",
    "_metricsTest     = 'Resulting metrics (testing)'\n",
    "\n",
    "_metricsPrint = [_accuracy, _recall, _precision, _f1, _auc]\n",
    "\n",
    "# Get a clean dictionary for the metrics.\n",
    "def getMetricsDict():\n",
    "    return {\n",
    "        _loss          : torch.tensor(0.),\n",
    "        _groundtruth   : torch.tensor([]),\n",
    "        _logits        : torch.tensor([])\n",
    "    }\n",
    "\n",
    "# Function used to update the dictionary of resulting metrics.\n",
    "def updateRunningMetrics(logits, groundtruth, loss, batchAmount, metricsResults):\n",
    "    # Accumulate the loss.\n",
    "    metricsResults[_loss] += loss.cpu() / batchAmount\n",
    "    # Accumulate the groundtruth and the logits.\n",
    "    metricsResults[_groundtruth] = torch.cat((metricsResults[_groundtruth], groundtruth.cpu())) \n",
    "    metricsResults[_logits] = torch.cat((metricsResults[_logits], logits.cpu()))\n",
    "\n",
    "# Function used to process the dictionary of resulting metrics (make final calculations).\n",
    "def processRunningMetrics(metricsResults):\n",
    "    # Detach the other values in the dictionary.\n",
    "    metricsResults[_loss] = metricsResults[_loss].detach()\n",
    "    metricsResults[_groundtruth] = metricsResults[_groundtruth].detach()\n",
    "    metricsResults[_logits] = metricsResults[_logits].detach()\n",
    "    # Save in the dictionary the probabilities and the predictions.\n",
    "    metricsResults[_probabilities] = softmax(metricsResults[_logits]).detach()\n",
    "    metricsResults[_predictions] = torch.argmax(metricsResults[_probabilities], axis=1).detach()\n",
    "\n",
    "    # Get Groundtruth (as numpy).\n",
    "    groundtruth = metricsResults[_groundtruth].detach().numpy()\n",
    "    # Get probabilities (as numpy).\n",
    "    probs = metricsResults[_probabilities].detach().numpy()\n",
    "    # Get predictions (as numpy).\n",
    "    preds = metricsResults[_predictions].detach().numpy()\n",
    "\n",
    "    # Calculate confusion matrix (normalized).\n",
    "    confusionMatrix = confusion_matrix(groundtruth, preds)\n",
    "    metricsResults[_confusionMatrix] = torch.tensor(confusionMatrix)\n",
    "\n",
    "    # Calculate accuracy by class.\n",
    "    confusionMatrix = confusionMatrix.astype('float') / confusionMatrix.sum(axis=1)[:, np.newaxis]\n",
    "    metricsResults[_accuracyClass] = torch.tensor(confusionMatrix.diagonal())\n",
    "\n",
    "    # Calculate accuracy.\n",
    "    metricsResults[_accuracy] = torch.tensor(accuracy_score(groundtruth, preds))\n",
    "    # Calculate recall.\n",
    "    metricsResults[_recall] = torch.tensor(recall_score(groundtruth, preds, average='macro', zero_division=0))\n",
    "    # Calculate precision.\n",
    "    metricsResults[_precision] = torch.tensor(precision_score(groundtruth, preds, average='macro', zero_division=0))\n",
    "    # Calculate F1.\n",
    "    metricsResults[_f1] = torch.tensor(f1_score(groundtruth, preds, average='macro', zero_division=0))\n",
    "    # Calculate AUC.\n",
    "    metricsResults[_auc] = torch.tensor(roc_auc_score(groundtruth, probs, multi_class='ovr'))\n",
    "\n",
    "# Pretty print the metrics dictionaries.\n",
    "def printMetricsDict(metricsResults):\n",
    "    # All metrics to print\n",
    "    metricPrints = []\n",
    "\n",
    "    # Format the loss.\n",
    "    lossPrint = 'Loss: {:.4f}'.format(metricsResults[_loss])\n",
    "    metricPrints.append(lossPrint)\n",
    "\n",
    "    # Format the the remaining metrics.\n",
    "    baseMetricString = '{}: {:1.4f}'\n",
    "    for metric in _metricsPrint:\n",
    "        metricPrints.append(baseMetricString.format(metric, metricsResults[metric]))\n",
    "\n",
    "    print(', '.join(metricPrints))\n",
    "\n",
    "# This functions process an metrics result dictionary for wandb. Is necessary to indicte\n",
    "#   the metrics origin, training or testing.\n",
    "def processMetricsWandb(metricsResults, training=False):\n",
    "    # Get the prefix to log on wandb, the keys must be different.\n",
    "    resultsType = 'training' if training else 'testing'\n",
    "\n",
    "    # Confusion matrix as a heat map.\n",
    "    _confusionMatrixHM = 'Confusion matrix (heat map)'\n",
    "\n",
    "    # All the wandb keys are based in the original metrics results keys.\n",
    "    lossKey = '{} ({})'.format(_loss, resultsType)\n",
    "    metricsKeys = ['{} ({})'.format(_metric, resultsType) for _metric in _metricsPrint]\n",
    "    accuracyClassKeys = ['{} accuracy ({})'.format(_class, resultsType) for _class in config[classes]]\n",
    "    confusionMatrixKey = '{} ({})'.format(_confusionMatrix, resultsType)\n",
    "    confusionMatrixHMKey = '{} ({})'.format(_confusionMatrixHM, resultsType)\n",
    "\n",
    "    # Get the confusion matrix for wandb.\n",
    "    data = []\n",
    "    for i in range(config[classesLen]):\n",
    "        for j in range(config[classesLen]):\n",
    "            data.append([config[classes][i], config[classesID][i], config[classes][j], config[classesID][j], metricsResults[_confusionMatrix][i, j].item()])\n",
    "\n",
    "    confusionMatrix = wandb.Table(columns=[\"Actual\", \"Actual (id)\", \"Predicted\", \"Predicted (id)\", \"nPredictions\"], data=data)\n",
    "\n",
    "    confusionMatrixHM = wandb.plots.HeatMap(config[classes], config[classes], metricsResults[_confusionMatrix].numpy(), show_text=False)\n",
    "\n",
    "    # Make the dictionary for wandb and store the values.\n",
    "    wandbDict = {\n",
    "        lossKey              : metricsResults[_loss].item(),\n",
    "        confusionMatrixKey   : confusionMatrix,\n",
    "        confusionMatrixHMKey : confusionMatrixHM\n",
    "    }\n",
    "    for i in range(len(metricsKeys)):\n",
    "        wandbDict[metricsKeys[i]] = metricsResults[_metricsPrint[i]].item()\n",
    "    for i in range(config[classesLen]):\n",
    "        wandbDict[accuracyClassKeys[i]] = metricsResults[_accuracyClass][i].item()\n",
    "\n",
    "    # Return, to log later.\n",
    "    return wandbDict\n",
    "\n",
    "# Get the metrics dictionaries for wandb and log them.\n",
    "def logMetricsWandb(trainMetricsResults, testMetricsResults):\n",
    "    # Get both dictionaries for wandb.\n",
    "    wandbTrainDict = processMetricsWandb(trainMetricsResults, training=True)\n",
    "    wandbTestDict  = processMetricsWandb(testMetricsResults, training=False)\n",
    "\n",
    "    # Merge the dictionaries.\n",
    "    wandbDict = {**wandbTrainDict, **wandbTestDict}\n",
    "\n",
    "    # Log on wandb\n",
    "    wandb.log(wandbDict)\n",
    "\n",
    "# Function used to save the model and the metrics.\n",
    "def saveEpochData(trainMetricsResults, testMetricsResults, model, optimizer, criterion, epoch, rootPath):\n",
    "    # Create a dir for the current epoch.\n",
    "    runDir = os.path.join(os.getcwd(), rootPath, str(epoch))\n",
    "    Path(runDir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Path\n",
    "    savePath = os.path.join(runDir, 'model.pth')\n",
    "\n",
    "    # Make dict for torch.save\n",
    "    saveDict = {\n",
    "        _model     : model.state_dict(),\n",
    "        _optimizer : optimizer.state_dict(),\n",
    "        _criterion : criterion,\n",
    "        _epoch     : epoch\n",
    "    }\n",
    "\n",
    "    # Save both metrics, for train and test.\n",
    "    metricsResults = {\n",
    "        _metricsTrain : trainMetricsResults,\n",
    "        _metricsTest  : testMetricsResults\n",
    "    }\n",
    "\n",
    "    # Merge the save dict with the metricsResults dict.\n",
    "    saveDict = {**metricsResults, **saveDict}\n",
    "\n",
    "    # Save\n",
    "    torch.save(saveDict, savePath)"
   ]
  },
  {
   "source": [
    "### Loader function.\n",
    "Should return the training loader and test loader, a iterable object by batches."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation definitions.\n",
    "transformTrain = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(config[inputSize]),  # This one does a resize (it cuts randomly, it doesn't keep the whole image).\n",
    "        transforms.RandomHorizontalFlip(),                # Flip the image horizontally randomly.\n",
    "        transforms.ToTensor(),                            # Make the image a tensor.\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Expected normalization for pretrained pytorch models.\n",
    "    ])\n",
    "transformTest = transforms.Compose([\n",
    "        transforms.Resize(config[inputSize]),             # Resize the image, keeping all pixels.\n",
    "        transforms.CenterCrop(config[inputSize]),         # Cut the image in the center.\n",
    "        transforms.ToTensor(),                            # Make the image a tensor.\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Expected normalization for pretrained pytorch models.\n",
    "    ])\n",
    "\n",
    "# Function used to get the data loaders.\n",
    "# A folder with two folders inside called train and test is expected as a rootPath.\n",
    "def getLoaders(rootPath):\n",
    "    trainPath = os.path.join(rootPath, 'labelTrain')\n",
    "    testPath  = os.path.join(rootPath, 'labelTest')\n",
    "\n",
    "    # Get the training and test data, apply the transformations.\n",
    "    trainset = torchvision.datasets.ImageFolder(root=trainPath, transform=transformTrain)\n",
    "    testset  = torchvision.datasets.ImageFolder(root=testPath,  transform=transformTest)\n",
    "\n",
    "    # Get the loaders, to iterate the data through batches.\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=config[batchSize], shuffle=True, num_workers=2)\n",
    "    testloader  = torch.utils.data.DataLoader(testset,  batch_size=config[batchSize], shuffle=True, num_workers=2)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "source": [
    "### Training method.\n",
    "This method takes care of a single training pass. Another function call this one multiple times."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch(dataloader, model, criterion, optimizer):\n",
    "    # Metrics for training.\n",
    "    metricsResults = getMetricsDict()\n",
    "\n",
    "    # Enable the grad, for training.\n",
    "    with torch.set_grad_enabled(True):\n",
    "\n",
    "        # Indicate that the model is going to be trained.\n",
    "        model.train()\n",
    "\n",
    "        # Loader len, for metrics calculation.\n",
    "        loaderLen = len(dataloader)\n",
    "\n",
    "        # Iterate the batches for training.\n",
    "        for batch in dataloader:\n",
    "            # Train the model.\n",
    "            # Get the inputs and labels, and move them to the selected device.\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            # Zero the gradient parameters.\n",
    "            optimizer.zero_grad()\n",
    "            # Get the predictions.\n",
    "            outputs = model(inputs)\n",
    "            # Calculate the error.\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Calculates the derivatives of the parameters that have a gradient.\n",
    "            loss.backward()\n",
    "            # Update the parameters based on the computer gradient.\n",
    "            optimizer.step()\n",
    "            # Metrics for the training set.\n",
    "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults)\n",
    "\n",
    "    return metricsResults"
   ]
  },
  {
   "source": [
    "### Evaluation method.\n",
    "This method evaluates the model for a specified dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion):\n",
    "    # Metrics for testing.\n",
    "    metricsResults = getMetricsDict()\n",
    "\n",
    "    # Enable the grad, for training.\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # Indicate that the model is going to be evaluated.\n",
    "        model.eval()\n",
    "\n",
    "        # Loader len, for metrics calculation.\n",
    "        loaderLen = len(dataloader)\n",
    "\n",
    "        # Iterate the batches for testing.\n",
    "        for batch in dataloader:\n",
    "            # Test the model.\n",
    "            # Get the inputs and labels, and move them to the selected device.\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            # Get the predictions.\n",
    "            outputs = model(inputs)\n",
    "            # Calculate the error.\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Metrics for the testing set.\n",
    "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults)\n",
    "\n",
    "    return metricsResults"
   ]
  },
  {
   "source": [
    "### Trainining and evaluate method.\n",
    "For the specific purpose of this project, in each epoch we evaluate metrics for each data set (training and testing) in each epoch, this method simplifies the process. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEvaluate(trainloader, testloader, model, criterion, optimizer, savePath):\n",
    "\n",
    "    for epoch in range(config[epochsInit], config[epochs] + 1):\n",
    "        \n",
    "        # Train the model.\n",
    "        trainMetricsResults = trainEpoch(trainloader, model, criterion, optimizer)\n",
    "        processRunningMetrics(trainMetricsResults)\n",
    "\n",
    "        # Evaluate the model.\n",
    "        testMetricsResults = evaluate(testloader, model, criterion)\n",
    "        processRunningMetrics(testMetricsResults)\n",
    "\n",
    "        # Log on wandb\n",
    "        logMetricsWandb(trainMetricsResults, testMetricsResults)\n",
    "\n",
    "        # Save model and metrics for the epochs.\n",
    "        saveEpochData(trainMetricsResults, testMetricsResults, model, optimizer, criterion, epoch, savePath)\n",
    "\n",
    "        # Print the results.\n",
    "        if epoch % 1 == 0:\n",
    "            print('**', '[', 'Epoch ', epoch, ']', '*' * 48, sep='')\n",
    "            print('\\tTraining results:', end=' ')\n",
    "            printMetricsDict(trainMetricsResults)\n",
    "            print('\\t Testing results:', end=' ')\n",
    "            printMetricsDict(testMetricsResults)"
   ]
  },
  {
   "source": [
    "### General method for execution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCheckpoint(model, optimizer, criterion, loadPath):\n",
    "    # Load the checkpoint.\n",
    "    checkpoint = torch.load(loadPath)\n",
    "    # Load model.\n",
    "    model.load_state_dict(checkpoint[_model])\n",
    "    # Load optimizer.\n",
    "    optimizer.load_state_dict(checkpoint[_optimizer])\n",
    "    # Load criterion.\n",
    "    criterion = checkpoint[_criterion]\n",
    "    # Set epoch.\n",
    "    config[epochsInit] = checkpoint[_epoch] + 1\n",
    "\n",
    "    return model, optimizer, criterion\n",
    "\n",
    "def executeTest(dataPath, runName, savePath, loadPath=None):\n",
    "    # Get the model.\n",
    "    # Get a predefined model from pytorch, without the pretrained parameters.\n",
    "    net = models.resnet18(pretrained=False)\n",
    "    # Get the input size of the las layer of the model.\n",
    "    llInputSize = net.fc.in_features\n",
    "    # Modify the last layer of the model, to classify the amount of required classes.\n",
    "    net.fc = nn.Linear(llInputSize, config[outputSize])\n",
    "\n",
    "    # Load the model to the selected device.\n",
    "    net.to(device)\n",
    "    \n",
    "    # Get criterion and optimizer.\n",
    "    # Optimizer and the loss funtion used to train the model.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=config[learningRate])\n",
    "\n",
    "    # Check if required to load a checkpoint.\n",
    "    if loadPath != None:\n",
    "        net, optimizer, criterion = loadCheckpoint(net, optimizer, criterion, loadPath)\n",
    "        net.to(device)\n",
    "\n",
    "    # Get the loaders.\n",
    "    trainloader, testloader = getLoaders(dataPath)\n",
    "\n",
    "    # Init wandb\n",
    "    run = wandb.init(project='Classifier-UNET-RESNET', entity='tecai', config=config, name=runName)\n",
    "\n",
    "    # Train and evaluate\n",
    "    trainAndEvaluate(trainloader, testloader, net, criterion, optimizer, savePath)\n",
    "\n",
    "    # Finish wandb\n",
    "    run.finish()"
   ]
  },
  {
   "source": [
    "# Experiments\n",
    "The experiments seek to explore the transfer learning, so it will focus on seeing the performance of the model in different datasets, exchanging parameters learned from other runs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### First run\n",
    "For the first run we are going to explore the performance of resnet34 with pretrained parameters on the raw dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "707, Precision: 0.7553, F1: 0.6729, AUC: 0.9816\n",
      "**[Epoch 30]************************************************\n",
      "\tTraining results: Loss: 0.4751, Accuracy: 0.8715, Recall: 0.8471, Precision: 0.8560, F1: 0.8510, AUC: 0.9964\n",
      "\t Testing results: Loss: 1.4749, Accuracy: 0.5941, Recall: 0.5367, Precision: 0.6587, F1: 0.5442, AUC: 0.9623\n",
      "**[Epoch 31]************************************************\n",
      "\tTraining results: Loss: 0.4760, Accuracy: 0.8778, Recall: 0.8567, Precision: 0.8646, F1: 0.8596, AUC: 0.9968\n",
      "\t Testing results: Loss: 0.6051, Accuracy: 0.8132, Recall: 0.7704, Precision: 0.8290, F1: 0.7793, AUC: 0.9941\n",
      "**[Epoch 32]************************************************\n",
      "\tTraining results: Loss: 0.4600, Accuracy: 0.8871, Recall: 0.8694, Precision: 0.8730, F1: 0.8707, AUC: 0.9970\n",
      "\t Testing results: Loss: 0.9125, Accuracy: 0.7416, Recall: 0.7131, Precision: 0.7772, F1: 0.7124, AUC: 0.9865\n",
      "**[Epoch 33]************************************************\n",
      "\tTraining results: Loss: 0.4246, Accuracy: 0.8863, Recall: 0.8698, Precision: 0.8718, F1: 0.8696, AUC: 0.9972\n",
      "\t Testing results: Loss: 1.6173, Accuracy: 0.5854, Recall: 0.5078, Precision: 0.7284, F1: 0.4979, AUC: 0.9694\n",
      "**[Epoch 34]************************************************\n",
      "\tTraining results: Loss: 0.4137, Accuracy: 0.8876, Recall: 0.8692, Precision: 0.8754, F1: 0.8712, AUC: 0.9975\n",
      "\t Testing results: Loss: 0.9557, Accuracy: 0.7148, Recall: 0.6525, Precision: 0.7763, F1: 0.6679, AUC: 0.9862\n",
      "**[Epoch 35]************************************************\n",
      "\tTraining results: Loss: 0.4185, Accuracy: 0.8917, Recall: 0.8724, Precision: 0.8783, F1: 0.8745, AUC: 0.9974\n",
      "\t Testing results: Loss: 0.9219, Accuracy: 0.7280, Recall: 0.6731, Precision: 0.7788, F1: 0.6888, AUC: 0.9881\n",
      "**[Epoch 36]************************************************\n",
      "\tTraining results: Loss: 0.3835, Accuracy: 0.8954, Recall: 0.8767, Precision: 0.8830, F1: 0.8789, AUC: 0.9974\n",
      "\t Testing results: Loss: 0.5013, Accuracy: 0.8371, Recall: 0.7952, Precision: 0.8644, F1: 0.8077, AUC: 0.9964\n",
      "**[Epoch 37]************************************************\n",
      "\tTraining results: Loss: 0.4022, Accuracy: 0.8948, Recall: 0.8770, Precision: 0.8846, F1: 0.8799, AUC: 0.9977\n",
      "\t Testing results: Loss: 1.2996, Accuracy: 0.6740, Recall: 0.6208, Precision: 0.7567, F1: 0.6087, AUC: 0.9760\n",
      "**[Epoch 38]************************************************\n",
      "\tTraining results: Loss: 0.3994, Accuracy: 0.8915, Recall: 0.8699, Precision: 0.8788, F1: 0.8731, AUC: 0.9971\n",
      "\t Testing results: Loss: 0.8253, Accuracy: 0.7720, Recall: 0.7370, Precision: 0.7984, F1: 0.7459, AUC: 0.9865\n",
      "**[Epoch 39]************************************************\n",
      "\tTraining results: Loss: 0.3888, Accuracy: 0.8918, Recall: 0.8714, Precision: 0.8769, F1: 0.8732, AUC: 0.9976\n",
      "\t Testing results: Loss: 3.1335, Accuracy: 0.4951, Recall: 0.4492, Precision: 0.7218, F1: 0.4799, AUC: 0.8947\n",
      "**[Epoch 40]************************************************\n",
      "\tTraining results: Loss: 0.4324, Accuracy: 0.8878, Recall: 0.8695, Precision: 0.8799, F1: 0.8740, AUC: 0.9970\n",
      "\t Testing results: Loss: 2.0656, Accuracy: 0.4985, Recall: 0.4427, Precision: 0.6808, F1: 0.4417, AUC: 0.9609\n",
      "**[Epoch 41]************************************************\n",
      "\tTraining results: Loss: 0.4068, Accuracy: 0.8809, Recall: 0.8671, Precision: 0.8692, F1: 0.8672, AUC: 0.9971\n",
      "\t Testing results: Loss: 0.5113, Accuracy: 0.8407, Recall: 0.8089, Precision: 0.8623, F1: 0.8195, AUC: 0.9947\n",
      "**[Epoch 42]************************************************\n",
      "\tTraining results: Loss: 0.3630, Accuracy: 0.9029, Recall: 0.8856, Precision: 0.8920, F1: 0.8881, AUC: 0.9981\n",
      "\t Testing results: Loss: 0.6870, Accuracy: 0.7997, Recall: 0.7594, Precision: 0.8547, F1: 0.7674, AUC: 0.9925\n",
      "**[Epoch 43]************************************************\n",
      "\tTraining results: Loss: 0.3663, Accuracy: 0.9029, Recall: 0.8857, Precision: 0.8932, F1: 0.8887, AUC: 0.9980\n",
      "\t Testing results: Loss: 0.7984, Accuracy: 0.7517, Recall: 0.7199, Precision: 0.7958, F1: 0.7329, AUC: 0.9890\n",
      "**[Epoch 44]************************************************\n",
      "\tTraining results: Loss: 0.3915, Accuracy: 0.8970, Recall: 0.8782, Precision: 0.8842, F1: 0.8807, AUC: 0.9975\n",
      "\t Testing results: Loss: 0.9113, Accuracy: 0.7270, Recall: 0.6790, Precision: 0.8074, F1: 0.6836, AUC: 0.9884\n",
      "**[Epoch 45]************************************************\n",
      "\tTraining results: Loss: 0.3629, Accuracy: 0.8964, Recall: 0.8780, Precision: 0.8853, F1: 0.8809, AUC: 0.9976\n",
      "\t Testing results: Loss: 0.8720, Accuracy: 0.7785, Recall: 0.7206, Precision: 0.8393, F1: 0.7472, AUC: 0.9845\n",
      "**[Epoch 46]************************************************\n",
      "\tTraining results: Loss: 0.3332, Accuracy: 0.9118, Recall: 0.8963, Precision: 0.9043, F1: 0.8994, AUC: 0.9982\n",
      "\t Testing results: Loss: 0.8165, Accuracy: 0.7564, Recall: 0.7313, Precision: 0.8140, F1: 0.7358, AUC: 0.9918\n",
      "**[Epoch 47]************************************************\n",
      "\tTraining results: Loss: 0.3449, Accuracy: 0.9097, Recall: 0.8924, Precision: 0.8982, F1: 0.8947, AUC: 0.9983\n",
      "\t Testing results: Loss: 1.6689, Accuracy: 0.5719, Recall: 0.5317, Precision: 0.6616, F1: 0.5342, AUC: 0.9555\n",
      "**[Epoch 48]************************************************\n",
      "\tTraining results: Loss: 0.4029, Accuracy: 0.8988, Recall: 0.8829, Precision: 0.8903, F1: 0.8855, AUC: 0.9976\n",
      "\t Testing results: Loss: 0.8629, Accuracy: 0.7517, Recall: 0.7158, Precision: 0.7524, F1: 0.6995, AUC: 0.9889\n",
      "**[Epoch 49]************************************************\n",
      "\tTraining results: Loss: 0.3675, Accuracy: 0.8998, Recall: 0.8818, Precision: 0.8858, F1: 0.8832, AUC: 0.9978\n",
      "\t Testing results: Loss: 0.6143, Accuracy: 0.8179, Recall: 0.7851, Precision: 0.8615, F1: 0.7963, AUC: 0.9920\n",
      "**[Epoch 50]************************************************\n",
      "\tTraining results: Loss: 0.3431, Accuracy: 0.9063, Recall: 0.8900, Precision: 0.8972, F1: 0.8926, AUC: 0.9983\n",
      "\t Testing results: Loss: 0.6440, Accuracy: 0.8098, Recall: 0.7797, Precision: 0.8443, F1: 0.7826, AUC: 0.9930\n",
      "**[Epoch 51]************************************************\n",
      "\tTraining results: Loss: 0.3257, Accuracy: 0.9102, Recall: 0.8966, Precision: 0.8988, F1: 0.8970, AUC: 0.9982\n",
      "\t Testing results: Loss: 0.4228, Accuracy: 0.8758, Recall: 0.8536, Precision: 0.8759, F1: 0.8589, AUC: 0.9972\n",
      "**[Epoch 52]************************************************\n",
      "\tTraining results: Loss: 0.3387, Accuracy: 0.9201, Recall: 0.9070, Precision: 0.9133, F1: 0.9097, AUC: 0.9986\n",
      "\t Testing results: Loss: 2.1697, Accuracy: 0.5400, Recall: 0.4814, Precision: 0.6810, F1: 0.4673, AUC: 0.9477\n",
      "**[Epoch 53]************************************************\n",
      "\tTraining results: Loss: 0.3448, Accuracy: 0.9071, Recall: 0.8928, Precision: 0.8964, F1: 0.8939, AUC: 0.9981\n",
      "\t Testing results: Loss: 0.8485, Accuracy: 0.7524, Recall: 0.7161, Precision: 0.8333, F1: 0.7151, AUC: 0.9912\n",
      "**[Epoch 54]************************************************\n",
      "\tTraining results: Loss: 0.3312, Accuracy: 0.9180, Recall: 0.9053, Precision: 0.9069, F1: 0.9056, AUC: 0.9985\n",
      "\t Testing results: Loss: 0.4337, Accuracy: 0.8676, Recall: 0.8364, Precision: 0.8728, F1: 0.8430, AUC: 0.9964\n",
      "**[Epoch 55]************************************************\n",
      "\tTraining results: Loss: 0.3537, Accuracy: 0.9128, Recall: 0.8996, Precision: 0.9047, F1: 0.9015, AUC: 0.9985\n",
      "\t Testing results: Loss: 0.8685, Accuracy: 0.7416, Recall: 0.7131, Precision: 0.8078, F1: 0.7239, AUC: 0.9885\n",
      "**[Epoch 56]************************************************\n",
      "\tTraining results: Loss: 0.3245, Accuracy: 0.9128, Recall: 0.8983, Precision: 0.9026, F1: 0.9000, AUC: 0.9985\n",
      "\t Testing results: Loss: 0.8013, Accuracy: 0.7579, Recall: 0.7013, Precision: 0.8342, F1: 0.7244, AUC: 0.9926\n",
      "**[Epoch 57]************************************************\n",
      "\tTraining results: Loss: 0.3011, Accuracy: 0.9218, Recall: 0.9057, Precision: 0.9149, F1: 0.9099, AUC: 0.9986\n",
      "\t Testing results: Loss: 0.4333, Accuracy: 0.8763, Recall: 0.8519, Precision: 0.8818, F1: 0.8535, AUC: 0.9965\n",
      "**[Epoch 58]************************************************\n",
      "\tTraining results: Loss: 0.3039, Accuracy: 0.9172, Recall: 0.9041, Precision: 0.9079, F1: 0.9058, AUC: 0.9986\n",
      "\t Testing results: Loss: 0.5443, Accuracy: 0.8449, Recall: 0.8158, Precision: 0.8667, F1: 0.8189, AUC: 0.9955\n",
      "**[Epoch 59]************************************************\n",
      "\tTraining results: Loss: 0.3231, Accuracy: 0.9193, Recall: 0.9039, Precision: 0.9098, F1: 0.9060, AUC: 0.9985\n",
      "\t Testing results: Loss: 1.5294, Accuracy: 0.6629, Recall: 0.6229, Precision: 0.7996, F1: 0.6364, AUC: 0.9582\n",
      "**[Epoch 60]************************************************\n",
      "\tTraining results: Loss: 0.3505, Accuracy: 0.9117, Recall: 0.8956, Precision: 0.9001, F1: 0.8972, AUC: 0.9981\n",
      "\t Testing results: Loss: 0.8780, Accuracy: 0.7372, Recall: 0.7284, Precision: 0.7919, F1: 0.7329, AUC: 0.9899\n",
      "**[Epoch 61]************************************************\n",
      "\tTraining results: Loss: 0.2990, Accuracy: 0.9195, Recall: 0.9080, Precision: 0.9139, F1: 0.9107, AUC: 0.9986\n",
      "\t Testing results: Loss: 0.7879, Accuracy: 0.7623, Recall: 0.7285, Precision: 0.7845, F1: 0.7224, AUC: 0.9912\n",
      "**[Epoch 62]************************************************\n",
      "\tTraining results: Loss: 0.3332, Accuracy: 0.9227, Recall: 0.9078, Precision: 0.9160, F1: 0.9114, AUC: 0.9988\n",
      "\t Testing results: Loss: 1.0077, Accuracy: 0.7332, Recall: 0.7193, Precision: 0.8097, F1: 0.7109, AUC: 0.9881\n",
      "**[Epoch 63]************************************************\n",
      "\tTraining results: Loss: 0.3697, Accuracy: 0.9144, Recall: 0.9044, Precision: 0.9081, F1: 0.9056, AUC: 0.9985\n",
      "\t Testing results: Loss: 0.6698, Accuracy: 0.8000, Recall: 0.7777, Precision: 0.8072, F1: 0.7691, AUC: 0.9930\n",
      "**[Epoch 64]************************************************\n",
      "\tTraining results: Loss: 0.3218, Accuracy: 0.9182, Recall: 0.9052, Precision: 0.9109, F1: 0.9076, AUC: 0.9984\n",
      "\t Testing results: Loss: 0.9211, Accuracy: 0.7631, Recall: 0.7088, Precision: 0.8626, F1: 0.7360, AUC: 0.9789\n",
      "**[Epoch 65]************************************************\n",
      "\tTraining results: Loss: 0.3148, Accuracy: 0.9128, Recall: 0.8980, Precision: 0.9080, F1: 0.9022, AUC: 0.9984\n",
      "\t Testing results: Loss: 0.6248, Accuracy: 0.8104, Recall: 0.7865, Precision: 0.8314, F1: 0.7810, AUC: 0.9934\n",
      "**[Epoch 66]************************************************\n",
      "\tTraining results: Loss: 0.3299, Accuracy: 0.9195, Recall: 0.9045, Precision: 0.9115, F1: 0.9072, AUC: 0.9987\n",
      "\t Testing results: Loss: 1.1674, Accuracy: 0.6754, Recall: 0.6385, Precision: 0.8047, F1: 0.6472, AUC: 0.9854\n",
      "**[Epoch 67]************************************************\n",
      "\tTraining results: Loss: 0.3102, Accuracy: 0.9200, Recall: 0.9076, Precision: 0.9106, F1: 0.9087, AUC: 0.9987\n",
      "\t Testing results: Loss: 0.5430, Accuracy: 0.8338, Recall: 0.7934, Precision: 0.8476, F1: 0.8000, AUC: 0.9955\n",
      "**[Epoch 68]************************************************\n",
      "\tTraining results: Loss: 0.2819, Accuracy: 0.9245, Recall: 0.9128, Precision: 0.9163, F1: 0.9139, AUC: 0.9988\n",
      "\t Testing results: Loss: 0.8704, Accuracy: 0.7501, Recall: 0.7066, Precision: 0.7854, F1: 0.7050, AUC: 0.9902\n",
      "**[Epoch 69]************************************************\n",
      "\tTraining results: Loss: 0.3096, Accuracy: 0.9213, Recall: 0.9071, Precision: 0.9114, F1: 0.9089, AUC: 0.9986\n",
      "\t Testing results: Loss: 0.4594, Accuracy: 0.8600, Recall: 0.8482, Precision: 0.8665, F1: 0.8488, AUC: 0.9966\n",
      "**[Epoch 70]************************************************\n",
      "\tTraining results: Loss: 0.3039, Accuracy: 0.9183, Recall: 0.9041, Precision: 0.9092, F1: 0.9062, AUC: 0.9987\n",
      "\t Testing results: Loss: 0.5199, Accuracy: 0.8400, Recall: 0.8011, Precision: 0.8739, F1: 0.8220, AUC: 0.9953\n",
      "**[Epoch 71]************************************************\n",
      "\tTraining results: Loss: 0.2564, Accuracy: 0.9281, Recall: 0.9143, Precision: 0.9191, F1: 0.9162, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.2903, Accuracy: 0.9088, Recall: 0.8947, Precision: 0.9034, F1: 0.8958, AUC: 0.9985\n",
      "**[Epoch 72]************************************************\n",
      "\tTraining results: Loss: 0.2951, Accuracy: 0.9302, Recall: 0.9181, Precision: 0.9212, F1: 0.9193, AUC: 0.9989\n",
      "\t Testing results: Loss: 0.4613, Accuracy: 0.8548, Recall: 0.8279, Precision: 0.8554, F1: 0.8307, AUC: 0.9967\n",
      "**[Epoch 73]************************************************\n",
      "\tTraining results: Loss: 0.2713, Accuracy: 0.9275, Recall: 0.9147, Precision: 0.9186, F1: 0.9163, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.6246, Accuracy: 0.8143, Recall: 0.7810, Precision: 0.8557, F1: 0.7900, AUC: 0.9937\n",
      "**[Epoch 74]************************************************\n",
      "\tTraining results: Loss: 0.2856, Accuracy: 0.9252, Recall: 0.9118, Precision: 0.9150, F1: 0.9128, AUC: 0.9987\n",
      "\t Testing results: Loss: 0.5159, Accuracy: 0.8367, Recall: 0.7959, Precision: 0.8760, F1: 0.8177, AUC: 0.9956\n",
      "**[Epoch 75]************************************************\n",
      "\tTraining results: Loss: 0.3411, Accuracy: 0.9281, Recall: 0.9158, Precision: 0.9186, F1: 0.9168, AUC: 0.9989\n",
      "\t Testing results: Loss: 0.4686, Accuracy: 0.8524, Recall: 0.8335, Precision: 0.8526, F1: 0.8287, AUC: 0.9966\n",
      "**[Epoch 76]************************************************\n",
      "\tTraining results: Loss: 0.2836, Accuracy: 0.9302, Recall: 0.9182, Precision: 0.9222, F1: 0.9197, AUC: 0.9989\n",
      "\t Testing results: Loss: 0.5876, Accuracy: 0.8439, Recall: 0.8112, Precision: 0.8543, F1: 0.8169, AUC: 0.9900\n",
      "**[Epoch 77]************************************************\n",
      "\tTraining results: Loss: 0.3095, Accuracy: 0.9255, Recall: 0.9109, Precision: 0.9160, F1: 0.9130, AUC: 0.9988\n",
      "\t Testing results: Loss: 0.7628, Accuracy: 0.7906, Recall: 0.7544, Precision: 0.8152, F1: 0.7502, AUC: 0.9931\n",
      "**[Epoch 78]************************************************\n",
      "\tTraining results: Loss: 0.2923, Accuracy: 0.9266, Recall: 0.9170, Precision: 0.9172, F1: 0.9167, AUC: 0.9989\n",
      "\t Testing results: Loss: 0.4254, Accuracy: 0.8668, Recall: 0.8337, Precision: 0.8799, F1: 0.8401, AUC: 0.9977\n",
      "**[Epoch 79]************************************************\n",
      "\tTraining results: Loss: 0.2707, Accuracy: 0.9312, Recall: 0.9190, Precision: 0.9220, F1: 0.9201, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.5255, Accuracy: 0.8496, Recall: 0.8257, Precision: 0.8839, F1: 0.8347, AUC: 0.9951\n",
      "**[Epoch 80]************************************************\n",
      "\tTraining results: Loss: 0.3552, Accuracy: 0.9179, Recall: 0.9047, Precision: 0.9084, F1: 0.9061, AUC: 0.9986\n",
      "\t Testing results: Loss: 0.6157, Accuracy: 0.8187, Recall: 0.8081, Precision: 0.8461, F1: 0.8042, AUC: 0.9955\n",
      "**[Epoch 81]************************************************\n",
      "\tTraining results: Loss: 0.2817, Accuracy: 0.9302, Recall: 0.9188, Precision: 0.9225, F1: 0.9203, AUC: 0.9991\n",
      "\t Testing results: Loss: 0.7845, Accuracy: 0.7660, Recall: 0.7114, Precision: 0.8243, F1: 0.7251, AUC: 0.9916\n",
      "**[Epoch 82]************************************************\n",
      "\tTraining results: Loss: 0.2624, Accuracy: 0.9273, Recall: 0.9142, Precision: 0.9190, F1: 0.9160, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.3107, Accuracy: 0.8980, Recall: 0.8804, Precision: 0.9026, F1: 0.8843, AUC: 0.9984\n",
      "**[Epoch 83]************************************************\n",
      "\tTraining results: Loss: 0.2465, Accuracy: 0.9359, Recall: 0.9259, Precision: 0.9307, F1: 0.9280, AUC: 0.9991\n",
      "\t Testing results: Loss: 0.5634, Accuracy: 0.8250, Recall: 0.7938, Precision: 0.8395, F1: 0.7975, AUC: 0.9954\n",
      "**[Epoch 84]************************************************\n",
      "\tTraining results: Loss: 0.2853, Accuracy: 0.9273, Recall: 0.9177, Precision: 0.9182, F1: 0.9175, AUC: 0.9989\n",
      "\t Testing results: Loss: 1.2340, Accuracy: 0.6743, Recall: 0.6824, Precision: 0.7523, F1: 0.6702, AUC: 0.9804\n",
      "**[Epoch 85]************************************************\n",
      "\tTraining results: Loss: 0.2950, Accuracy: 0.9278, Recall: 0.9196, Precision: 0.9185, F1: 0.9184, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.4213, Accuracy: 0.8714, Recall: 0.8519, Precision: 0.8853, F1: 0.8616, AUC: 0.9968\n",
      "**[Epoch 86]************************************************\n",
      "\tTraining results: Loss: 0.2905, Accuracy: 0.9292, Recall: 0.9190, Precision: 0.9224, F1: 0.9203, AUC: 0.9989\n",
      "\t Testing results: Loss: 0.4888, Accuracy: 0.8501, Recall: 0.8170, Precision: 0.8617, F1: 0.8282, AUC: 0.9965\n",
      "**[Epoch 87]************************************************\n",
      "\tTraining results: Loss: 0.2329, Accuracy: 0.9359, Recall: 0.9259, Precision: 0.9284, F1: 0.9269, AUC: 0.9991\n",
      "\t Testing results: Loss: 0.2834, Accuracy: 0.9127, Recall: 0.8988, Precision: 0.9098, F1: 0.9016, AUC: 0.9986\n",
      "**[Epoch 88]************************************************\n",
      "\tTraining results: Loss: 0.2474, Accuracy: 0.9364, Recall: 0.9246, Precision: 0.9300, F1: 0.9271, AUC: 0.9991\n",
      "\t Testing results: Loss: 0.3323, Accuracy: 0.8932, Recall: 0.8739, Precision: 0.8929, F1: 0.8796, AUC: 0.9981\n",
      "**[Epoch 89]************************************************\n",
      "\tTraining results: Loss: 0.2371, Accuracy: 0.9395, Recall: 0.9296, Precision: 0.9324, F1: 0.9305, AUC: 0.9992\n",
      "\t Testing results: Loss: 0.2910, Accuracy: 0.9076, Recall: 0.8886, Precision: 0.9057, F1: 0.8917, AUC: 0.9986\n",
      "**[Epoch 90]************************************************\n",
      "\tTraining results: Loss: 0.2510, Accuracy: 0.9359, Recall: 0.9240, Precision: 0.9275, F1: 0.9253, AUC: 0.9991\n",
      "\t Testing results: Loss: 0.5001, Accuracy: 0.8437, Recall: 0.8106, Precision: 0.8577, F1: 0.8116, AUC: 0.9962\n",
      "**[Epoch 91]************************************************\n",
      "\tTraining results: Loss: 0.2881, Accuracy: 0.9317, Recall: 0.9222, Precision: 0.9243, F1: 0.9228, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.6900, Accuracy: 0.8060, Recall: 0.7719, Precision: 0.8327, F1: 0.7736, AUC: 0.9920\n",
      "**[Epoch 92]************************************************\n",
      "\tTraining results: Loss: 0.2817, Accuracy: 0.9279, Recall: 0.9140, Precision: 0.9199, F1: 0.9165, AUC: 0.9985\n",
      "\t Testing results: Loss: 0.6414, Accuracy: 0.8185, Recall: 0.7757, Precision: 0.8099, F1: 0.7691, AUC: 0.9943\n",
      "**[Epoch 93]************************************************\n",
      "\tTraining results: Loss: 0.2909, Accuracy: 0.9309, Recall: 0.9190, Precision: 0.9231, F1: 0.9202, AUC: 0.9989\n",
      "\t Testing results: Loss: 0.4863, Accuracy: 0.8543, Recall: 0.8263, Precision: 0.8495, F1: 0.8240, AUC: 0.9961\n",
      "**[Epoch 94]************************************************\n",
      "\tTraining results: Loss: 0.2378, Accuracy: 0.9331, Recall: 0.9213, Precision: 0.9263, F1: 0.9235, AUC: 0.9991\n",
      "\t Testing results: Loss: 0.2745, Accuracy: 0.9156, Recall: 0.9032, Precision: 0.9047, F1: 0.9002, AUC: 0.9987\n",
      "**[Epoch 95]************************************************\n",
      "\tTraining results: Loss: 0.2856, Accuracy: 0.9315, Recall: 0.9184, Precision: 0.9225, F1: 0.9201, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.6738, Accuracy: 0.8224, Recall: 0.7834, Precision: 0.8715, F1: 0.7891, AUC: 0.9908\n",
      "**[Epoch 96]************************************************\n",
      "\tTraining results: Loss: 0.2369, Accuracy: 0.9410, Recall: 0.9314, Precision: 0.9332, F1: 0.9320, AUC: 0.9993\n",
      "\t Testing results: Loss: 0.8725, Accuracy: 0.7402, Recall: 0.7067, Precision: 0.8039, F1: 0.7177, AUC: 0.9908\n",
      "**[Epoch 97]************************************************\n",
      "\tTraining results: Loss: 0.2752, Accuracy: 0.9257, Recall: 0.9162, Precision: 0.9224, F1: 0.9188, AUC: 0.9987\n",
      "\t Testing results: Loss: 0.5597, Accuracy: 0.8374, Recall: 0.8075, Precision: 0.8705, F1: 0.8172, AUC: 0.9923\n",
      "**[Epoch 98]************************************************\n",
      "\tTraining results: Loss: 0.2698, Accuracy: 0.9361, Recall: 0.9258, Precision: 0.9285, F1: 0.9269, AUC: 0.9992\n",
      "\t Testing results: Loss: 0.3970, Accuracy: 0.8769, Recall: 0.8496, Precision: 0.8760, F1: 0.8513, AUC: 0.9975\n",
      "**[Epoch 99]************************************************\n",
      "\tTraining results: Loss: 0.2518, Accuracy: 0.9406, Recall: 0.9332, Precision: 0.9342, F1: 0.9334, AUC: 0.9992\n",
      "\t Testing results: Loss: 0.4465, Accuracy: 0.8759, Recall: 0.8505, Precision: 0.8845, F1: 0.8492, AUC: 0.9936\n",
      "**[Epoch 100]************************************************\n",
      "\tTraining results: Loss: 0.2597, Accuracy: 0.9346, Recall: 0.9223, Precision: 0.9268, F1: 0.9239, AUC: 0.9990\n",
      "\t Testing results: Loss: 0.2607, Accuracy: 0.9189, Recall: 0.8983, Precision: 0.9172, F1: 0.9020, AUC: 0.9989\n"
     ]
    }
   ],
   "source": [
    "# Paths of data.\n",
    "dataPath = 'data/corrida1'\n",
    "savePath = '/media/pablo/Disquito/platsRuns/cnn(corrida1)'\n",
    "\n",
    "# Run name (for wanbd).\n",
    "runName = 'CNN (corrida 1)'\n",
    "# Group type, for wandb.\n",
    "config[groupType] = 'Corrida 1'\n",
    "\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\"\n",
    "#wandbID = wandb.util.generate_id()\n",
    "wandbID = '2jyap6s9'\n",
    "os.environ[\"WANDB_RUN_ID\"] = wandbID\n",
    "#print('Current wandb run id:', wandbID)\n",
    "\n",
    "# Execute.\n",
    "executeTest(dataPath, runName, savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "111, Precision: 0.9270, F1: 0.9133, AUC: 0.9992\n",
      "**[Epoch 30]************************************************\n",
      "\tTraining results: Loss: 0.2097, Accuracy: 0.9401, Recall: 0.9290, Precision: 0.9319, F1: 0.9303, AUC: 0.9992\n",
      "\t Testing results: Loss: 0.2323, Accuracy: 0.9261, Recall: 0.9138, Precision: 0.9258, F1: 0.9146, AUC: 0.9990\n",
      "**[Epoch 31]************************************************\n",
      "\tTraining results: Loss: 0.2037, Accuracy: 0.9413, Recall: 0.9305, Precision: 0.9342, F1: 0.9323, AUC: 0.9993\n",
      "\t Testing results: Loss: 0.2637, Accuracy: 0.9195, Recall: 0.9047, Precision: 0.9213, F1: 0.9082, AUC: 0.9990\n",
      "**[Epoch 32]************************************************\n",
      "\tTraining results: Loss: 0.2026, Accuracy: 0.9414, Recall: 0.9327, Precision: 0.9354, F1: 0.9339, AUC: 0.9993\n",
      "\t Testing results: Loss: 0.1823, Accuracy: 0.9433, Recall: 0.9331, Precision: 0.9407, F1: 0.9348, AUC: 0.9994\n",
      "**[Epoch 33]************************************************\n",
      "\tTraining results: Loss: 0.1929, Accuracy: 0.9433, Recall: 0.9348, Precision: 0.9362, F1: 0.9354, AUC: 0.9993\n",
      "\t Testing results: Loss: 0.1758, Accuracy: 0.9456, Recall: 0.9369, Precision: 0.9424, F1: 0.9376, AUC: 0.9994\n",
      "**[Epoch 34]************************************************\n",
      "\tTraining results: Loss: 0.1868, Accuracy: 0.9469, Recall: 0.9383, Precision: 0.9415, F1: 0.9398, AUC: 0.9994\n",
      "\t Testing results: Loss: 0.2187, Accuracy: 0.9323, Recall: 0.9208, Precision: 0.9333, F1: 0.9246, AUC: 0.9992\n",
      "**[Epoch 35]************************************************\n",
      "\tTraining results: Loss: 0.1833, Accuracy: 0.9450, Recall: 0.9366, Precision: 0.9388, F1: 0.9376, AUC: 0.9994\n",
      "\t Testing results: Loss: 0.1258, Accuracy: 0.9624, Recall: 0.9542, Precision: 0.9588, F1: 0.9559, AUC: 0.9997\n",
      "**[Epoch 36]************************************************\n",
      "\tTraining results: Loss: 0.1830, Accuracy: 0.9478, Recall: 0.9387, Precision: 0.9415, F1: 0.9400, AUC: 0.9994\n",
      "\t Testing results: Loss: 0.1821, Accuracy: 0.9422, Recall: 0.9297, Precision: 0.9452, F1: 0.9353, AUC: 0.9995\n",
      "**[Epoch 37]************************************************\n",
      "\tTraining results: Loss: 0.1864, Accuracy: 0.9458, Recall: 0.9373, Precision: 0.9412, F1: 0.9391, AUC: 0.9994\n",
      "\t Testing results: Loss: 0.3095, Accuracy: 0.9061, Recall: 0.8947, Precision: 0.9126, F1: 0.8956, AUC: 0.9986\n",
      "**[Epoch 38]************************************************\n",
      "\tTraining results: Loss: 0.1801, Accuracy: 0.9487, Recall: 0.9389, Precision: 0.9425, F1: 0.9406, AUC: 0.9994\n",
      "\t Testing results: Loss: 0.2186, Accuracy: 0.9349, Recall: 0.9163, Precision: 0.9443, F1: 0.9247, AUC: 0.9992\n",
      "**[Epoch 39]************************************************\n",
      "\tTraining results: Loss: 0.1725, Accuracy: 0.9493, Recall: 0.9410, Precision: 0.9428, F1: 0.9418, AUC: 0.9995\n",
      "\t Testing results: Loss: 0.1207, Accuracy: 0.9647, Recall: 0.9573, Precision: 0.9602, F1: 0.9583, AUC: 0.9997\n",
      "**[Epoch 40]************************************************\n",
      "\tTraining results: Loss: 0.1817, Accuracy: 0.9472, Recall: 0.9379, Precision: 0.9406, F1: 0.9391, AUC: 0.9994\n",
      "\t Testing results: Loss: 0.4402, Accuracy: 0.8727, Recall: 0.8604, Precision: 0.8891, F1: 0.8552, AUC: 0.9974\n",
      "**[Epoch 41]************************************************\n",
      "\tTraining results: Loss: 0.1755, Accuracy: 0.9501, Recall: 0.9424, Precision: 0.9461, F1: 0.9442, AUC: 0.9995\n",
      "\t Testing results: Loss: 0.1777, Accuracy: 0.9444, Recall: 0.9356, Precision: 0.9387, F1: 0.9344, AUC: 0.9994\n",
      "**[Epoch 42]************************************************\n",
      "\tTraining results: Loss: 0.1658, Accuracy: 0.9513, Recall: 0.9426, Precision: 0.9456, F1: 0.9439, AUC: 0.9995\n",
      "\t Testing results: Loss: 0.1576, Accuracy: 0.9512, Recall: 0.9408, Precision: 0.9462, F1: 0.9415, AUC: 0.9996\n",
      "**[Epoch 43]************************************************\n",
      "\tTraining results: Loss: 0.1650, Accuracy: 0.9527, Recall: 0.9442, Precision: 0.9471, F1: 0.9455, AUC: 0.9995\n",
      "\t Testing results: Loss: 0.1273, Accuracy: 0.9599, Recall: 0.9497, Precision: 0.9565, F1: 0.9521, AUC: 0.9997\n",
      "**[Epoch 44]************************************************\n",
      "\tTraining results: Loss: 0.1664, Accuracy: 0.9515, Recall: 0.9437, Precision: 0.9457, F1: 0.9446, AUC: 0.9995\n",
      "\t Testing results: Loss: 0.1273, Accuracy: 0.9609, Recall: 0.9550, Precision: 0.9555, F1: 0.9547, AUC: 0.9997\n",
      "**[Epoch 45]************************************************\n",
      "\tTraining results: Loss: 0.1605, Accuracy: 0.9533, Recall: 0.9454, Precision: 0.9474, F1: 0.9463, AUC: 0.9995\n",
      "\t Testing results: Loss: 0.1132, Accuracy: 0.9657, Recall: 0.9589, Precision: 0.9609, F1: 0.9595, AUC: 0.9997\n",
      "**[Epoch 46]************************************************\n",
      "\tTraining results: Loss: 0.1580, Accuracy: 0.9533, Recall: 0.9452, Precision: 0.9475, F1: 0.9463, AUC: 0.9995\n",
      "\t Testing results: Loss: 0.1319, Accuracy: 0.9587, Recall: 0.9511, Precision: 0.9547, F1: 0.9507, AUC: 0.9997\n",
      "**[Epoch 47]************************************************\n",
      "\tTraining results: Loss: 0.1581, Accuracy: 0.9544, Recall: 0.9459, Precision: 0.9485, F1: 0.9471, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1207, Accuracy: 0.9622, Recall: 0.9527, Precision: 0.9614, F1: 0.9564, AUC: 0.9997\n",
      "**[Epoch 48]************************************************\n",
      "\tTraining results: Loss: 0.1563, Accuracy: 0.9547, Recall: 0.9470, Precision: 0.9494, F1: 0.9481, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1243, Accuracy: 0.9622, Recall: 0.9519, Precision: 0.9608, F1: 0.9532, AUC: 0.9997\n",
      "**[Epoch 49]************************************************\n",
      "\tTraining results: Loss: 0.1538, Accuracy: 0.9565, Recall: 0.9493, Precision: 0.9515, F1: 0.9504, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1487, Accuracy: 0.9527, Recall: 0.9458, Precision: 0.9514, F1: 0.9473, AUC: 0.9996\n",
      "**[Epoch 50]************************************************\n",
      "\tTraining results: Loss: 0.1461, Accuracy: 0.9594, Recall: 0.9530, Precision: 0.9540, F1: 0.9534, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1285, Accuracy: 0.9609, Recall: 0.9613, Precision: 0.9612, F1: 0.9603, AUC: 0.9998\n",
      "**[Epoch 51]************************************************\n",
      "\tTraining results: Loss: 0.1521, Accuracy: 0.9572, Recall: 0.9502, Precision: 0.9527, F1: 0.9514, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1313, Accuracy: 0.9591, Recall: 0.9489, Precision: 0.9594, F1: 0.9526, AUC: 0.9996\n",
      "**[Epoch 52]************************************************\n",
      "\tTraining results: Loss: 0.1535, Accuracy: 0.9540, Recall: 0.9449, Precision: 0.9486, F1: 0.9466, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1797, Accuracy: 0.9410, Recall: 0.9359, Precision: 0.9380, F1: 0.9350, AUC: 0.9995\n",
      "**[Epoch 53]************************************************\n",
      "\tTraining results: Loss: 0.1501, Accuracy: 0.9584, Recall: 0.9521, Precision: 0.9538, F1: 0.9529, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1727, Accuracy: 0.9485, Recall: 0.9347, Precision: 0.9509, F1: 0.9402, AUC: 0.9996\n",
      "**[Epoch 54]************************************************\n",
      "\tTraining results: Loss: 0.1450, Accuracy: 0.9579, Recall: 0.9506, Precision: 0.9534, F1: 0.9519, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1323, Accuracy: 0.9593, Recall: 0.9503, Precision: 0.9561, F1: 0.9505, AUC: 0.9997\n",
      "**[Epoch 55]************************************************\n",
      "\tTraining results: Loss: 0.1494, Accuracy: 0.9561, Recall: 0.9485, Precision: 0.9507, F1: 0.9496, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1156, Accuracy: 0.9651, Recall: 0.9592, Precision: 0.9619, F1: 0.9600, AUC: 0.9997\n",
      "**[Epoch 56]************************************************\n",
      "\tTraining results: Loss: 0.1459, Accuracy: 0.9578, Recall: 0.9510, Precision: 0.9529, F1: 0.9519, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.2256, Accuracy: 0.9281, Recall: 0.9088, Precision: 0.9325, F1: 0.9129, AUC: 0.9992\n",
      "**[Epoch 57]************************************************\n",
      "\tTraining results: Loss: 0.1517, Accuracy: 0.9568, Recall: 0.9501, Precision: 0.9518, F1: 0.9509, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.1799, Accuracy: 0.9406, Recall: 0.9236, Precision: 0.9375, F1: 0.9275, AUC: 0.9995\n",
      "**[Epoch 58]************************************************\n",
      "\tTraining results: Loss: 0.1395, Accuracy: 0.9609, Recall: 0.9538, Precision: 0.9559, F1: 0.9548, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1624, Accuracy: 0.9494, Recall: 0.9401, Precision: 0.9477, F1: 0.9414, AUC: 0.9996\n",
      "**[Epoch 59]************************************************\n",
      "\tTraining results: Loss: 0.1413, Accuracy: 0.9609, Recall: 0.9538, Precision: 0.9567, F1: 0.9552, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.3866, Accuracy: 0.8987, Recall: 0.8896, Precision: 0.9177, F1: 0.8902, AUC: 0.9954\n",
      "**[Epoch 60]************************************************\n",
      "\tTraining results: Loss: 0.1326, Accuracy: 0.9625, Recall: 0.9571, Precision: 0.9583, F1: 0.9576, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1505, Accuracy: 0.9532, Recall: 0.9484, Precision: 0.9473, F1: 0.9463, AUC: 0.9996\n",
      "**[Epoch 61]************************************************\n",
      "\tTraining results: Loss: 0.1337, Accuracy: 0.9624, Recall: 0.9553, Precision: 0.9585, F1: 0.9568, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1146, Accuracy: 0.9648, Recall: 0.9559, Precision: 0.9628, F1: 0.9582, AUC: 0.9998\n",
      "**[Epoch 62]************************************************\n",
      "\tTraining results: Loss: 0.1371, Accuracy: 0.9602, Recall: 0.9541, Precision: 0.9555, F1: 0.9547, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1275, Accuracy: 0.9615, Recall: 0.9511, Precision: 0.9606, F1: 0.9548, AUC: 0.9997\n",
      "**[Epoch 63]************************************************\n",
      "\tTraining results: Loss: 0.1364, Accuracy: 0.9596, Recall: 0.9527, Precision: 0.9540, F1: 0.9533, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1019, Accuracy: 0.9691, Recall: 0.9653, Precision: 0.9654, F1: 0.9649, AUC: 0.9998\n",
      "**[Epoch 64]************************************************\n",
      "\tTraining results: Loss: 0.1316, Accuracy: 0.9606, Recall: 0.9545, Precision: 0.9562, F1: 0.9553, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1092, Accuracy: 0.9657, Recall: 0.9580, Precision: 0.9629, F1: 0.9599, AUC: 0.9998\n",
      "**[Epoch 65]************************************************\n",
      "\tTraining results: Loss: 0.1369, Accuracy: 0.9612, Recall: 0.9541, Precision: 0.9554, F1: 0.9547, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1919, Accuracy: 0.9385, Recall: 0.9226, Precision: 0.9365, F1: 0.9262, AUC: 0.9994\n",
      "**[Epoch 66]************************************************\n",
      "\tTraining results: Loss: 0.1391, Accuracy: 0.9598, Recall: 0.9519, Precision: 0.9552, F1: 0.9535, AUC: 0.9996\n",
      "\t Testing results: Loss: 0.0984, Accuracy: 0.9692, Recall: 0.9643, Precision: 0.9652, F1: 0.9642, AUC: 0.9998\n",
      "**[Epoch 67]************************************************\n",
      "\tTraining results: Loss: 0.1316, Accuracy: 0.9630, Recall: 0.9567, Precision: 0.9589, F1: 0.9578, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1194, Accuracy: 0.9626, Recall: 0.9534, Precision: 0.9617, F1: 0.9564, AUC: 0.9998\n",
      "**[Epoch 68]************************************************\n",
      "\tTraining results: Loss: 0.1313, Accuracy: 0.9625, Recall: 0.9563, Precision: 0.9571, F1: 0.9567, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1002, Accuracy: 0.9696, Recall: 0.9638, Precision: 0.9650, F1: 0.9641, AUC: 0.9998\n",
      "**[Epoch 69]************************************************\n",
      "\tTraining results: Loss: 0.1282, Accuracy: 0.9637, Recall: 0.9579, Precision: 0.9591, F1: 0.9585, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0939, Accuracy: 0.9761, Recall: 0.9706, Precision: 0.9733, F1: 0.9719, AUC: 0.9998\n",
      "**[Epoch 70]************************************************\n",
      "\tTraining results: Loss: 0.1267, Accuracy: 0.9637, Recall: 0.9578, Precision: 0.9589, F1: 0.9583, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1505, Accuracy: 0.9532, Recall: 0.9549, Precision: 0.9485, F1: 0.9492, AUC: 0.9997\n",
      "**[Epoch 71]************************************************\n",
      "\tTraining results: Loss: 0.1268, Accuracy: 0.9626, Recall: 0.9562, Precision: 0.9574, F1: 0.9568, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1086, Accuracy: 0.9652, Recall: 0.9576, Precision: 0.9627, F1: 0.9592, AUC: 0.9998\n",
      "**[Epoch 72]************************************************\n",
      "\tTraining results: Loss: 0.1272, Accuracy: 0.9632, Recall: 0.9568, Precision: 0.9584, F1: 0.9576, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0922, Accuracy: 0.9731, Recall: 0.9680, Precision: 0.9702, F1: 0.9689, AUC: 0.9999\n",
      "**[Epoch 73]************************************************\n",
      "\tTraining results: Loss: 0.1260, Accuracy: 0.9646, Recall: 0.9590, Precision: 0.9603, F1: 0.9596, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1223, Accuracy: 0.9616, Recall: 0.9553, Precision: 0.9569, F1: 0.9550, AUC: 0.9998\n",
      "**[Epoch 74]************************************************\n",
      "\tTraining results: Loss: 0.1256, Accuracy: 0.9641, Recall: 0.9575, Precision: 0.9594, F1: 0.9584, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0873, Accuracy: 0.9743, Recall: 0.9689, Precision: 0.9709, F1: 0.9697, AUC: 0.9998\n",
      "**[Epoch 75]************************************************\n",
      "\tTraining results: Loss: 0.1206, Accuracy: 0.9665, Recall: 0.9609, Precision: 0.9620, F1: 0.9614, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1599, Accuracy: 0.9475, Recall: 0.9398, Precision: 0.9459, F1: 0.9379, AUC: 0.9996\n",
      "**[Epoch 76]************************************************\n",
      "\tTraining results: Loss: 0.1237, Accuracy: 0.9639, Recall: 0.9576, Precision: 0.9605, F1: 0.9590, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.1076, Accuracy: 0.9665, Recall: 0.9595, Precision: 0.9608, F1: 0.9591, AUC: 0.9997\n",
      "**[Epoch 77]************************************************\n",
      "\tTraining results: Loss: 0.1205, Accuracy: 0.9661, Recall: 0.9606, Precision: 0.9616, F1: 0.9610, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0942, Accuracy: 0.9712, Recall: 0.9647, Precision: 0.9688, F1: 0.9664, AUC: 0.9998\n",
      "**[Epoch 78]************************************************\n",
      "\tTraining results: Loss: 0.1210, Accuracy: 0.9648, Recall: 0.9581, Precision: 0.9600, F1: 0.9590, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0894, Accuracy: 0.9743, Recall: 0.9713, Precision: 0.9707, F1: 0.9707, AUC: 0.9998\n",
      "**[Epoch 79]************************************************\n",
      "\tTraining results: Loss: 0.1184, Accuracy: 0.9678, Recall: 0.9628, Precision: 0.9640, F1: 0.9634, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.1542, Accuracy: 0.9496, Recall: 0.9391, Precision: 0.9507, F1: 0.9432, AUC: 0.9996\n",
      "**[Epoch 80]************************************************\n",
      "\tTraining results: Loss: 0.1231, Accuracy: 0.9628, Recall: 0.9559, Precision: 0.9578, F1: 0.9568, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0792, Accuracy: 0.9753, Recall: 0.9701, Precision: 0.9721, F1: 0.9709, AUC: 0.9999\n",
      "**[Epoch 81]************************************************\n",
      "\tTraining results: Loss: 0.1154, Accuracy: 0.9671, Recall: 0.9610, Precision: 0.9630, F1: 0.9619, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0868, Accuracy: 0.9731, Recall: 0.9680, Precision: 0.9691, F1: 0.9682, AUC: 0.9998\n",
      "**[Epoch 82]************************************************\n",
      "\tTraining results: Loss: 0.1122, Accuracy: 0.9677, Recall: 0.9627, Precision: 0.9637, F1: 0.9632, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0880, Accuracy: 0.9731, Recall: 0.9675, Precision: 0.9705, F1: 0.9686, AUC: 0.9999\n",
      "**[Epoch 83]************************************************\n",
      "\tTraining results: Loss: 0.1173, Accuracy: 0.9664, Recall: 0.9615, Precision: 0.9628, F1: 0.9621, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.1157, Accuracy: 0.9632, Recall: 0.9582, Precision: 0.9614, F1: 0.9589, AUC: 0.9998\n",
      "**[Epoch 84]************************************************\n",
      "\tTraining results: Loss: 0.1178, Accuracy: 0.9664, Recall: 0.9614, Precision: 0.9633, F1: 0.9623, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.2205, Accuracy: 0.9367, Recall: 0.9204, Precision: 0.9526, F1: 0.9312, AUC: 0.9988\n",
      "**[Epoch 85]************************************************\n",
      "\tTraining results: Loss: 0.1147, Accuracy: 0.9673, Recall: 0.9620, Precision: 0.9640, F1: 0.9629, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.2502, Accuracy: 0.9241, Recall: 0.9178, Precision: 0.9239, F1: 0.9153, AUC: 0.9992\n",
      "**[Epoch 86]************************************************\n",
      "\tTraining results: Loss: 0.1128, Accuracy: 0.9658, Recall: 0.9607, Precision: 0.9617, F1: 0.9612, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.1372, Accuracy: 0.9562, Recall: 0.9458, Precision: 0.9537, F1: 0.9487, AUC: 0.9996\n",
      "**[Epoch 87]************************************************\n",
      "\tTraining results: Loss: 0.1104, Accuracy: 0.9682, Recall: 0.9634, Precision: 0.9644, F1: 0.9638, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0949, Accuracy: 0.9701, Recall: 0.9624, Precision: 0.9671, F1: 0.9637, AUC: 0.9998\n",
      "**[Epoch 88]************************************************\n",
      "\tTraining results: Loss: 0.1117, Accuracy: 0.9695, Recall: 0.9643, Precision: 0.9654, F1: 0.9648, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.1124, Accuracy: 0.9663, Recall: 0.9579, Precision: 0.9636, F1: 0.9601, AUC: 0.9997\n",
      "**[Epoch 89]************************************************\n",
      "\tTraining results: Loss: 0.1178, Accuracy: 0.9663, Recall: 0.9603, Precision: 0.9622, F1: 0.9612, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0918, Accuracy: 0.9708, Recall: 0.9660, Precision: 0.9683, F1: 0.9669, AUC: 0.9998\n",
      "**[Epoch 90]************************************************\n",
      "\tTraining results: Loss: 0.1137, Accuracy: 0.9671, Recall: 0.9620, Precision: 0.9626, F1: 0.9622, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0966, Accuracy: 0.9694, Recall: 0.9626, Precision: 0.9681, F1: 0.9647, AUC: 0.9998\n",
      "**[Epoch 91]************************************************\n",
      "\tTraining results: Loss: 0.1186, Accuracy: 0.9656, Recall: 0.9599, Precision: 0.9623, F1: 0.9610, AUC: 0.9997\n",
      "\t Testing results: Loss: 0.0808, Accuracy: 0.9771, Recall: 0.9730, Precision: 0.9730, F1: 0.9728, AUC: 0.9998\n",
      "**[Epoch 92]************************************************\n",
      "\tTraining results: Loss: 0.1056, Accuracy: 0.9701, Recall: 0.9650, Precision: 0.9663, F1: 0.9656, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0839, Accuracy: 0.9741, Recall: 0.9707, Precision: 0.9706, F1: 0.9703, AUC: 0.9999\n",
      "**[Epoch 93]************************************************\n",
      "\tTraining results: Loss: 0.1036, Accuracy: 0.9698, Recall: 0.9644, Precision: 0.9658, F1: 0.9650, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0728, Accuracy: 0.9777, Recall: 0.9728, Precision: 0.9746, F1: 0.9736, AUC: 0.9999\n",
      "**[Epoch 94]************************************************\n",
      "\tTraining results: Loss: 0.1049, Accuracy: 0.9698, Recall: 0.9651, Precision: 0.9670, F1: 0.9660, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0803, Accuracy: 0.9759, Recall: 0.9705, Precision: 0.9736, F1: 0.9717, AUC: 0.9999\n",
      "**[Epoch 95]************************************************\n",
      "\tTraining results: Loss: 0.1080, Accuracy: 0.9679, Recall: 0.9627, Precision: 0.9640, F1: 0.9633, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0834, Accuracy: 0.9748, Recall: 0.9702, Precision: 0.9717, F1: 0.9707, AUC: 0.9998\n",
      "**[Epoch 96]************************************************\n",
      "\tTraining results: Loss: 0.1122, Accuracy: 0.9681, Recall: 0.9626, Precision: 0.9644, F1: 0.9635, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.1701, Accuracy: 0.9460, Recall: 0.9346, Precision: 0.9436, F1: 0.9371, AUC: 0.9994\n",
      "**[Epoch 97]************************************************\n",
      "\tTraining results: Loss: 0.1064, Accuracy: 0.9700, Recall: 0.9649, Precision: 0.9667, F1: 0.9658, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0854, Accuracy: 0.9726, Recall: 0.9666, Precision: 0.9691, F1: 0.9675, AUC: 0.9998\n",
      "**[Epoch 98]************************************************\n",
      "\tTraining results: Loss: 0.1067, Accuracy: 0.9685, Recall: 0.9628, Precision: 0.9643, F1: 0.9635, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0870, Accuracy: 0.9727, Recall: 0.9693, Precision: 0.9684, F1: 0.9686, AUC: 0.9998\n",
      "**[Epoch 99]************************************************\n",
      "\tTraining results: Loss: 0.1008, Accuracy: 0.9717, Recall: 0.9668, Precision: 0.9681, F1: 0.9674, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.0860, Accuracy: 0.9738, Recall: 0.9688, Precision: 0.9698, F1: 0.9690, AUC: 0.9998\n",
      "**[Epoch 100]************************************************\n",
      "\tTraining results: Loss: 0.1105, Accuracy: 0.9715, Recall: 0.9669, Precision: 0.9670, F1: 0.9670, AUC: 0.9998\n",
      "\t Testing results: Loss: 0.1320, Accuracy: 0.9578, Recall: 0.9443, Precision: 0.9625, F1: 0.9498, AUC: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# Paths of data.\n",
    "dataPath = 'data/corrida2'\n",
    "savePath = '/media/pablo/Disquito/platsRuns/cnn(corrida2)'\n",
    "\n",
    "# Run name (for wanbd).\n",
    "runName = 'CNN (corrida 2)'\n",
    "# Group type, for wandb.\n",
    "config[groupType] = 'Corrida 2'\n",
    "\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\"\n",
    "#wandbID = wandb.util.generate_id()\n",
    "wandbID = '14ae4s7w'\n",
    "os.environ[\"WANDB_RUN_ID\"] = wandbID\n",
    "#print('Current wandb run id:', wandbID)\n",
    "\n",
    "# Execute.\n",
    "executeTest(dataPath, runName, savePath)"
   ]
  }
 ]
}