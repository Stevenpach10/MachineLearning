{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea 2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "# Tarea 2\n",
        "Integrantes:\n",
        "- Pablo Josué Brenes Jiménez - 2016250460\n",
        "- Steven Andrey Pacheco Portuguez - 2016125971\n",
        "- Luis José Castillo Valverde - 2016094804\n",
        "\n",
        "Movimos todos los archivos a celdas de jupyter. En las celdas de documentación previas a cada celda de código describimos los cambios o funciones agregadas. Al final del jupyter se encuentran tres muestras de ejecución, estas son:\n",
        "- [x] Nuestra prueba de regresión, usando tanh y MSE.\n",
        "- [x] Una prueba de clasificación utilizando tanh.\n",
        "- [x] La clasificación original que se encontraba en el main (muestra de que los cambios no afectaron el funcionamiento)."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e83UApwMCzIf"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjmsXC3hCwTT"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import tkinter\n",
        "import csv\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUH_wSSXHKew"
      },
      "source": [
        "# Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzvHcvBIHL0H"
      },
      "source": [
        "## download_iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_VNjxQnHPfS"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "filename = 'iris.ds'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(iris, outfile)\n",
        "outfile.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4AFrx2DHY1Q"
      },
      "source": [
        "## download_nmist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Zi-qmxHY8m"
      },
      "source": [
        "# mnist = fetch_openml('mnist_784', cache=False)\n",
        "# filename = 'nmist.ds'\n",
        "# outfile = open(filename,'wb')\n",
        "# pickle.dump(mnist, outfile)\n",
        "# outfile.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgCMttd1DtNh"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG_ZwpdkEOTV"
      },
      "source": [
        "## config_iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVlDDvG9ENy9"
      },
      "source": [
        "class Config_iris:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    #hyperparameters\n",
        "    self.dataset_path = r\"iris.ds\"\n",
        "    self.batch_size = 10\n",
        "    self.validate_every_no_of_batches = 80\n",
        "    self.epochs = 1000\n",
        "    self.input_size = 4\n",
        "    self.output_size = 3\n",
        "    self.hidden_shapes = [10]\n",
        "    self.lr = 0.0085\n",
        "    self.has_dropout=True\n",
        "    self.dropout_perc=0.5\n",
        "    self.output_log = r\"iris_log.txt\"\n",
        "    #iris dataset\n",
        "    with open(self.dataset_path, \"rb\") as input_file:\n",
        "        self.iris_dataset = pickle.load(input_file)\n",
        "        self.x = np.array(self.iris_dataset['data'])\n",
        "        self.x = self.x / np.max(self.x, axis=0)\n",
        "        self.y = np.array(self.iris_dataset['target'])\n",
        "    self.data = dataset(self.x, self.y, self.batch_size)\n",
        "    self.splitter = dataset_splitter(self.data.compl_x, self.data.compl_y, self.batch_size, 0.6, 0.2)\n",
        "    self.ds_train = self.splitter.ds_train\n",
        "    self.ds_val = self.splitter.ds_val\n",
        "    self.ds_test = self.splitter.ds_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbgQi6mVFCqT"
      },
      "source": [
        "## config_mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi8M2DORFG9z"
      },
      "source": [
        "class Config_mnist:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    #hyperparameters\n",
        "    self.dataset_path = r\"nmist.ds\"\n",
        "    self.batch_size = 32\n",
        "    self.validate_every_no_of_batches = 600\n",
        "    self.epochs = 10\n",
        "    self.input_size = 784\n",
        "    self.output_size = 10\n",
        "    self.hidden_shapes = [512, 128]\n",
        "    self.lr = 0.0085\n",
        "    self.has_dropout=True\n",
        "    self.dropout_perc=0.5\n",
        "    self.output_log = r\"nmist_log.txt\"\n",
        "    with open(self.dataset_path, \"rb\") as input_file:\n",
        "        self.nmist = pickle.load(input_file)\n",
        "        self.x = np.array(self.nmist.data)\n",
        "        self.x = self.x / 255.0\n",
        "        self.y = np.array(self.nmist.target).astype(np.int)\n",
        "        #print(x)\n",
        "    self.data = dataset(self.x, self.y, self.batch_size)\n",
        "    self.splitter = dataset_splitter(self.data.compl_x, self.data.compl_y, self.batch_size, 0.8, 0.2)\n",
        "    self.ds_train = self.splitter.ds_train\n",
        "    self.ds_val = self.splitter.ds_val\n",
        "    self.ds_test = self.splitter.ds_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTS4ROXtFXCn"
      },
      "source": [
        "## config_xor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f72NR39OFXZd"
      },
      "source": [
        "class Config_xor:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    #hyperparameters\n",
        "    self.batch_size = 2\n",
        "    self.validate_every_no_of_batches = 8\n",
        "    self.epochs = 2000\n",
        "    self.input_size = 2\n",
        "    self.output_size = 2\n",
        "    self.hidden_shapes = [2]\n",
        "    self.lr = 0.085\n",
        "    self.has_dropout=False\n",
        "    self.dropout_perc=0.5\n",
        "    self.output_log = \"xor_log.txt\"\n",
        "    #XOR dataset - baseline to check backprop, update and forward calculations\n",
        "    self.ds_train = dataset(np.array([[0,0], [0,1], [1,0], [1,1]]), np.array([0,1,1,0]),  self.batch_size)\n",
        "    self.ds_test = dataset(np.array([[0,0], [0,1], [1,0], [1,1]]), np.array([0,1,1,0]),  self.batch_size)\n",
        "    self.ds_val = dataset(np.array([[0,0], [0,1], [1,0], [1,1]]), np.array([0,1,1,0]),  self.batch_size)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMbJ06sT5RSp"
      },
      "source": [
        "## config_sin\n",
        "Esta es la clase que agregamos con los parámetros para aproximar la función seno, también está la función que genera estos datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O9NJoHi5Wt1"
      },
      "source": [
        "def sinFunction():\n",
        "    x = np.linspace(0.0, 2.0 * np.pi, 800).reshape(-1, 1)\n",
        "    y = np.sin(x)\n",
        "\n",
        "    return x , y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjmEQud45Szr"
      },
      "source": [
        "class Config_sin:\n",
        "  \n",
        "  def __init__(self):\n",
        "\n",
        "    #hyperparameters\n",
        "    self.batch_size = 64\n",
        "    self.validate_every_no_of_batches = 300\n",
        "    self.epochs = 10000\n",
        "    self.input_size = 1\n",
        "    self.output_size = 1\n",
        "    self.hidden_shapes = [100, 100, 100]\n",
        "    self.lr = 0.05\n",
        "    self.has_dropout=False\n",
        "    self.dropout_perc=0.5\n",
        "    self.output_log = r\"sin_log.txt\"\n",
        "\n",
        "    self.x, self.y = sinFunction()\n",
        "    self.data = dataset(self.x, self.y, self.batch_size)\n",
        "    self.splitter = dataset_splitter(self.data.compl_x, self.data.compl_y, self.batch_size, 0.6, 0.2)\n",
        "    self.ds_train = self.splitter.ds_train\n",
        "    self.ds_val = self.splitter.ds_val\n",
        "    self.ds_test = self.splitter.ds_test"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMRg_NNPECzh"
      },
      "source": [
        "## config\n",
        "Este archivo la modificamos para agregar el caso de SIN al enumerado (los datos los generamos a partir de una función seno)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwt5tXwLD2V6"
      },
      "source": [
        "class ConfigEnum:\n",
        "    XOR, IRIS, MNIST, SIN = range(4)\n",
        "\n",
        "#factory-like class which produces different configs for each dataset tested\n",
        "class hyperparams():\n",
        "\n",
        "    def __init__(self, config_enum=1): #default is iris based on reqs\n",
        "        if config_enum==ConfigEnum.XOR:\n",
        "            config = Config_xor()\n",
        "        elif config_enum==ConfigEnum.IRIS:\n",
        "            config = Config_iris()\n",
        "        elif config_enum==ConfigEnum.SIN:\n",
        "            config = Config_sin()\n",
        "        else:\n",
        "            config = Config_mnist()\n",
        "        self.config = config\n",
        "        self.batch_size = config.batch_size\n",
        "        self.validate_every_no_of_batches = config.validate_every_no_of_batches\n",
        "        self.epochs = config.epochs\n",
        "        self.input_size = config.input_size\n",
        "        self.output_size = config.output_size\n",
        "        self.hidden_shapes = config.hidden_shapes\n",
        "        self.lr = config.lr\n",
        "        self.has_dropout= config.has_dropout\n",
        "        self.dropout_perc= config.dropout_perc\n",
        "        self.output_log = config.output_log\n",
        "        self.ds_train = config.ds_train\n",
        "        self.ds_test = config.ds_test\n",
        "        self.ds_val = config.ds_val\n",
        "\n",
        "    def split_again(self, perc_train, perc_val):\n",
        "        self.ds_train, self.ds_val, self.ds_test = self.config.splitter.split(self.batch_size, perc_train, perc_val)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtzFThfAFiux"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I69aNz5Fi8e"
      },
      "source": [
        "#shuffles data and labels keeping indexes\n",
        "def _shuffle(x, y):\n",
        "    assert(len(x) == len(y)), \"Make sure data and labels have the same lenght!\"\n",
        "    rand_indexes = np.random.permutation(len(x))\n",
        "    return x[rand_indexes], y[rand_indexes]\n",
        "\n",
        "#represents a dataset, useful for val dataset, train dataset and test dataset.\n",
        "class dataset():\n",
        "    def __init__(self, x, y, batch_size):\n",
        "        #assert(len(y) % batch_size == 0), \"Make sure batch size divides number of items perfectly!\"\n",
        "        self.compl_x = x[:]\n",
        "        self.compl_y = y[:]\n",
        "        self.batch_size = batch_size\n",
        "        self.reset()\n",
        "        self.size = len(self.compl_y)\n",
        "\n",
        "    def shapes(self):\n",
        "        return ( self.compl_x.shape, self.compl_y.shape )\n",
        "\n",
        "    def view(self):\n",
        "        print(self.compl_x, self.compl_y)\n",
        "\n",
        "    #iterate over the dataset\n",
        "    def next(self):\n",
        "        if self.left_items < self.batch_size:\n",
        "            x = self.x[self.current:]\n",
        "            y = self.y[self.current:]\n",
        "            self.current += len(self.x)\n",
        "            self.left_items = 0\n",
        "            return x, y\n",
        "        else:\n",
        "            x = self.x[self.current:self.current+self.batch_size]\n",
        "            y = self.y[self.current:self.current+self.batch_size]\n",
        "            self.current += self.batch_size\n",
        "            self.left_items -= self.batch_size\n",
        "            return x, y\n",
        "\n",
        "    def iter_done(self):\n",
        "        return self.left_items == 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = self.compl_x[:]\n",
        "        self.y = self.compl_y[:]\n",
        "        self.x, self.y = _shuffle(self.x, self.y)\n",
        "        self.current = 0\n",
        "        self.left_items = len(self.compl_y)\n",
        "\n",
        "#splits a complete dataset into 3 subsets for train, val and test, by percentage\n",
        "class dataset_splitter():\n",
        "    def __init__(self, x, y, batch_size, perc_train=0.8, perc_val=0.2):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.split(batch_size, perc_train, perc_val)\n",
        "\n",
        "    def _split_by_limits(self, batch_size, train_limit, val_limit):\n",
        "        self.ds_train = dataset(self.x[:train_limit], self.y[:train_limit], batch_size)\n",
        "        self.ds_train.reset()\n",
        "        self.ds_val = dataset(self.x[train_limit:val_limit], self.y[train_limit:val_limit], batch_size)\n",
        "        self.ds_val.reset()\n",
        "        self.ds_test = dataset(self.x[val_limit:], self.y[val_limit:], batch_size)\n",
        "        self.ds_test.reset()\n",
        "\n",
        "    def split(self, batch_size, perc_train, perc_val):\n",
        "        self.x, self.y = _shuffle(self.x, self.y)\n",
        "        n = len(self.x)\n",
        "        train_limit = int(n * perc_train)\n",
        "        temp = int(train_limit * (1.0 - perc_val))\n",
        "        val_limit = train_limit - temp\n",
        "        train_limit = temp\n",
        "        #print(n, train_limit, val_limit)\n",
        "        self._split_by_limits(batch_size, train_limit, train_limit+val_limit)\n",
        "        print(self.ds_train.shapes(), self.ds_val.shapes(), self.ds_test.shapes())\n",
        "        return self.ds_train, self.ds_val, self.ds_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ8FSl7kDxc3"
      },
      "source": [
        "# Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3EcdkT3G5YX"
      },
      "source": [
        "## dumps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTZ5Pc8JD5d0"
      },
      "source": [
        "class nnlogger():\n",
        "    def __init__(self, output_file, header):\n",
        "        self.csv_file = open(output_file, \"w\")\n",
        "        self.writer = csv.writer(self.csv_file, delimiter=',')\n",
        "        self.writer.writerow( header )\n",
        "\n",
        "    def write(self, line):\n",
        "        self.writer.writerow( line )\n",
        "\n",
        "    def close(self):\n",
        "        self.csv_file.close()\n",
        "\n",
        "class historian():\n",
        "\n",
        "    def __init__(self, figsize=(8,6)):\n",
        "        self.iter = []\n",
        "        self.acc =  []\n",
        "        self.loss = []\n",
        "\n",
        "    def add(self, iter, loss, accuracy):\n",
        "        self.iter += [ iter ]\n",
        "        self.acc +=  [ accuracy ]\n",
        "        self.loss += [ loss ]\n",
        "\n",
        "\n",
        "class nnplotter():\n",
        "\n",
        "    @classmethod\n",
        "    def view(cls, val_history, train_history):\n",
        "        ax = plt.subplot(2, 1, 1)\n",
        "        ax.plot(val_history.iter, val_history.loss, 'b--', label=\"val\")\n",
        "        ax.plot(train_history.iter, train_history.loss, 'r--', label=\"train\")\n",
        "        plt.ylabel(\"loss\")\n",
        "        ax.legend()\n",
        "\n",
        "        ax2 = plt.subplot(2, 1, 2)\n",
        "        ax2.plot(val_history.iter, val_history.acc, 'b--', label=\"val\")\n",
        "        ax2.plot(train_history.iter, train_history.acc, 'r--', label= \"train\")\n",
        "        plt.ylabel(\"accuracy\")\n",
        "        plt.xlabel(\"iteration\")\n",
        "        ax2.legend()\n",
        "\n",
        "        plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inWjriVEDzj1"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Hkqy70GLCX"
      },
      "source": [
        "## funcs\n",
        "Acá es dónde agregamos las funciones nuevas solicitadas, tanh, la derivada de tanh, MSE y la derivada de MSE para los cálculos, están comentadas, al final del archivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v-xRv3OGLVa"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def sigmoid_grad(s):\n",
        "    return s * (1.0 - s)\n",
        "\n",
        "def relu(x):\n",
        "    return x * (x > 0)\n",
        "\n",
        "def  relu_grad(x):\n",
        "    return 1.0 * (x > 0)\n",
        "\n",
        "#with numerical stability\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "def logloss(x, y):\n",
        "    probs = softmax(x)\n",
        "    return probs, -y * np.log(probs)\n",
        "\n",
        "def logloss_grad(probs, y):\n",
        "    probs[:,y] -= 1.0\n",
        "    return probs\n",
        "\n",
        "def batch_hits(x, y):\n",
        "    return np.sum(np.argmax(x, axis=1) == y)\n",
        "\n",
        "# Cross Entropy Loss\n",
        "def crossEntropyLoss(x, y):\n",
        "    return -np.mean(np.sum(y * np.log(x + 1e-15), axis=1))\n",
        "\n",
        "# CrossEntropyLoss and Softmax derivates\n",
        "def crossEntropySoftmax(x, y):\n",
        "    return y - x\n",
        "\n",
        "########\n",
        "# Tanh #\n",
        "########\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "############\n",
        "# Tanh dev #\n",
        "############\n",
        "def tanh_grad(s):\n",
        "    return 1 - np.tanh(s) ** 2\n",
        "\n",
        "#######\n",
        "# MSE #\n",
        "#######\n",
        "def MSE(x, y):\n",
        "    return 1/x.shape[0] * np.sum((x - y) ** 2)\n",
        "\n",
        "###########\n",
        "# MSE dev #\n",
        "###########\n",
        "def MSE_grad(y, probs):\n",
        "    res = 2/y.shape[0] * (y - probs)\n",
        "    return res"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o3KPBn2GtbT"
      },
      "source": [
        "## op"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41o91ZBKGwYa"
      },
      "source": [
        "#used as baseline for any differenciable layer\n",
        "class op():\n",
        "\n",
        "    def __init__(self, i_size, o_size):\n",
        "        self.i_size = i_size\n",
        "        self.o_size = o_size\n",
        "        self._xavier_init()\n",
        "        self.o = np.zeros(o_size)\n",
        "        self.x = None #will be assigned during forward\n",
        "        self.grads = np.zeros((o_size, i_size))\n",
        "\n",
        "    def _xavier_init(self):\n",
        "        self.W = np.random.randn(self.i_size, self.o_size) / np.sqrt(self.i_size)\n",
        "        self.b = np.random.randn()\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "    def backward(self, prev):\n",
        "        pass\n",
        "\n",
        "    def update(self, lr):\n",
        "        self.W += lr * np.dot(self.x.T, self.grads)\n",
        "        self.b += lr * np.mean(self.grads, axis = 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYIoNGmEFxF4"
      },
      "source": [
        "## dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viyGvfU7D59H"
      },
      "source": [
        "class dense(op):\n",
        "\n",
        "    def __init__(self, i_size, o_size, func_acti, func_acti_grad):\n",
        "        super(dense, self).__init__(i_size, o_size)\n",
        "        self.func_acti = func_acti\n",
        "        self.func_acti_grad = func_acti_grad\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        self.o = self.func_acti(np.dot(x, self.W) + self.b)\n",
        "        return self.o\n",
        "\n",
        "    def backward(self, prev):\n",
        "        self.grads = self.func_acti_grad(prev.x) * np.dot(prev.grads, prev.W.T)\n",
        "\n",
        "    def dropout(self, prob):\n",
        "        self.mask = np.random.binomial(size=self.o.shape[1], n=1, p=1-prob)\n",
        "        return self.mask"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDVQIECoGTYk"
      },
      "source": [
        "## loss_layer\n",
        "Reconstruimos esta clase para que sea modular, se puede pasar por parámetro las funciones de activación y de costo a utilizar durante la instanciación. Puede ver como entran por parámetro y como se asignan las nuevas funciones, para el caso del código original que trabaja con entropía cruzada mantuvimos un caso especial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H3F0Nn5GTh-"
      },
      "source": [
        "#implements a log loss layer\n",
        "class loss_layer(op):\n",
        "\n",
        "    def __init__(self, i_size, o_size, func_acti, func_acti_grad, func_loss, func_loss_grad):\n",
        "        super(loss_layer, self).__init__(i_size, o_size)\n",
        "\n",
        "        self.func_acti = func_acti\n",
        "        self.func_acti_grad = func_acti_grad\n",
        "        self.func_loss = func_loss\n",
        "        self.func_loss_grad = func_loss_grad\n",
        "        if func_acti == softmax:\n",
        "            self.func_backward = crossEntropySoftmax\n",
        "        else:\n",
        "            self.func_backward = lambda x, y : self.func_acti_grad(self.z) * self.func_loss_grad(y, self.o)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        self.z = np.dot(x, self.W) + self.b\n",
        "        self.o = self.func_acti(self.z)\n",
        "        return self.o\n",
        "\n",
        "    def backward(self, y, rewards=None):\n",
        "        if self.func_acti == softmax:\n",
        "            one_hot = np.zeros(self.o.shape)\n",
        "            one_hot[np.arange(self.o.shape[0]), y] = 1\n",
        "        else:\n",
        "            one_hot = y\n",
        "\n",
        "        if rewards is not None:\n",
        "            self.grads = self.func_backward(self.o, one_hot) * rewards\n",
        "        else:\n",
        "            self.grads = self.func_backward(self.o, one_hot)\n",
        "\n",
        "    def loss(self, y):\n",
        "        if self.func_acti == softmax:\n",
        "            one_hot = np.zeros(self.o.shape, dtype=np.int)\n",
        "            one_hot[np.arange(self.o.shape[0]), y] = 1\n",
        "        else:\n",
        "            one_hot = y\n",
        "        \n",
        "        #fixed_section = np.nan_to_num((1 - one_hot) * np.log(1 - self.o))\n",
        "        return self.func_loss(self.o, one_hot)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUpK-B-mGZsP"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJI6FJfbGZEc"
      },
      "source": [
        "class model():\n",
        "    def __init__(self, input_size, output_size, hidden_shapes, func_acti, func_acti_grad, func_acti_loss_layer , func_acti_loss_layer_grad, func_loss_loss_layer, func_loss_loss_layer_grad, has_dropout=True, dropout_perc=0.5):\n",
        "        assert(len(hidden_shapes) > 0), \"NN must have at least 1 hidden layer!\"\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_shapes = hidden_shapes\n",
        "        self.hidden_amount = len(self.hidden_shapes)\n",
        "        self.hidden_layers = []\n",
        "        self.has_dropout = has_dropout\n",
        "        self.dropout_perc = dropout_perc\n",
        "        self.populate_layers(func_acti, func_acti_grad, func_acti_loss_layer, func_acti_loss_layer_grad, func_loss_loss_layer, func_loss_loss_layer_grad)\n",
        "\n",
        "\n",
        "    def populate_layers(self, func_acti, func_acti_grad, func_acti_loss_layer, func_acti_loss_layer_grad, func_loss_loss_layer, func_loss_loss_layer_grad):\n",
        "        i_size = self.input_size\n",
        "        for i in range(0, self.hidden_amount):\n",
        "            self.hidden_layers.append(dense(i_size, self.hidden_shapes[i], func_acti, func_acti_grad))\n",
        "            i_size = self.hidden_shapes[i]\n",
        "        self.loss_layer = loss_layer(i_size, self.output_size, func_acti_loss_layer, func_acti_loss_layer_grad, func_loss_loss_layer, func_loss_loss_layer_grad)\n",
        "\n",
        "    def forward(self, x, y, train=True):\n",
        "        self.dropout_masks = []\n",
        "        data = x\n",
        "        for i in range(0, self.hidden_amount):\n",
        "            data = self.hidden_layers[i].forward(data)\n",
        "            if train and self.has_dropout: #do dropout only during training\n",
        "                mask = self.hidden_layers[i].dropout(self.dropout_perc)\n",
        "                data *= mask\n",
        "                self.dropout_masks.append(mask)\n",
        "\n",
        "        o = self.loss_layer.forward(data)\n",
        "        loss = self.loss_layer.loss(y)\n",
        "        #print(loss, o)\n",
        "        return o, loss\n",
        "\n",
        "    def predict(self, x):\n",
        "        data = x\n",
        "        for i in range(0, self.hidden_amount):\n",
        "            data = self.hidden_layers[i].forward(data)\n",
        "        o = self.loss_layer.forward(data)\n",
        "        return o\n",
        "\n",
        "    #alpha is used for reinforcement learning fir reward\n",
        "    def backward(self, y, o, rewards=None):\n",
        "        self.loss_layer.backward(y, rewards)\n",
        "        prev = self.loss_layer\n",
        "        for i in reversed(range(self.hidden_amount)):\n",
        "            self.hidden_layers[i].backward(prev)\n",
        "            prev = self.hidden_layers[i]\n",
        "            if self.has_dropout:\n",
        "                self.hidden_layers[i].grads *= self.dropout_masks[i]  # also mask here\n",
        "\n",
        "    def update(self, lr):\n",
        "        for i in range(self.hidden_amount):\n",
        "            self.hidden_layers[i].update(lr)\n",
        "        self.loss_layer.update(lr)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME2SqDK2C4TI"
      },
      "source": [
        "# Train-Test (Main)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g46zIr4PKyJd"
      },
      "source": [
        "def test(ds, verbose=False, phase=\"Validation\"):\n",
        "    ds.reset()\n",
        "    hits = 0\n",
        "    mean_loss = 0\n",
        "    while not(ds.iter_done()):\n",
        "        x, y = ds.next()\n",
        "        o, batch_loss = nn.forward(x, y, train=False)\n",
        "        hits += batch_hits(o, y)\n",
        "        mean_loss += np.mean(batch_loss)\n",
        "        #if verbose:\n",
        "        #    print(\"Loss: \" + str(mean_loss), \" Predicted: \" + str(o), \" Expected: \" + str(y))\n",
        "    accuracy = float(hits) / float(ds.size)\n",
        "    mean_loss = float(mean_loss) / float(ds.size)\n",
        "    if verbose:\n",
        "        print(phase + \" Accuracy: \" + str(accuracy) + \" Mean Loss \" + str(mean_loss))\n",
        "    return accuracy, mean_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04qFe9u2KyPF"
      },
      "source": [
        "def train(nn, hp, val_hist, train_hist, logger):\n",
        "    cur_epoch = 1\n",
        "    cur_iter = 1\n",
        "    for i in range(1, hp.epochs+1):\n",
        "        train_loss = 0\n",
        "        hits = 0\n",
        "        cur_trained = 0\n",
        "        while not(hp.ds_train.iter_done()):\n",
        "            x, y = hp.ds_train.next()\n",
        "            o, batch_loss = nn.forward(x, y)\n",
        "            nn.backward(y,o)\n",
        "            nn.update(hp.lr)\n",
        "\n",
        "            hits += batch_hits(o, y)\n",
        "            cur_trained += len(x)\n",
        "            train_loss += np.mean(batch_loss)\n",
        "\n",
        "            if cur_iter % hp.validate_every_no_of_batches == 0:\n",
        "\n",
        "                train_accuracy = float(hits) / float(cur_trained)\n",
        "                train_loss = float(train_loss) / float(cur_trained)\n",
        "                train_hist.add(cur_iter, train_loss, train_accuracy)\n",
        "                logger.write( (cur_epoch, \"Training\", cur_iter, train_accuracy, train_loss) )\n",
        "                hits = 0\n",
        "                train_loss = 0\n",
        "\n",
        "                val_accuracy, val_loss = test(hp.ds_val, True)\n",
        "                val_hist.add(cur_iter, val_loss, val_accuracy)\n",
        "                logger.write( (cur_epoch, \"Val\", cur_iter, val_accuracy, val_loss) )\n",
        "            cur_iter+=1\n",
        "        cur_epoch+=1\n",
        "        hp.ds_train.reset()\n",
        "    return val_hist"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YdNCtyI4wgv"
      },
      "source": [
        "# Muestras de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzcwV_rRcQ2C"
      },
      "source": [
        "## Prueba de regresión, utilizando MSE como función de costo y tanh como función de activación en la última capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Rg7JlfcSas",
        "outputId": "c9e35736-7746-432c-d732-8660037ce9b8"
      },
      "source": [
        "#This is for a regression problem.\n",
        "hp = hyperparams(ConfigEnum.SIN)\n",
        "nn = model(hp.input_size, hp.output_size, hp.hidden_shapes, sigmoid, sigmoid_grad, tanh, tanh_grad, \n",
        "MSE, MSE_grad,  has_dropout=hp.has_dropout, dropout_perc=hp.dropout_perc)\n",
        "\n",
        "val_hist = historian()\n",
        "train_hist = historian()\n",
        "logger = nnlogger(hp.output_log, (\"Epoch\", \"Phase\", \"Iteration\", \"Accuracy\", \"Loss\") )\n",
        "train(nn, hp, val_hist, train_hist, logger)\n",
        "test(hp.ds_test, verbose=True, phase=\"Test\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((384, 1), (384, 1)) ((96, 1), (96, 1)) ((320, 1), (320, 1))\n",
            "Validation Accuracy: 0.0 Mean Loss 0.017014855697344854\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0036968424833682123\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002713944010191893\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0027775651067815828\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002665708009633262\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002565757674616842\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024412324690287895\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0025866239731168693\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002520759675736496\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022948435726231602\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002519201775326358\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024030627374786403\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00247828351288481\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0026284829477373002\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002373810320302245\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002184430322864337\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002709302362731092\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022831977025786544\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024908516544006275\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0023644332938155374\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002454715917469147\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0026462833154320257\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024416886178392247\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0026416366376074882\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002634075866115758\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002581022462981952\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024780328527935053\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0023780431407236305\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002422567280765384\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002413702078150548\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0025484472095251786\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002091744307414899\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024596328934997015\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0025296776721975816\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002098833227671073\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002112827437669555\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00224909404865994\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024154205253197037\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002398623637311759\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0020668403394480343\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019178683941389867\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0023482345211798257\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0021357505963019515\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002071029493794853\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002172985680615825\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002369552475961253\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024191702101647047\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022475106505034006\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022881002957933845\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0025152743195482104\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0020639891266556886\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017692423889869864\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0030155487394087654\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0021226709780062295\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001959203372932401\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022356207211657528\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002552298963499734\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022029177226903685\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002319875231554171\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002344315243511339\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002160116394840765\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002033981180186823\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002222070473221423\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002031315949905891\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002351775569710252\n",
            "Validation Accuracy: 0.0 Mean Loss 0.004717402776310649\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002834849005624859\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017247217898950585\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002071607022988532\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017543191034198487\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0021327881800733517\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017185298565792456\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019278984813380356\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0023718004602699813\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019024417865960302\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019263760937634456\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0020417668363012505\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017808616727206256\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001953424941941073\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019411147167742182\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0018164550462285382\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0018824280994602968\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001962224557056724\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002268254848385435\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0024726385372804125\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002040550094651129\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0020499728639594567\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0021482540442811686\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019120953208916838\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001835325364937776\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0025098157114992734\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0018926516405064614\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016620517122630317\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0020271395373178285\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019399411561414448\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001759173070564309\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017183768547867457\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016861087627814705\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0023905464702970755\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0019324669786208032\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001933964133194165\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001564504122592703\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022384495001740276\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016360953490501806\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0018906266204677038\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00301348530596532\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017924649985179859\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016213551597769086\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002100282637579146\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001766135610043858\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001864106603494796\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0015851168841503132\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0015451736835046619\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002004111939246978\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002150637167301892\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0020690143488610643\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016398763958016653\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016810337613111911\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017837525718005336\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001631085217754887\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016653194212130063\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017821904445151204\n",
            "Validation Accuracy: 0.0 Mean Loss 0.002439270560081274\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001596792800129949\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016116036133298883\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0020800278176711794\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0018058849705857487\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0016555710452981723\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0014782673868378945\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0017357374275075832\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0015841709751870266\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0014263317516756667\n",
            "Validation Accuracy: 0.0 Mean Loss 0.001004549548134543\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0013403408133710309\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0008460978406534545\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00043066421507343306\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0004343632902098905\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00033433075294351015\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0022597140224174606\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00034710621101415517\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0002889819401571941\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00039364851755832375\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00022121769349489062\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0006539110683232321\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0004061835670151194\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00022713515126022068\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0011111280563939248\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00033269751446134057\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0003587343880230294\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0002356923824733011\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0002370564614687621\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00021967789309837137\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00040088080245905856\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00034604536269162707\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0008866314926548007\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0003874632737713205\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0006068477875973189\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00021566541521957693\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0005337366212413158\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0004036742177019771\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00020121563504496247\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00021191275956681954\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0005027239921675085\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00018504730089284797\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00019846643585077591\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0005695044159445758\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00019426028086112876\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0003117816724249296\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0002011017969321164\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0002502418987926922\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0002555127567161029\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00027926052854194554\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00023585300324242657\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00026995127869545245\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0002634736470202677\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00023452156791162334\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0004146915652865721\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0006887596310432859\n",
            "Validation Accuracy: 0.0 Mean Loss 0.000249776590861107\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0003630856950393861\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00015757737795254375\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0004289986702902001\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00014947483509392885\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00023470761049129406\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0001738773463903612\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00018737733627842583\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00017363788405310893\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00016284828161753693\n",
            "Validation Accuracy: 0.0 Mean Loss 0.000217936351289851\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00017893372268769432\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00023170299363966615\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00017526281012678166\n",
            "Validation Accuracy: 0.0 Mean Loss 0.0001690795038623505\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00048446644836195875\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00015783088862131282\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00022408271578281812\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00017221564215836346\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00022593955830420582\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00024143639463499136\n",
            "Validation Accuracy: 0.0 Mean Loss 0.00024102098355705814\n",
            "Test Accuracy: 0.0 Mean Loss 0.00021136661671526712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.00021136661671526712)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "geOXJ8W4chmN",
        "outputId": "04e1ab7b-4933-47fa-ab4f-fe9c6f963c93"
      },
      "source": [
        "y_test = nn.predict(hp.ds_test.x)\n",
        "plt.subplot(211)\n",
        "plt.scatter(hp.ds_test.x, hp.ds_test.y, label='label')\n",
        "plt.scatter(hp.ds_test.x, y_test, label='predict')\n",
        "plt.xlabel('#')\n",
        "plt.ylabel('Sin value')\n",
        "plt.legend()\n",
        "plt.subplot(212)\n",
        "plt.scatter(hp.ds_test.x, hp.ds_test.y - y_test, label='error')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "logger.close()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAgiDPdwcOPz"
      },
      "source": [
        "## Prueba de clasificación utilizando la función tanh implementada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQJM2LyscS-s",
        "outputId": "899eaa38-2024-42d5-f2fe-0179551051a0"
      },
      "source": [
        "#load hyperparameters and settings according to dataset enum\n",
        "hp = hyperparams(ConfigEnum.XOR)\n",
        "#hp = hyperparams(ConfigEnum.IRIS)\n",
        "#hp = hyperparams(ConfigEnum.MNIST)\n",
        "\n",
        "#model has number of inputs, number of outputs, and list with sizes of hidden layers\n",
        "#requires at least 1 hidden layer, else fails assert\n",
        "\n",
        "#This is adding the TANH activation Function to the model.\n",
        "nn = model(hp.input_size, hp.output_size, hp.hidden_shapes, tanh, tanh_grad, softmax, None, \n",
        "crossEntropyLoss, None,  has_dropout=hp.has_dropout, dropout_perc=hp.dropout_perc)\n",
        "\n",
        "val_hist = historian()\n",
        "train_hist = historian()\n",
        "logger = nnlogger(hp.output_log, (\"Epoch\", \"Phase\", \"Iteration\", \"Accuracy\", \"Loss\") )\n",
        "train(nn, hp, val_hist, train_hist, logger)\n",
        "test(hp.ds_test, verbose=True, phase=\"Test\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5 Mean Loss 0.3726039580219074\n",
            "Validation Accuracy: 0.5 Mean Loss 0.35857121678037407\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3514949707434341\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3472671656184749\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3444653143577916\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34236243252411824\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34047961529633985\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33846710716141903\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33645813648939615\n",
            "Validation Accuracy: 0.75 Mean Loss 0.33407467993633233\n",
            "Validation Accuracy: 0.75 Mean Loss 0.33134692794884973\n",
            "Validation Accuracy: 0.75 Mean Loss 0.3282076802474383\n",
            "Validation Accuracy: 0.75 Mean Loss 0.3251590968178835\n",
            "Validation Accuracy: 0.75 Mean Loss 0.3218834011436653\n",
            "Validation Accuracy: 0.75 Mean Loss 0.31891519890050046\n",
            "Validation Accuracy: 0.75 Mean Loss 0.31527160224721706\n",
            "Validation Accuracy: 0.75 Mean Loss 0.3117390721362353\n",
            "Validation Accuracy: 0.75 Mean Loss 0.3083858039392216\n",
            "Validation Accuracy: 0.75 Mean Loss 0.3053241257900039\n",
            "Validation Accuracy: 0.75 Mean Loss 0.3021515108130187\n",
            "Validation Accuracy: 0.75 Mean Loss 0.29900207861501216\n",
            "Validation Accuracy: 0.75 Mean Loss 0.29568030191592876\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2936124861160121\n",
            "Validation Accuracy: 0.75 Mean Loss 0.29024698695611445\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2868569653189001\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2836874752425359\n",
            "Validation Accuracy: 0.75 Mean Loss 0.28046747349840806\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2779122056478329\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2714009855002791\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2687831792685116\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2648844646286185\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2596721050392499\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2565021524193766\n",
            "Validation Accuracy: 0.75 Mean Loss 0.25054848036126287\n",
            "Validation Accuracy: 0.75 Mean Loss 0.24723944337180062\n",
            "Validation Accuracy: 0.75 Mean Loss 0.24072434446455482\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2359317517141794\n",
            "Validation Accuracy: 1.0 Mean Loss 0.23079284542548645\n",
            "Validation Accuracy: 1.0 Mean Loss 0.22411876947487536\n",
            "Validation Accuracy: 1.0 Mean Loss 0.21944504442201337\n",
            "Validation Accuracy: 1.0 Mean Loss 0.21421358021122816\n",
            "Validation Accuracy: 1.0 Mean Loss 0.20942684102903314\n",
            "Validation Accuracy: 1.0 Mean Loss 0.20598292342940527\n",
            "Validation Accuracy: 1.0 Mean Loss 0.1921459959850148\n",
            "Validation Accuracy: 1.0 Mean Loss 0.1901823293857659\n",
            "Validation Accuracy: 1.0 Mean Loss 0.1860683400080116\n",
            "Validation Accuracy: 1.0 Mean Loss 0.17593556585875972\n",
            "Validation Accuracy: 1.0 Mean Loss 0.17245133437384025\n",
            "Validation Accuracy: 1.0 Mean Loss 0.16341355371201552\n",
            "Validation Accuracy: 1.0 Mean Loss 0.1532086813774327\n",
            "Validation Accuracy: 1.0 Mean Loss 0.1522852784804092\n",
            "Validation Accuracy: 1.0 Mean Loss 0.14244222415166038\n",
            "Validation Accuracy: 1.0 Mean Loss 0.13549748270916512\n",
            "Validation Accuracy: 1.0 Mean Loss 0.1368760729425338\n",
            "Validation Accuracy: 1.0 Mean Loss 0.12613724111974695\n",
            "Validation Accuracy: 1.0 Mean Loss 0.12508150717322564\n",
            "Validation Accuracy: 1.0 Mean Loss 0.11647377703996822\n",
            "Validation Accuracy: 1.0 Mean Loss 0.10959295645365269\n",
            "Validation Accuracy: 1.0 Mean Loss 0.10850884901518386\n",
            "Validation Accuracy: 1.0 Mean Loss 0.10476775093308467\n",
            "Validation Accuracy: 1.0 Mean Loss 0.09863243260736176\n",
            "Validation Accuracy: 1.0 Mean Loss 0.09639195989289354\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0898010705630384\n",
            "Validation Accuracy: 1.0 Mean Loss 0.08642129556368301\n",
            "Validation Accuracy: 1.0 Mean Loss 0.08502730824327846\n",
            "Validation Accuracy: 1.0 Mean Loss 0.08039103203793736\n",
            "Validation Accuracy: 1.0 Mean Loss 0.08176871517960574\n",
            "Validation Accuracy: 1.0 Mean Loss 0.07440834752140049\n",
            "Validation Accuracy: 1.0 Mean Loss 0.07473439650709715\n",
            "Validation Accuracy: 1.0 Mean Loss 0.07114713869281578\n",
            "Validation Accuracy: 1.0 Mean Loss 0.06883734238920974\n",
            "Validation Accuracy: 1.0 Mean Loss 0.06683046282179389\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0651842525671279\n",
            "Validation Accuracy: 1.0 Mean Loss 0.061286871303493765\n",
            "Validation Accuracy: 1.0 Mean Loss 0.06197450886863687\n",
            "Validation Accuracy: 1.0 Mean Loss 0.05989647628961685\n",
            "Validation Accuracy: 1.0 Mean Loss 0.05716297869818021\n",
            "Validation Accuracy: 1.0 Mean Loss 0.05502350557597293\n",
            "Validation Accuracy: 1.0 Mean Loss 0.05388492135056801\n",
            "Validation Accuracy: 1.0 Mean Loss 0.052163695798687626\n",
            "Validation Accuracy: 1.0 Mean Loss 0.052637358400121924\n",
            "Validation Accuracy: 1.0 Mean Loss 0.049342082897919255\n",
            "Validation Accuracy: 1.0 Mean Loss 0.048524804370825986\n",
            "Validation Accuracy: 1.0 Mean Loss 0.047528632300561605\n",
            "Validation Accuracy: 1.0 Mean Loss 0.04586109636468459\n",
            "Validation Accuracy: 1.0 Mean Loss 0.045047676064420505\n",
            "Validation Accuracy: 1.0 Mean Loss 0.042812671137512845\n",
            "Validation Accuracy: 1.0 Mean Loss 0.04256872525923491\n",
            "Validation Accuracy: 1.0 Mean Loss 0.04159802424565595\n",
            "Validation Accuracy: 1.0 Mean Loss 0.041272682935523206\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03982909968936578\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03919255207627747\n",
            "Validation Accuracy: 1.0 Mean Loss 0.038915834953389836\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03698725309246868\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03686552334465411\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03627385327331584\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03433853012248636\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03382321530338964\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03283312629072392\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03280942655022324\n",
            "Validation Accuracy: 1.0 Mean Loss 0.032061590547398086\n",
            "Validation Accuracy: 1.0 Mean Loss 0.031140934111152017\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03140180969404008\n",
            "Validation Accuracy: 1.0 Mean Loss 0.030567947986980586\n",
            "Validation Accuracy: 1.0 Mean Loss 0.03062330984370532\n",
            "Validation Accuracy: 1.0 Mean Loss 0.030032867526262767\n",
            "Validation Accuracy: 1.0 Mean Loss 0.029061078262908553\n",
            "Validation Accuracy: 1.0 Mean Loss 0.028338205056532825\n",
            "Validation Accuracy: 1.0 Mean Loss 0.02790320602111209\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0278975779777969\n",
            "Validation Accuracy: 1.0 Mean Loss 0.02758840485458711\n",
            "Validation Accuracy: 1.0 Mean Loss 0.02713978144306463\n",
            "Validation Accuracy: 1.0 Mean Loss 0.026435945280082092\n",
            "Validation Accuracy: 1.0 Mean Loss 0.025860780104287166\n",
            "Validation Accuracy: 1.0 Mean Loss 0.025278740573051385\n",
            "Validation Accuracy: 1.0 Mean Loss 0.025068038179390184\n",
            "Validation Accuracy: 1.0 Mean Loss 0.024157491983966908\n",
            "Validation Accuracy: 1.0 Mean Loss 0.024562054502872806\n",
            "Validation Accuracy: 1.0 Mean Loss 0.024130462474896017\n",
            "Validation Accuracy: 1.0 Mean Loss 0.023245054204881127\n",
            "Validation Accuracy: 1.0 Mean Loss 0.02321259453031451\n",
            "Validation Accuracy: 1.0 Mean Loss 0.022716772734881353\n",
            "Validation Accuracy: 1.0 Mean Loss 0.022674665304156398\n",
            "Validation Accuracy: 1.0 Mean Loss 0.022391008936762033\n",
            "Validation Accuracy: 1.0 Mean Loss 0.02183315730030183\n",
            "Validation Accuracy: 1.0 Mean Loss 0.021834819910944835\n",
            "Validation Accuracy: 1.0 Mean Loss 0.021685285803605035\n",
            "Validation Accuracy: 1.0 Mean Loss 0.021316170388653972\n",
            "Validation Accuracy: 1.0 Mean Loss 0.020951960279976985\n",
            "Validation Accuracy: 1.0 Mean Loss 0.02073364138557148\n",
            "Validation Accuracy: 1.0 Mean Loss 0.020488647890549657\n",
            "Validation Accuracy: 1.0 Mean Loss 0.02017264809640716\n",
            "Validation Accuracy: 1.0 Mean Loss 0.019462415516412267\n",
            "Validation Accuracy: 1.0 Mean Loss 0.019513720308780652\n",
            "Validation Accuracy: 1.0 Mean Loss 0.019407441459613227\n",
            "Validation Accuracy: 1.0 Mean Loss 0.019369354578581206\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01900461074288092\n",
            "Validation Accuracy: 1.0 Mean Loss 0.018472197058370707\n",
            "Validation Accuracy: 1.0 Mean Loss 0.018317316254987392\n",
            "Validation Accuracy: 1.0 Mean Loss 0.018229898728721942\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01805620016907887\n",
            "Validation Accuracy: 1.0 Mean Loss 0.017970841276878403\n",
            "Validation Accuracy: 1.0 Mean Loss 0.017818325175746517\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01764820574662198\n",
            "Validation Accuracy: 1.0 Mean Loss 0.017265575065384037\n",
            "Validation Accuracy: 1.0 Mean Loss 0.017110878984958902\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01675841467478833\n",
            "Validation Accuracy: 1.0 Mean Loss 0.016758645851473925\n",
            "Validation Accuracy: 1.0 Mean Loss 0.016523113005751832\n",
            "Validation Accuracy: 1.0 Mean Loss 0.016295127831145013\n",
            "Validation Accuracy: 1.0 Mean Loss 0.016219355701427393\n",
            "Validation Accuracy: 1.0 Mean Loss 0.015953556749148765\n",
            "Validation Accuracy: 1.0 Mean Loss 0.015846773827025793\n",
            "Validation Accuracy: 1.0 Mean Loss 0.015726519126089706\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01563568664790522\n",
            "Validation Accuracy: 1.0 Mean Loss 0.015579271412029484\n",
            "Validation Accuracy: 1.0 Mean Loss 0.015304656537024956\n",
            "Validation Accuracy: 1.0 Mean Loss 0.015020520284996796\n",
            "Validation Accuracy: 1.0 Mean Loss 0.014994328264040627\n",
            "Validation Accuracy: 1.0 Mean Loss 0.014702913385468235\n",
            "Validation Accuracy: 1.0 Mean Loss 0.014559985252356161\n",
            "Validation Accuracy: 1.0 Mean Loss 0.014613623326232703\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01435654693101945\n",
            "Validation Accuracy: 1.0 Mean Loss 0.014337579224439215\n",
            "Validation Accuracy: 1.0 Mean Loss 0.014126613716878202\n",
            "Validation Accuracy: 1.0 Mean Loss 0.014030524380510754\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013997836422876624\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013711381526290858\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013638515380093683\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013588248507422292\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013471681046748056\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013411726628687375\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013265661781847104\n",
            "Validation Accuracy: 1.0 Mean Loss 0.013220930478851211\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012915073025297739\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012866542899000287\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012804876290280287\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012674405833598721\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012401914428733143\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012406762454194257\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012346597603320266\n",
            "Validation Accuracy: 1.0 Mean Loss 0.012184013393680405\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01213469551025122\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011969048016533241\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011978511074316665\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011858820353925069\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011692948607574142\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011717841298890166\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011553134401973\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01155993334384662\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011520403325191726\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011344421106130749\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011168571969388273\n",
            "Validation Accuracy: 1.0 Mean Loss 0.011102153613028007\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010940729787669471\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010840968913671492\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01084572956962886\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010713927232385003\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010786563036271178\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0106518073364668\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010533362312036249\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010578549602676375\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010530849341157184\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010420167410103723\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010401433498417642\n",
            "Validation Accuracy: 1.0 Mean Loss 0.01025842681023656\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010180030215911084\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010095884366616221\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010030967236968669\n",
            "Validation Accuracy: 1.0 Mean Loss 0.010007167046074779\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009888142033918065\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009880256140028399\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00985812960760123\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00981014778803433\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009697502132004428\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009656161774272346\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00948673514434042\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009416546704730501\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00941404200088488\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009332936557333173\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009257944137931063\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00924590460698932\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009122832262873925\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009085070457884791\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009072376540225366\n",
            "Validation Accuracy: 1.0 Mean Loss 0.009055474823099633\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008948859206169798\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008925558059109343\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008876387977637352\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008827716036583229\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008771958742925407\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008749406403013107\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008648057980490061\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008628014295889145\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00850454369912431\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008400898237928537\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008413232219271385\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008392278420917733\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00838786491738066\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008316976178035455\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008218335009642279\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00819196984320842\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008145214524487153\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0081163057835937\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008094124394731467\n",
            "Validation Accuracy: 1.0 Mean Loss 0.008022343296295214\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007985884561961391\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007934927945727121\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007911513067072641\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007859315016447693\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007824059035946872\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0078163966557423\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007770413178470902\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00768235786541058\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007641932720926281\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007650731499474852\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007593437495059567\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007548044470931074\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007511171471195262\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007457985073197568\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007455381829629373\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007404506782619786\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007374616438035512\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00732864282124377\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007312134056529946\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007276673223818712\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00724989588935089\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00723949216234852\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007206107127796523\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007153439758898339\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007137036143122116\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007059051549708945\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0070299345222216945\n",
            "Validation Accuracy: 1.0 Mean Loss 0.007010826361266945\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0069587481120124755\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0069164076745179505\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006882288017137384\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006846640952437052\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006829790164018433\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00682010180822826\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006750212740657735\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006764671609016833\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006703569735428121\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0066818016575139055\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00666031926001753\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00664520330579583\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0066142139706501235\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006577686815553374\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006523651084185684\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006495547041117215\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00647766751465717\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0064674017624260114\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006453548628185538\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006382933739221029\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006376562421968522\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0063337545852975505\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0063054966627507075\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006301051412523816\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006236304372789656\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006209998766376021\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006173205473026253\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00618629003255072\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006137798154812441\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006137965212919724\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006098213259093395\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006099813002339686\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0060589837062878325\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006023087964130459\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006015079159005058\n",
            "Validation Accuracy: 1.0 Mean Loss 0.006001655465461185\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005944056375847017\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0059221764582942545\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005905012346448965\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00589679206731567\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005871076612594751\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005839038428572457\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005825548085332559\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005789449402657129\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005778921288234531\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0057654824451872245\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005726552650533137\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0057212039782725994\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005683529159418854\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0056617129656232204\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0056286017845687195\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0056003699846782495\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005548403497437383\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005549715643454818\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005532088328920711\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005505463565066907\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005496940037035017\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005480535989859007\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005451895614882334\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005427249972084065\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0054186940191085445\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00538379290352142\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005354670153931857\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005334405661869102\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005320438388796343\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005318723677605146\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005306797426404759\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005293623551594723\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0052887540018239565\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005260453243726362\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005251926362718207\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00520380157196722\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005193292647862044\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005191143598294125\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005179865914850697\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005146343593382965\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005143139536079738\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005098818158596339\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00509165012526923\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005088530119298292\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005070646263672925\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005029326132695947\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005025801894021549\n",
            "Validation Accuracy: 1.0 Mean Loss 0.005019387614828456\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00500914307674404\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00497711152479742\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004951907918765541\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004933091753878771\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00491704566990091\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004881997994982087\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004888990737281966\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00486008765452195\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004858242146805941\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0048318960027664976\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0048239215776441245\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004805381021981712\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0047774937521393385\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004766517974104829\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004754905982001335\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004750874475480954\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004730184693306935\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004709015029369034\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0046877000163156\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004670453713500113\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004649095987705142\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0046549478713304535\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00463794317699581\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004631758552700665\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004623296774614618\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0045965005098334575\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00457098968723267\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004561846274354401\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004548554297648083\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0045317892760546995\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004509367488655512\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0044923515535972266\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004485973634234331\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004482879400282086\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004476616592017335\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004464292754099191\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004445287445095168\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004436843285884798\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004415792071358258\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00439528497287113\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004369705740372688\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004352687653989833\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004349738881295813\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004330176370076702\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004323547752916481\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004303100153872564\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00429395269903279\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004296628718900602\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004280392055971076\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00428014836687285\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004254512063673716\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004255107646598925\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004239327541720321\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0042217912854388565\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004214122815859499\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004196293267031634\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00419193404252698\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0041842882065598495\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0041767472959536615\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004159129717212137\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004151585957424864\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004132395640515556\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004116205699991291\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004103154057646392\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004095188915703393\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004091416658366712\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004085625010215697\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004072247795519231\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004057795183225544\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004045718463905324\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004038266980886921\n",
            "Validation Accuracy: 1.0 Mean Loss 0.004023511345541259\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0040084172029752054\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003987293242032906\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003974340360414963\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0039701798009810895\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003952138752842478\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003949703761205777\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0039398099841161105\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003936465658226903\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003926507077607378\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003915883840550229\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003907561093887641\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003883413898447825\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0038760986062116374\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003856657581179228\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003855234093565164\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0038425118633029906\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003839111622315812\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0038212519652498973\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0037949456379737026\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0037828068440106935\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003777963520676368\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003765115630416976\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003762558552825003\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00376108593576549\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0037498862260833057\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003743060690310724\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0037360362072552866\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0037239862743398337\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003720957468509894\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003713712695207887\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003704074014171529\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003682677587355611\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0036783654848758073\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003668390574891458\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003652191767607029\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003642583415779733\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0036370109670781593\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003634990491179134\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003620828649777832\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003609127845470358\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003606881452227138\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0036014486420026083\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0035879163801403983\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0035799541035376834\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003568227697167671\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003562954176949441\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0035520296879488914\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003547023012059052\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003538419341442268\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0035340325918580486\n",
            "Validation Accuracy: 1.0 Mean Loss 0.00352863164702045\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003522542023995195\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003500179266963401\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0034963308592286485\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003483940508017273\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0034740255525080475\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003460037436765564\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0034542726957754386\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003451075223358084\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0034472468003290202\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0034427819444528924\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003437670812191449\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003426988185842172\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003415466189320168\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0034082436677255216\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003403781116253922\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0033971278197012676\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003389281627300808\n",
            "Validation Accuracy: 1.0 Mean Loss 0.003382844939808894\n",
            "Validation Accuracy: 1.0 Mean Loss 0.0033747346045362734\n",
            "Test Accuracy: 1.0 Mean Loss 0.003374734604536273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 0.003374734604536273)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fmy3uQnPc5iR",
        "outputId": "9d3d2b0b-428e-4a70-f443-87261d615132"
      },
      "source": [
        "nnplotter.view(val_hist, train_hist) #see results on plot"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ndyjQLDcx13"
      },
      "source": [
        "## Prueba de clasificación base, la ejecución original del profesor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "863PYTD-cx8C",
        "outputId": "9e2f7653-93b3-4fff-a9fd-2d9f8ffb5043"
      },
      "source": [
        "#load hyperparameters and settings according to dataset enum\n",
        "hp = hyperparams(ConfigEnum.XOR)\n",
        "#hp = hyperparams(ConfigEnum.IRIS)\n",
        "#hp = hyperparams(ConfigEnum.MNIST)\n",
        "\n",
        "#model has number of inputs, number of outputs, and list with sizes of hidden layers\n",
        "#requires at least 1 hidden layer, else fails assert\n",
        "\n",
        "#This is the base model\n",
        "nn = model(hp.input_size, hp.output_size, hp.hidden_shapes, sigmoid, sigmoid_grad, softmax, None, \n",
        "crossEntropyLoss, None,  has_dropout=hp.has_dropout, dropout_perc=hp.dropout_perc)\n",
        "\n",
        "val_hist = historian()\n",
        "train_hist = historian()\n",
        "logger = nnlogger(hp.output_log, (\"Epoch\", \"Phase\", \"Iteration\", \"Accuracy\", \"Loss\") )\n",
        "train(nn, hp, val_hist, train_hist, logger)\n",
        "test(hp.ds_test, verbose=True, phase=\"Test\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5 Mean Loss 0.34753861169288264\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3462667074996144\n",
            "Validation Accuracy: 0.25 Mean Loss 0.34554465939683404\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3452303063731442\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3449989349766521\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34488851197243464\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3447975385022316\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34471746037093237\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34464302019097803\n",
            "Validation Accuracy: 0.5 Mean Loss 0.344558231755014\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3444795999493796\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3444001631845913\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34431488867652604\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34422972509094296\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34414001021502666\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34404710161486507\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3439551638923921\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34385174895564835\n",
            "Validation Accuracy: 0.5 Mean Loss 0.343753440851962\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34365156605040614\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34354658301236923\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3434372468852306\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3433314164149243\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3432146918459419\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34309164774198647\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34296546920498\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34284228641796444\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34270147855943084\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34255834150816367\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3424121141223181\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3422686532521124\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34211310154633556\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3419536250082639\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3417848374474925\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3416175634871449\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3414443087960395\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34125661241462224\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3410696855769091\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3408761351018126\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34067408858796533\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3404695024489638\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34024509926323976\n",
            "Validation Accuracy: 0.5 Mean Loss 0.34001681903833386\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3397844500858056\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3395376935004961\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33928805004192164\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33902960502574964\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3387598251078353\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3384847660262883\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3381847595982932\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33788460564232625\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3375724153993518\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33723826903806514\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33689560312437694\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33653570006557376\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33617255946087143\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3358009230151495\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33539825270874785\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3349800841563878\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3345601710062841\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3341276416270287\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33364934737062946\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33318216330629796\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33269837583427797\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33219644890566613\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33167199090236826\n",
            "Validation Accuracy: 0.5 Mean Loss 0.33112686440458705\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3305491938249995\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3299696081485338\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3293729435795507\n",
            "Validation Accuracy: 0.5 Mean Loss 0.32874471634563807\n",
            "Validation Accuracy: 0.5 Mean Loss 0.32810407112428613\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3274394392813339\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3267495155703831\n",
            "Validation Accuracy: 0.5 Mean Loss 0.32604108325737313\n",
            "Validation Accuracy: 0.5 Mean Loss 0.32530878052408185\n",
            "Validation Accuracy: 0.5 Mean Loss 0.32455472100421123\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3237768342227792\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3229764484160824\n",
            "Validation Accuracy: 0.5 Mean Loss 0.32215153298094945\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3212959623150329\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3204301582518667\n",
            "Validation Accuracy: 0.5 Mean Loss 0.319531712738899\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3186181227084245\n",
            "Validation Accuracy: 0.5 Mean Loss 0.31767122826378646\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3166880689597712\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3156822002216205\n",
            "Validation Accuracy: 0.5 Mean Loss 0.31465790316563247\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3136135381582273\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3125507030499963\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3114397526991531\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3103228560644736\n",
            "Validation Accuracy: 0.5 Mean Loss 0.30917688252110404\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3080224398571797\n",
            "Validation Accuracy: 0.5 Mean Loss 0.306844055015039\n",
            "Validation Accuracy: 0.5 Mean Loss 0.30564949528208063\n",
            "Validation Accuracy: 0.5 Mean Loss 0.30442104108185863\n",
            "Validation Accuracy: 0.5 Mean Loss 0.3031717995316763\n",
            "Validation Accuracy: 0.5 Mean Loss 0.30188958793563603\n",
            "Validation Accuracy: 0.75 Mean Loss 0.300601302792907\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2993045031202429\n",
            "Validation Accuracy: 0.75 Mean Loss 0.29796828971316536\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2966295277318276\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2952752985553635\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2939166323539961\n",
            "Validation Accuracy: 0.75 Mean Loss 0.29250744948313\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2910982597639094\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2896625227282716\n",
            "Validation Accuracy: 0.75 Mean Loss 0.28825316366239295\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2868233029080403\n",
            "Validation Accuracy: 0.75 Mean Loss 0.28540278882697345\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2839587571673957\n",
            "Validation Accuracy: 0.75 Mean Loss 0.28250780198433567\n",
            "Validation Accuracy: 0.75 Mean Loss 0.28103667316170816\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2795651596296199\n",
            "Validation Accuracy: 0.75 Mean Loss 0.27810060068560294\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2766281735890826\n",
            "Validation Accuracy: 0.75 Mean Loss 0.27516760095126075\n",
            "Validation Accuracy: 0.75 Mean Loss 0.27368173051486044\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2721969355714745\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2707360042394575\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2692719503445074\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2678104856158115\n",
            "Validation Accuracy: 0.75 Mean Loss 0.26636949996274245\n",
            "Validation Accuracy: 0.75 Mean Loss 0.264918006805266\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2634961617182211\n",
            "Validation Accuracy: 0.75 Mean Loss 0.26207554289865764\n",
            "Validation Accuracy: 0.75 Mean Loss 0.26066603821283324\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2592645092132983\n",
            "Validation Accuracy: 0.75 Mean Loss 0.25788212818502215\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2565056463221729\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2551148668105359\n",
            "Validation Accuracy: 0.75 Mean Loss 0.25378392723197946\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2524521821400476\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2511410760472366\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2498284324545303\n",
            "Validation Accuracy: 0.75 Mean Loss 0.24852919207847574\n",
            "Validation Accuracy: 0.75 Mean Loss 0.24727644832012016\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2460386263606652\n",
            "Validation Accuracy: 0.75 Mean Loss 0.24481821080863536\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2435974956463488\n",
            "Validation Accuracy: 0.75 Mean Loss 0.24240442277507387\n",
            "Validation Accuracy: 0.75 Mean Loss 0.24124483257527643\n",
            "Validation Accuracy: 0.75 Mean Loss 0.240095298889859\n",
            "Validation Accuracy: 0.75 Mean Loss 0.2389765625911855\n",
            "Validation Accuracy: 0.75 Mean Loss 0.23787154204154565\n",
            "Validation Accuracy: 0.75 Mean Loss 0.23678825795716119\n",
            "Validation Accuracy: 0.5 Mean Loss 0.23573480545339434\n",
            "Validation Accuracy: 0.5 Mean Loss 0.23469445040531658\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2336624710624684\n",
            "Validation Accuracy: 0.5 Mean Loss 0.23266894411487193\n",
            "Validation Accuracy: 0.5 Mean Loss 0.23167906635486507\n",
            "Validation Accuracy: 0.5 Mean Loss 0.23072477631329147\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22977584277925073\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2288506539429647\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2279401737980675\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22704804211479962\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22618595127794736\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22533330355381334\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22449369502092065\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22367151988790243\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22286301281245965\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22207483639958003\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2213119497799632\n",
            "Validation Accuracy: 0.5 Mean Loss 0.22054841263996539\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21981620396550977\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21911316364996763\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21841796164851593\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21773326592028355\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21706402828292742\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21640831214512718\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21577284417460205\n",
            "Validation Accuracy: 0.5 Mean Loss 0.215149370059186\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2145325832302651\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21393292671686384\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21334164410141243\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21277635368959813\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2122219752426865\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2116747280194406\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2111427807762944\n",
            "Validation Accuracy: 0.5 Mean Loss 0.21061536421230959\n",
            "Validation Accuracy: 0.5 Mean Loss 0.210104127208456\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20961123421684885\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20911500325444032\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2086337777097336\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20816601884056282\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2077052441790145\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20725480781880382\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20681569333074323\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20638514748641157\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2059639200670813\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2055519533124504\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20514341175512033\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20474491460913596\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20435903335485717\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2039761991582923\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20360381833118454\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20324194932175416\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20288330470395338\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20253557887995133\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20219205247772962\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20185580474089712\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20152605318618466\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20120107195060466\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20088574990953376\n",
            "Validation Accuracy: 0.5 Mean Loss 0.20057292632549392\n",
            "Validation Accuracy: 0.5 Mean Loss 0.2002669770103674\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1999648791694944\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19966887112390236\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19938145011413275\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1990973640491231\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19882045428623388\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1985457212129591\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1982787174301252\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19801394923130405\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19775212269128153\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19749847041708724\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1972489507578214\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19700575999860465\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19676631228403227\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19652839056430849\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19629585637767233\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19606670189510783\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19584389863011648\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19562180915528138\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19540417957209935\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19519024600930734\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19498355303442133\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19477128276808742\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19456955638404244\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19437158489352183\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19417306114368688\n",
            "Validation Accuracy: 0.5 Mean Loss 0.193980508200915\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19379027024937975\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19360391818171224\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19341973792918593\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19323887545858773\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19306288569972505\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19288756895041695\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19271718718134834\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19254845474271132\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19237937087114215\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19221416929239762\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1920529185672431\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19189310003818766\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19173391953206542\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19157963374101375\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19142505550119832\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19127618346427083\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19112724357001057\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19098066727345545\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1908370242422949\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19069589121561462\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1905550079491739\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19041858449500842\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1902813603873255\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1901498078185151\n",
            "Validation Accuracy: 0.5 Mean Loss 0.19001679990335113\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18988610150014487\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18975746995933235\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18963073760026955\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18950544877196443\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18938214696466332\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1892602095434422\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18914108096338336\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18902116983823447\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18890404646048492\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18878779828807565\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18867366729300059\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18856128140867626\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18845048402600678\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18834244650267928\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18823418686027804\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18812594323597756\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18802191167585935\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18791772292593012\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18781474860574385\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18771478431406932\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1876150815502397\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18751631384789708\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1874193184001115\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1873233394863002\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1872287211608824\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18713568694519525\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1870426525565641\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1869517117102198\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18686113645055827\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18677212694313303\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18668476692781666\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1865970428941604\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18651094317915995\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18642525431472534\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18633976416528025\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18625702244114983\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1861756024939373\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1860946587521763\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18601431740585844\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18593553734275478\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1858571277191985\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18578021965732172\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18570266108506117\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1856272156108869\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18555146580746576\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18547730939122534\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18540434723446753\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18533132095864877\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18525975679756182\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18518859876678206\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18511840622847595\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18504921173535677\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18498085950361456\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18491267820829324\n",
            "Validation Accuracy: 0.5 Mean Loss 0.184845090301013\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18477788807608264\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18471217269652646\n",
            "Validation Accuracy: 0.5 Mean Loss 0.184646818729786\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1845821270330798\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18451808917974866\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18445473109973176\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1843929006252517\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1843318394566903\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18427006986221348\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1842093061963441\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18414923467123512\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1840901043404351\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18403120243633508\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1839732722707946\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18391568917945822\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18385833332393\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1838021798654078\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18374648507419863\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18369170193252635\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18363680325412024\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18358236237028758\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18352879882804496\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18347603727661044\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18342371757345072\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1833715920726698\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18332036383754408\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18326918593498298\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18321887453982036\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1831684694017788\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18311877933262524\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18306950818686413\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18301966536968634\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18297035214292007\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18292227260889787\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18287500394185258\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18282808217564878\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18278130360938466\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18273536274005442\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18269010731814897\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1826438260335574\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18259917125215305\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1825542985242094\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18250951168391813\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1824661684495008\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18242276462118057\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18237969170204432\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18233677851651414\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18229441325702994\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18225246310096854\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1822105324685216\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1821690097077509\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1821279113314488\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18208717257567833\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18204714747818268\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18200749447936043\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18196847111411724\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18192900089487263\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18189015119382904\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1818511638695629\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18181322933814542\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18177514723471533\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18173766630669222\n",
            "Validation Accuracy: 0.5 Mean Loss 0.181700569270146\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1816633996075781\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18162664501070525\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18159023425970572\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1815541890731481\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18151869511433927\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1814834684362197\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18144789698191613\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1814130805191252\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18137828296119124\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1813440340175989\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18131014335921808\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18127632746252118\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18124296188930872\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18120984099660808\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18117673720676522\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1811438816155771\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18111133210773978\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18107914724378618\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18104695622848507\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18101515163680898\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18098375818073392\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1809526098637455\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18092124760842787\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18089029014748392\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1808597586566945\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18082934435860315\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18079930354026924\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18076942203292334\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18073973477403493\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1807101622537095\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18068086111712273\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18065214418443473\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1806232303435496\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18059475107177603\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18056633880046621\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1805384609147344\n",
            "Validation Accuracy: 0.5 Mean Loss 0.180510695145748\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18048312671919958\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1804555156177518\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18042830144185037\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18040143519330015\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18037424932433316\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18034745412396858\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18032081472803596\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18029451507552216\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1802682595708218\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18024224555009394\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18021640897751626\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18019052925046347\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18016476028432452\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18013931620812085\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18011404501477019\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1800895775460633\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1800646629763747\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1800396740240429\n",
            "Validation Accuracy: 0.5 Mean Loss 0.18001516228972325\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1799910194479529\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1799670378233269\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1799434027026034\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17992022401910837\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17989574478626258\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1798720577944135\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17984874365509895\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17982558863702164\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17980270294983774\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17977966454989558\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17975707844120123\n",
            "Validation Accuracy: 0.5 Mean Loss 0.179734504871856\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1797122889937282\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17969019019973825\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1796681820408683\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1796458552473319\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1796237589537633\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17960186317361831\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17958030869428637\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17955906448588743\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1795380387740049\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1795172842835243\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1794962123144114\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1794751401985547\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17945431118678234\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1794339862906085\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1794136732143724\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1793932585765387\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17937281524140447\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17935281163192113\n",
            "Validation Accuracy: 0.5 Mean Loss 0.179332779172509\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1793131182550682\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17929351663598564\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1792738854236317\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17925432768212773\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1792349511018355\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17921565097141434\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17919670506896868\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1791780002495254\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17915911047133698\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1791403114621381\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17912161848330493\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17910317868913428\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17908451309472834\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1790661824562397\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17904778384556533\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1790303478712521\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17901260457929968\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17899441423070825\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17897755929447998\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17895994441003324\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17894314678994327\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17892475236516683\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17890617328006872\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17888862770235678\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17887133604418276\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17885365828364874\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17883668473975373\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1788197839482788\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17880298305083042\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17878648990484353\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17876973652256323\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17875344714251365\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17873693816165376\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1787204967271511\n",
            "Validation Accuracy: 0.5 Mean Loss 0.1787044248037065\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17868881803030884\n",
            "Validation Accuracy: 0.5 Mean Loss 0.17867217722090745\n",
            "Test Accuracy: 0.5 Mean Loss 0.17867217722090745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.17867217722090745)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Whx-98pZc7Ir",
        "outputId": "ec15fe62-a50b-4432-eaf0-dd8a2c1d9476"
      },
      "source": [
        "nnplotter.view(val_hist, train_hist) #see results on plot"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}