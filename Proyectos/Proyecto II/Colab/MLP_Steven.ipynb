{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MLP Steven.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "name": "python395jvsc74a57bd03a31fab793c547cb35fe033c429e016f6dd189ef070db975037acd85972e51d4"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "metadata": {
      "interpreter": {
        "hash": "3a31fab793c547cb35fe033c429e016f6dd189ef070db975037acd85972e51d4"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f99b3876f6c4cedb0e25acddb6d54a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2132a0a49baf436ab7d675b0b24e5104",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7cd1dfdab9c34ad1a411e3411d0f75cf",
              "IPY_MODEL_20de75cd911b45a4b0f0e7d9f5d61ab0"
            ]
          }
        },
        "2132a0a49baf436ab7d675b0b24e5104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cd1dfdab9c34ad1a411e3411d0f75cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_bc5de53295f54d4a8f4345680938be38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.67MB of 1.67MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f89f00ec7ba445e6beee4f6fcc1a28d7"
          }
        },
        "20de75cd911b45a4b0f0e7d9f5d61ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d4bdfc8b37649419c1ab44f62d747f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_887b052f5f5f4750b1f7d0dc51636fa9"
          }
        },
        "bc5de53295f54d4a8f4345680938be38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f89f00ec7ba445e6beee4f6fcc1a28d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d4bdfc8b37649419c1ab44f62d747f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "887b052f5f5f4750b1f7d0dc51636fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPmSsKaiKP8k",
        "outputId": "27138544-0d84-4405-a727-f44942e0fea3"
      },
      "source": [
        "!pip install googledrivedownloader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSP4y35bKRMN",
        "outputId": "171a6dad-e9ff-4bbb-f3ee-8073e61355a8"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import os\n",
        "\n",
        "if (not os.path.isdir('./data')):\n",
        "  gdd.download_file_from_google_drive(file_id='1nk52t3git04ZtlkvGIBKh4A4sbqwYibl',\n",
        "                                    dest_path='./dataset.zip',\n",
        "                                    unzip=True)\n",
        "  os.remove('./dataset.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1nk52t3git04ZtlkvGIBKh4A4sbqwYibl into ./dataset.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtQDLtUqKRXl"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "if (not os.path.isdir('./data')):\n",
        "  os.mkdir('./data')\n",
        "  shutil.move('./pp', './data/pp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1CShyDOKmEX",
        "outputId": "d550258e-2779-4f18-d07e-7b5adb6c52a4"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 10.7MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 37.2MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=51f82e768194c59c6e13d60aedf288f79f806b56dc49ad32f5f046eae696656e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=7895c6396aae551317a25c7357a824f4bfa386c262443abd19c8b22fab7b88f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: smmap, gitdb, GitPython, shortuuid, docker-pycreds, configparser, sentry-sdk, pathtools, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y7vemipKoZz",
        "outputId": "b51a081a-1de1-47d8-978d-4f185b3cc2fc"
      },
      "source": [
        "import wandb\n",
        "wandb.login(key=\"e3a44ac8e966c38d38fc008f8c96dd5c0d1760c3\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUskqFsMKDGc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb3JVWbnKDGn"
      },
      "source": [
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from os.path import isdir\n",
        "from os.path import join\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import shutil\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvpdOeqxKDGo"
      },
      "source": [
        "Misc functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JME5-H3fKDGp"
      },
      "source": [
        "def load_data(path):\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  onlyDirs = [f for f in listdir(path) if isdir(join(path, f))]\n",
        "\n",
        "  for category in onlyDirs:\n",
        "    pos_y = onlyDirs.index(category)\n",
        "    print(category, pos_y)\n",
        "    tempDirInput = join(path, category)\n",
        "    for f in listdir(tempDirInput):\n",
        "      inputPath = (join(tempDirInput, f))\n",
        "      if isfile(inputPath):\n",
        "        X.append(np.load(inputPath))\n",
        "        one_hot = np.zeros((len(onlyDirs)))\n",
        "        one_hot[pos_y] = 1\n",
        "        Y.append(one_hot)\n",
        "\n",
        "  return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSwTy3gNKDGp"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLuKJ1KBKDGq"
      },
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    \n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    \n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMmsDuXFKDGq"
      },
      "source": [
        "# About metrics.\n",
        "# Metric dictionary keys \n",
        "_loss            = 'Loss'\n",
        "_accuracy        = 'Accuracy'\n",
        "_accuracyClass   = 'Accuracy class'\n",
        "_confusionMatrix = 'Confusion matrix'\n",
        "_groundtruth     = 'Groundtruth'\n",
        "_predictions     = 'Predictions'\n",
        "# Get a clean dictionary for the metrics.\n",
        "def getMetricsDict(config):\n",
        "    return {\n",
        "        _loss            : torch.tensor(0., device=device),\n",
        "        _accuracy        : torch.tensor(0., device=device),\n",
        "        _accuracyClass   : torch.zeros(config[classesLen], device=device),\n",
        "        _confusionMatrix : torch.zeros((config[classesLen], config[classesLen]), dtype=torch.int, device=device),\n",
        "        _groundtruth     : torch.tensor([], device=device),\n",
        "        _predictions     : torch.tensor([], device=device)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1oq8YcmKDGs"
      },
      "source": [
        "# Pretty print the metrics dictionaries.\n",
        "def printMetricsDict(metricsResults, config):\n",
        "    # Build accuracy by class.\n",
        "    accuracyClassStr = ''\n",
        "    for i, _class in enumerate(config[classes]):\n",
        "        accuracyClassStr += '{}: {:2.2f}%'.format(_class, metricsResults[_accuracyClass][i] * 100)\n",
        "        accuracyClassStr += ', '\n",
        "    accuracyClassStr = accuracyClassStr[:-2]\n",
        "\n",
        "    print('Loss: {:.4f}, Accuracy: {:2.2f}% ({})'.format(metricsResults[_loss], metricsResults[_accuracy] * 100, accuracyClassStr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chudw12DKDGt"
      },
      "source": [
        "# Function used to update the dictionary of resulting metrics.\n",
        "def updateRunningMetrics(outputs, groundtruth, loss, batchAmount, metricsResults, config):\n",
        "    # Accumulate the loss.\n",
        "    metricsResults[_loss] += loss.cpu() / batchAmount\n",
        "    # Accumulate the confusion matrix.\n",
        "    confusionMatrix = getConfusionMatrix(outputs, groundtruth, config)\n",
        "    metricsResults[_confusionMatrix] += confusionMatrix\n",
        "    torch.cat((metricsResults[_groundtruth], groundtruth)) \n",
        "    metricsResults[_groundtruth] = torch.cat((metricsResults[_groundtruth], groundtruth)) \n",
        "    metricsResults[_predictions] = torch.cat((metricsResults[_predictions], outputs))\n",
        "\n",
        "# Function used to process the dictionary of resulting metrics (make final calculations).\n",
        "def processRunningMetrics(metricsResults):\n",
        "    # Get the total of samples processed by class.\n",
        "    classTotal = torch.sum(metricsResults[_confusionMatrix], 1)\n",
        "    # Get the total of samples correctly classified by class.\n",
        "    classCorrect = torch.diagonal(metricsResults[_confusionMatrix])\n",
        "\n",
        "    # Get the total accuracy, correct total samples / total samples.\n",
        "    metricsResults[_accuracy] = torch.sum(classCorrect) / torch.sum(classTotal)\n",
        "    # Get the total accuracy, by class.\n",
        "    metricsResults[_accuracyClass] = classCorrect / classTotal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6o-zR4kKDGu"
      },
      "source": [
        "# This functions process an metrics result dictionary for wandb. Is necessary to indicte\n",
        "#   the metrics origin, training or testing.\n",
        "def processMetricsWandb(metricsResults, config, training=False):\n",
        "    # Get the prefix to log on wandb, the keys must be different.\n",
        "    resultsType = 'training' if training else 'testing'\n",
        "\n",
        "    # All the wandb keys are based in the original metrics results keys.\n",
        "    lossKey = '{} ({})'.format(_loss, resultsType)\n",
        "    accuracyKey = '{} ({})'.format(_accuracy, resultsType)\n",
        "    accuracyClassKeys = ['{} accuracy ({})'.format(_class, resultsType) for _class in config[classes]]\n",
        "\n",
        "    confusionMatrixKey = '{} ({})'.format(_confusionMatrix, resultsType)\n",
        "    y_t = torch.argmax(metricsResults[_groundtruth],axis=1)\n",
        "    y_p = torch.argmax(metricsResults[_predictions], axis=1)\n",
        "    heatMap = wandb.plot.confusion_matrix(y_true=y_t.tolist(), preds=y_p.tolist(), class_names=config[classes], title=confusionMatrixKey)\n",
        "\n",
        "    # Make the dictionary for wandb and store the values.\n",
        "    wandbDict = {\n",
        "        lossKey             : metricsResults[_loss].item(),\n",
        "        accuracyKey         : metricsResults[_accuracy].item(),\n",
        "        confusionMatrixKey  : heatMap\n",
        "    }\n",
        "    for i in range(config[classesLen]):\n",
        "        wandbDict[accuracyClassKeys[i]] = metricsResults[_accuracyClass][i].item()\n",
        "\n",
        "    # Return, to log later.\n",
        "    return wandbDict\n",
        "    \n",
        "# Get the metrics dictionaries for wandb and log them.\n",
        "def logMetricsWandb(trainMetricsResults, testMetricsResults, config):\n",
        "    # Get both dictionaries for wandb.\n",
        "    wandbTrainDict = processMetricsWandb(trainMetricsResults, config, training=True)\n",
        "    wandbTestDict  = processMetricsWandb(testMetricsResults, config, training=False)\n",
        "\n",
        "    # Merge the dictionaries.\n",
        "    wandbDict = {**wandbTrainDict, **wandbTestDict}\n",
        "\n",
        "    # Log on wandb\n",
        "    wandb.log(wandbDict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EBXrOIaKDGv"
      },
      "source": [
        "# Calculate the confusion matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH6z1ON9KDGw"
      },
      "source": [
        "# Function to get the confusion matrix values.\n",
        "def getConfusionMatrix(outputs, groundtruth, config):\n",
        "    # Init the confusion matrix.\n",
        "    confusionMatrix = torch.zeros((config[classesLen], config[classesLen]), dtype=torch.int, device=device)\n",
        "\n",
        "    # Obtain the predictions (the greater number, because we use a one hot vector).\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Iterate the predictions.\n",
        "    for i in range(predicted.shape[0]):\n",
        "        # Add 1 based on the prediction done for a specific label.\n",
        "        \n",
        "        confusionMatrix[torch.argmax(groundtruth[i])][predicted[i]] += 1\n",
        "\n",
        "    return confusionMatrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3CkWfqzKDGx"
      },
      "source": [
        "Paths dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1yn1VZaKDGx"
      },
      "source": [
        "# Folder paths\n",
        "histOutputDir = 'data/pp/hist'\n",
        "\n",
        "run_ID = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvu1WYrdKDGy"
      },
      "source": [
        "# Load training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0COo97wKDGy",
        "outputId": "d0d6532b-ce43-42f0-b22f-767a126f290f"
      },
      "source": [
        "X_test, y_test = load_data(os.path.join(histOutputDir,'test'))\n",
        "X_train, y_train = load_data(os.path.join(histOutputDir,'train'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COVID 0\n",
            "Normal 1\n",
            "Lung_Opacity 2\n",
            "Viral_Pneumonia 3\n",
            "COVID 0\n",
            "Normal 1\n",
            "Lung_Opacity 2\n",
            "Viral_Pneumonia 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3YqRqCjKDGy"
      },
      "source": [
        "Global parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiA2l809KDGy"
      },
      "source": [
        "# Input size of the model.\n",
        "inputSize = 'inputSize'\n",
        "# Output size of the model.\n",
        "outputSize = 'outputSize'\n",
        "# Batch size.\n",
        "batchSize = 'batchSize'\n",
        "# Epochs amount.\n",
        "epochs = 'epochs'\n",
        "# Learning rate.\n",
        "learningRate = 'learningRate'\n",
        "#FC_Layer\n",
        "fc_size_1 = 'fc_size_1'\n",
        "fc_size_2 = 'fc_size_2'\n",
        "fc_size_3 = 'fc_size_3'\n",
        "fc_size_4 = 'fc_size_4'\n",
        "fc_size_5 = 'fc_size_5'\n",
        "fc_size_6 = 'fc_size_6'\n",
        "# Class names.\n",
        "classes = 'classes'\n",
        "# Number of classes to classify.\n",
        "classesLen = 'classesLen'\n",
        "name = 'name'\n",
        "\n",
        "upSampling = 'upSampling'\n",
        "\n",
        "#Experiment's config\n",
        "exp_1 = {\n",
        "    epochs        :   500,\n",
        "    learningRate :   0.0001,\n",
        "    batchSize    :   32,\n",
        "    inputSize     :   256,\n",
        "    fc_size_1     :   256,\n",
        "    fc_size_2     :   128,\n",
        "    fc_size_3     :   64,\n",
        "    fc_size_4     :   32,\n",
        "    fc_size_5     :   16,\n",
        "    fc_size_6     :   8,\n",
        "    outputSize      :   4,\n",
        "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
        "    classesLen     : 4,\n",
        "    upSampling     : False,\n",
        "    name           : 'WithoutUpsampling_32Batch'\n",
        "}\n",
        "exp_2 = {\n",
        "    epochs        :   500,\n",
        "    learningRate :   0.0001,\n",
        "    batchSize    :   32,\n",
        "    inputSize     :   256,\n",
        "    fc_size_1     :   256,\n",
        "    fc_size_2     :   128,\n",
        "    fc_size_3     :   64,\n",
        "    fc_size_4     :   32,\n",
        "    fc_size_5     :   16,\n",
        "    fc_size_6     :   8,\n",
        "    outputSize      :   4,\n",
        "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
        "    classesLen     : 4,\n",
        "    upSampling     : True,\n",
        "    name           : 'WithUpsampling_32Batch'\n",
        "}\n",
        "exp_3 = {\n",
        "    epochs        :   500,\n",
        "    learningRate :   0.0001,\n",
        "    batchSize    :   16,\n",
        "    inputSize     :   256,\n",
        "    fc_size_1     :   256,\n",
        "    fc_size_2     :   128,\n",
        "    fc_size_3     :   64,\n",
        "    fc_size_4     :   32,\n",
        "    fc_size_5     :   16,\n",
        "    fc_size_6     :   8,\n",
        "    outputSize      :   4,\n",
        "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
        "    classesLen     : 4,\n",
        "    upSampling     : False,\n",
        "    name           : 'WithoutUpsampling_16Batch'\n",
        "}\n",
        "exp_4 = {\n",
        "    epochs        :   500,\n",
        "    learningRate :   0.0001,\n",
        "    batchSize    :   16,\n",
        "    inputSize     :   256,\n",
        "    fc_size_1     :   256,\n",
        "    fc_size_2     :   128,\n",
        "    fc_size_3     :   64,\n",
        "    fc_size_4     :   32,\n",
        "    fc_size_5     :   16,\n",
        "    fc_size_6     :   8,\n",
        "    outputSize      :   4,\n",
        "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
        "    classesLen     : 4,\n",
        "    upSampling     : True,\n",
        "    name           : 'WithUpsampling_16Batch'\n",
        "}\n",
        "\n",
        "configs = [exp_1, exp_2, exp_3, exp_4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pl9R0uPKDGz"
      },
      "source": [
        "## Create a Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrTeO9fqKDGz"
      },
      "source": [
        "### UpSampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDiqzo6tKDG0"
      },
      "source": [
        "#This apply the upSampling to data.\n",
        "def upSamplingData(config):\n",
        "    if config[upSampling]:\n",
        "        dic_values = {}\n",
        "        weight = {}\n",
        "        for class_type in np.unique(y_train, axis=0):\n",
        "            dic_values[int(np.argmax(class_type))] = len(np.where((y_train == class_type).all(axis=1))[0])\n",
        "            weight[int(np.argmax(class_type))] = float(1.0/len(np.unique(y_train, axis=0)))/dic_values[int (np.argmax(class_type))]\n",
        "\n",
        "        print(\"dic_values\", dic_values)\n",
        "        print(\"weight\", weight)\n",
        "\n",
        "        samples_weight = np.array([weight[int(np.argmax(t))] for t in y_train])\n",
        "        samples_weight = torch.from_numpy(samples_weight)\n",
        "        sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
        "\n",
        "        return sampler\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjH-2UQtKDG0"
      },
      "source": [
        "#Sampler option is mutually exclusive with shuffle option.\n",
        "def setShuffle(config):\n",
        "    if config[upSampling]:\n",
        "        return False\n",
        "    return True\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_prsvyyKDG1"
      },
      "source": [
        "# Create a new dataloader according to the config JSON. \n",
        "def createDataLoaders(config):\n",
        "        tensor_x = torch.Tensor(X_train) \n",
        "        tensor_y = torch.Tensor(y_train)\n",
        "        my_dataset = TensorDataset(tensor_x,tensor_y) \n",
        "        trainingSetLoader = DataLoader(my_dataset,\n",
        "                shuffle=setShuffle(config),\n",
        "                sampler= upSamplingData(config),\n",
        "                batch_size=config[batchSize]) \n",
        "\n",
        "        tensor_x_test = torch.Tensor(X_test) \n",
        "        tensor_y_test = torch.Tensor(y_test)\n",
        "        my_dataset_test = TensorDataset(tensor_x_test,tensor_y_test) \n",
        "        testSetLoader = DataLoader(my_dataset_test,\n",
        "                shuffle=True,\n",
        "                batch_size=config[batchSize]) \n",
        "        return (trainingSetLoader, testSetLoader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwrpUpKZKDG1"
      },
      "source": [
        "Check CUDA is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqZHl7ugKDG1",
        "outputId": "ccea3928-853f-49b0-dad5-636b1eb8294e"
      },
      "source": [
        "#Check for CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvaEdfzQKDG3"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZkdMPAxKDG3"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, config):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, config[fc_size_1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config[fc_size_1], config[fc_size_2]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config[fc_size_2], config[fc_size_3]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config[fc_size_3], config[fc_size_4]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(config[fc_size_4], config[fc_size_5]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config[fc_size_5], config[fc_size_6]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config[fc_size_6], output_dim),\n",
        "            nn.Softmax(dim=1)\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbeJ2IcbKDG4"
      },
      "source": [
        "### Training method.\n",
        "This method takes care of a single training pass. Another function call this one multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CL7b2uTKDG4"
      },
      "source": [
        "def trainEpoch(dataloader, model, criterion, optimizer, config):\n",
        "    # Metrics for training.\n",
        "    metricsResults = getMetricsDict(config)\n",
        "\n",
        "    # Enable the grad, for training.\n",
        "    with torch.set_grad_enabled(True):\n",
        "\n",
        "        # Indicate that the model is going to be trained.\n",
        "        model.train()\n",
        "\n",
        "        # Loader len, for metrics calculation.\n",
        "        loaderLen = len(dataloader)\n",
        "\n",
        "        # Iterate the batches for training.\n",
        "        for batch in dataloader:\n",
        "            # Train the model.\n",
        "            # Get the inputs and labels, and move them to the selected device.\n",
        "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "            # Zero the gradient parameters.\n",
        "            optimizer.zero_grad()\n",
        "            # Get the predictions.\n",
        "            outputs = model(inputs)\n",
        "            # Calculate the error.\n",
        "            labels_argmax = torch.empty(labels.shape[0], dtype=torch.long, device=device)\n",
        "            labels_argmax = torch.argmax(labels, dim=1)\n",
        "            loss = criterion(outputs, labels_argmax)\n",
        "            # Calculates the derivatives of the parameters that have a gradient.\n",
        "            loss.backward()\n",
        "            # Update the parameters based on the computer gradient.\n",
        "            optimizer.step()\n",
        "            # Metrics for the training set.\n",
        "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults, config)\n",
        "\n",
        "    return metricsResults"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6DfObBUKDG4"
      },
      "source": [
        "### Evaluation method.\n",
        "This method evaluates the model for a specified dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atZ7wevGKDG4"
      },
      "source": [
        "def evaluate(dataloader, model, criterion, config):\n",
        "    # Metrics for testing.\n",
        "    metricsResults = getMetricsDict(config)\n",
        "\n",
        "    # Enable the grad, for training.\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # Indicate that the model is going to be evaluated.\n",
        "        model.eval()\n",
        "\n",
        "        # Loader len, for metrics calculation.\n",
        "        loaderLen = len(dataloader)\n",
        "\n",
        "        # Iterate the batches for testing.\n",
        "        for batch in dataloader:\n",
        "            # Test the model.\n",
        "            # Get the inputs and labels, and move them to the selected device.\n",
        "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "            # Get the predictions.\n",
        "            outputs = model(inputs)\n",
        "            # Calculate the error.\n",
        "            labels_argmax = torch.empty(labels.shape[0], dtype=torch.long, device=device)\n",
        "            labels_argmax = torch.argmax(labels, dim=1)\n",
        "            loss = criterion(outputs, labels_argmax)\n",
        "            # Metrics for the testing set.\n",
        "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults, config)\n",
        "\n",
        "    return metricsResults"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hb0pWeJKDG5"
      },
      "source": [
        "### Trainining and evaluate method.\n",
        "For the specific purpose of this project, in each epoch we evaluate metrics for each data set (training and testing) in each epoch, this method simplifies the process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boQmUoqJKDG5"
      },
      "source": [
        "def trainAndEvaluate(trainloader, testloader, model, criterion, optimizer, config):\n",
        "    startTimeTotal = time.time()\n",
        "    print(\"Running epochs: \" + str(config[epochs]))\n",
        "    for epoch in range(1, config[epochs] + 1):\n",
        "        \n",
        "        # Train the model.\n",
        "        trainMetricsResults = trainEpoch(trainloader, model, criterion, optimizer, config)\n",
        "        processRunningMetrics(trainMetricsResults)\n",
        "\n",
        "        # Evaluate the model.\n",
        "        testMetricsResults = evaluate(testloader, model, criterion, config)\n",
        "        processRunningMetrics(testMetricsResults)\n",
        "\n",
        "        # Log on wandb\n",
        "        logMetricsWandb(trainMetricsResults, testMetricsResults, config)\n",
        "\n",
        "        # Print the results.\n",
        "        if epoch %20 == 0:\n",
        "            print('**', '[', 'Epoch ', epoch, ']', '*' * 48, sep='')\n",
        "            print('\\tTraining results:', end=' ')\n",
        "            printMetricsDict(trainMetricsResults, config)\n",
        "            print('\\t Testing results:', end=' ')\n",
        "            printMetricsDict(testMetricsResults, config)\n",
        "        \n",
        "    # Print time\n",
        "    print('Epochs terminados')\n",
        "    print(\"--- %s seconds ---\" % (time.time() - startTimeTotal))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFsn24qAKDG6"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f99b3876f6c4cedb0e25acddb6d54a1",
            "2132a0a49baf436ab7d675b0b24e5104",
            "7cd1dfdab9c34ad1a411e3411d0f75cf",
            "20de75cd911b45a4b0f0e7d9f5d61ab0",
            "bc5de53295f54d4a8f4345680938be38",
            "f89f00ec7ba445e6beee4f6fcc1a28d7",
            "8d4bdfc8b37649419c1ab44f62d747f7",
            "887b052f5f5f4750b1f7d0dc51636fa9"
          ]
        },
        "id": "cSsgfZCgKDG6",
        "outputId": "20b38bb4-b890-4cbc-d4e3-4df0df2b715c"
      },
      "source": [
        "#Create the model, optimizer and criterion\n",
        "run_ID += 1\n",
        "for runConfig in configs:\n",
        "    print(\"Running\")\n",
        "    print(runConfig[name])\n",
        "    trainloader, testloader = createDataLoaders(runConfig)\n",
        "    \n",
        "    model = MLP(runConfig[inputSize], runConfig[outputSize], runConfig)\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(),lr=runConfig[learningRate])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    #Init WandB\n",
        "    nameRun = runConfig[name] + str(run_ID)\n",
        "    run = wandb.init(project='MLP', entity='tecai', config=runConfig,\n",
        "                            name=nameRun)\n",
        "    wandb.watch(model)\n",
        "    #Train and evaluate the model\n",
        "    trainAndEvaluate(trainloader, testloader, model, criterion, optimizer, runConfig)\n",
        "    #Finish WandB\n",
        "    run.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running\n",
            "WithUpsampling_16Batch\n",
            "dic_values {3: 1087, 2: 4806, 1: 8150, 0: 2889}\n",
            "weight {3: 0.00022999080036798528, 2: 5.201831044527674e-05, 1: 3.067484662576687e-05, 0: 8.653513326410523e-05}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstevenpach10\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">WithUpsampling_16Batch1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/tecai/MLP\" target=\"_blank\">https://wandb.ai/tecai/MLP</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/tecai/MLP/runs/1s5r545r\" target=\"_blank\">https://wandb.ai/tecai/MLP/runs/1s5r545r</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210511_151549-1s5r545r</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running epochs: 500\n",
            "**[Epoch 20]************************************************\n",
            "\tTraining results: Loss: 1.2304, Accuracy: 48.06% (COVID: 40.91%, Lung Opacity: 22.97%, Normal: 50.78%, Viral Pneumonia: 77.11%)\n",
            "\t Testing results: Loss: 1.3087, Accuracy: 42.22% (COVID: 45.53%, Lung Opacity: 44.37%, Normal: 30.02%, Viral Pneumonia: 72.87%)\n",
            "**[Epoch 40]************************************************\n",
            "\tTraining results: Loss: 1.1641, Accuracy: 56.41% (COVID: 59.90%, Lung Opacity: 39.92%, Normal: 45.23%, Viral Pneumonia: 81.41%)\n",
            "\t Testing results: Loss: 1.2370, Accuracy: 50.34% (COVID: 57.36%, Lung Opacity: 49.36%, Normal: 43.20%, Viral Pneumonia: 71.71%)\n",
            "**[Epoch 60]************************************************\n",
            "\tTraining results: Loss: 1.1181, Accuracy: 62.31% (COVID: 60.85%, Lung Opacity: 48.39%, Normal: 55.01%, Viral Pneumonia: 84.87%)\n",
            "\t Testing results: Loss: 1.1712, Accuracy: 56.44% (COVID: 63.14%, Lung Opacity: 50.29%, Normal: 59.29%, Viral Pneumonia: 72.87%)\n",
            "**[Epoch 80]************************************************\n",
            "\tTraining results: Loss: 1.0861, Accuracy: 65.34% (COVID: 67.77%, Lung Opacity: 50.67%, Normal: 58.21%, Viral Pneumonia: 84.60%)\n",
            "\t Testing results: Loss: 1.1570, Accuracy: 57.55% (COVID: 66.16%, Lung Opacity: 51.37%, Normal: 58.29%, Viral Pneumonia: 78.68%)\n",
            "**[Epoch 100]************************************************\n",
            "\tTraining results: Loss: 1.0613, Accuracy: 67.93% (COVID: 68.72%, Lung Opacity: 51.71%, Normal: 65.08%, Viral Pneumonia: 86.29%)\n",
            "\t Testing results: Loss: 1.1296, Accuracy: 60.43% (COVID: 71.25%, Lung Opacity: 54.85%, Normal: 59.45%, Viral Pneumonia: 78.68%)\n",
            "**[Epoch 120]************************************************\n",
            "\tTraining results: Loss: 1.0436, Accuracy: 69.57% (COVID: 70.85%, Lung Opacity: 52.59%, Normal: 67.26%, Viral Pneumonia: 87.64%)\n",
            "\t Testing results: Loss: 1.1004, Accuracy: 63.86% (COVID: 69.60%, Lung Opacity: 58.62%, Normal: 66.00%, Viral Pneumonia: 79.07%)\n",
            "**[Epoch 140]************************************************\n",
            "\tTraining results: Loss: 1.0189, Accuracy: 72.26% (COVID: 73.07%, Lung Opacity: 57.25%, Normal: 70.35%, Viral Pneumonia: 88.05%)\n",
            "\t Testing results: Loss: 1.0774, Accuracy: 66.22% (COVID: 74.42%, Lung Opacity: 59.99%, Normal: 69.24%, Viral Pneumonia: 78.29%)\n",
            "**[Epoch 160]************************************************\n",
            "\tTraining results: Loss: 1.0089, Accuracy: 73.35% (COVID: 74.43%, Lung Opacity: 58.71%, Normal: 70.15%, Viral Pneumonia: 89.96%)\n",
            "\t Testing results: Loss: 1.0837, Accuracy: 65.75% (COVID: 74.55%, Lung Opacity: 59.84%, Normal: 67.00%, Viral Pneumonia: 81.78%)\n",
            "**[Epoch 180]************************************************\n",
            "\tTraining results: Loss: 0.9945, Accuracy: 74.81% (COVID: 74.80%, Lung Opacity: 62.27%, Normal: 71.11%, Viral Pneumonia: 90.89%)\n",
            "\t Testing results: Loss: 1.0669, Accuracy: 67.35% (COVID: 75.93%, Lung Opacity: 66.99%, Normal: 62.60%, Viral Pneumonia: 68.22%)\n",
            "**[Epoch 200]************************************************\n",
            "\tTraining results: Loss: 0.9905, Accuracy: 75.17% (COVID: 77.34%, Lung Opacity: 63.03%, Normal: 70.34%, Viral Pneumonia: 90.11%)\n",
            "\t Testing results: Loss: 1.0580, Accuracy: 68.37% (COVID: 75.10%, Lung Opacity: 64.50%, Normal: 67.99%, Viral Pneumonia: 81.78%)\n",
            "**[Epoch 220]************************************************\n",
            "\tTraining results: Loss: 0.9873, Accuracy: 75.41% (COVID: 77.30%, Lung Opacity: 63.32%, Normal: 71.24%, Viral Pneumonia: 89.56%)\n",
            "\t Testing results: Loss: 1.0519, Accuracy: 68.96% (COVID: 77.58%, Lung Opacity: 68.36%, Normal: 63.02%, Viral Pneumonia: 77.13%)\n",
            "**[Epoch 240]************************************************\n",
            "\tTraining results: Loss: 0.9792, Accuracy: 76.28% (COVID: 75.97%, Lung Opacity: 66.05%, Normal: 73.85%, Viral Pneumonia: 89.08%)\n",
            "\t Testing results: Loss: 1.0388, Accuracy: 70.07% (COVID: 73.04%, Lung Opacity: 67.24%, Normal: 71.64%, Viral Pneumonia: 76.74%)\n",
            "**[Epoch 260]************************************************\n",
            "\tTraining results: Loss: 0.9583, Accuracy: 78.42% (COVID: 81.07%, Lung Opacity: 69.62%, Normal: 72.18%, Viral Pneumonia: 90.92%)\n",
            "\t Testing results: Loss: 1.0583, Accuracy: 68.34% (COVID: 82.39%, Lung Opacity: 64.25%, Normal: 64.01%, Viral Pneumonia: 81.40%)\n",
            "**[Epoch 280]************************************************\n",
            "\tTraining results: Loss: 0.9564, Accuracy: 78.61% (COVID: 80.36%, Lung Opacity: 67.88%, Normal: 72.88%, Viral Pneumonia: 92.98%)\n",
            "\t Testing results: Loss: 1.0399, Accuracy: 70.16% (COVID: 80.06%, Lung Opacity: 66.50%, Normal: 67.16%, Viral Pneumonia: 85.27%)\n",
            "**[Epoch 300]************************************************\n",
            "\tTraining results: Loss: 0.9479, Accuracy: 79.50% (COVID: 83.01%, Lung Opacity: 70.91%, Normal: 72.58%, Viral Pneumonia: 91.45%)\n",
            "\t Testing results: Loss: 1.0221, Accuracy: 71.93% (COVID: 81.02%, Lung Opacity: 68.95%, Normal: 69.65%, Viral Pneumonia: 80.62%)\n",
            "**[Epoch 320]************************************************\n",
            "\tTraining results: Loss: 0.9444, Accuracy: 79.80% (COVID: 82.29%, Lung Opacity: 70.14%, Normal: 74.77%, Viral Pneumonia: 91.94%)\n",
            "\t Testing results: Loss: 1.0256, Accuracy: 71.75% (COVID: 77.72%, Lung Opacity: 69.39%, Normal: 69.57%, Viral Pneumonia: 83.72%)\n",
            "**[Epoch 340]************************************************\n",
            "\tTraining results: Loss: 0.9390, Accuracy: 80.39% (COVID: 82.97%, Lung Opacity: 72.00%, Normal: 74.00%, Viral Pneumonia: 92.86%)\n",
            "\t Testing results: Loss: 1.0208, Accuracy: 72.08% (COVID: 81.02%, Lung Opacity: 71.40%, Normal: 64.84%, Viral Pneumonia: 86.05%)\n",
            "**[Epoch 360]************************************************\n",
            "\tTraining results: Loss: 0.9298, Accuracy: 81.31% (COVID: 84.61%, Lung Opacity: 74.09%, Normal: 74.13%, Viral Pneumonia: 92.88%)\n",
            "\t Testing results: Loss: 1.0130, Accuracy: 72.88% (COVID: 81.29%, Lung Opacity: 71.55%, Normal: 67.99%, Viral Pneumonia: 82.56%)\n",
            "**[Epoch 380]************************************************\n",
            "\tTraining results: Loss: 0.9282, Accuracy: 81.46% (COVID: 84.69%, Lung Opacity: 74.43%, Normal: 74.63%, Viral Pneumonia: 92.12%)\n",
            "\t Testing results: Loss: 1.0187, Accuracy: 72.24% (COVID: 77.72%, Lung Opacity: 69.88%, Normal: 69.98%, Viral Pneumonia: 86.05%)\n",
            "**[Epoch 400]************************************************\n",
            "\tTraining results: Loss: 0.9274, Accuracy: 81.51% (COVID: 85.28%, Lung Opacity: 74.03%, Normal: 74.84%, Viral Pneumonia: 92.36%)\n",
            "\t Testing results: Loss: 1.0459, Accuracy: 69.86% (COVID: 78.13%, Lung Opacity: 64.05%, Normal: 71.06%, Viral Pneumonia: 86.82%)\n",
            "**[Epoch 420]************************************************\n",
            "\tTraining results: Loss: 0.9309, Accuracy: 81.17% (COVID: 84.75%, Lung Opacity: 76.34%, Normal: 73.29%, Viral Pneumonia: 90.21%)\n",
            "\t Testing results: Loss: 1.0010, Accuracy: 73.94% (COVID: 81.57%, Lung Opacity: 72.58%, Normal: 70.15%, Viral Pneumonia: 81.01%)\n",
            "**[Epoch 440]************************************************\n",
            "\tTraining results: Loss: 0.9282, Accuracy: 81.45% (COVID: 84.06%, Lung Opacity: 75.44%, Normal: 74.48%, Viral Pneumonia: 91.83%)\n",
            "\t Testing results: Loss: 0.9843, Accuracy: 75.83% (COVID: 79.09%, Lung Opacity: 78.94%, Normal: 68.24%, Viral Pneumonia: 77.52%)\n",
            "**[Epoch 460]************************************************\n",
            "\tTraining results: Loss: 0.9281, Accuracy: 81.46% (COVID: 83.96%, Lung Opacity: 77.12%, Normal: 74.61%, Viral Pneumonia: 90.21%)\n",
            "\t Testing results: Loss: 1.0092, Accuracy: 73.38% (COVID: 81.43%, Lung Opacity: 72.67%, Normal: 67.50%, Viral Pneumonia: 83.72%)\n",
            "**[Epoch 480]************************************************\n",
            "\tTraining results: Loss: 0.9163, Accuracy: 82.62% (COVID: 86.70%, Lung Opacity: 78.69%, Normal: 75.15%, Viral Pneumonia: 89.91%)\n",
            "\t Testing results: Loss: 1.0095, Accuracy: 73.33% (COVID: 81.98%, Lung Opacity: 70.71%, Normal: 70.81%, Viral Pneumonia: 81.40%)\n",
            "**[Epoch 500]************************************************\n",
            "\tTraining results: Loss: 0.9219, Accuracy: 82.09% (COVID: 85.03%, Lung Opacity: 78.57%, Normal: 76.28%, Viral Pneumonia: 88.47%)\n",
            "\t Testing results: Loss: 0.9790, Accuracy: 76.38% (COVID: 82.67%, Lung Opacity: 82.27%, Normal: 63.02%, Viral Pneumonia: 74.42%)\n",
            "Epochs terminados\n",
            "--- 6494.068916320801 seconds ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 188<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f99b3876f6c4cedb0e25acddb6d54a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 1.64MB of 1.64MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210511_151549-1s5r545r/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210511_151549-1s5r545r/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Loss (training)</td><td>0.92185</td></tr><tr><td>Accuracy (training)</td><td>0.82093</td></tr><tr><td>COVID accuracy (training)</td><td>0.85031</td></tr><tr><td>Lung Opacity accuracy (training)</td><td>0.78571</td></tr><tr><td>Normal accuracy (training)</td><td>0.76277</td></tr><tr><td>Viral Pneumonia accuracy (training)</td><td>0.88468</td></tr><tr><td>Loss (testing)</td><td>0.97895</td></tr><tr><td>Accuracy (testing)</td><td>0.76376</td></tr><tr><td>COVID accuracy (testing)</td><td>0.82669</td></tr><tr><td>Lung Opacity accuracy (testing)</td><td>0.82272</td></tr><tr><td>Normal accuracy (testing)</td><td>0.63018</td></tr><tr><td>Viral Pneumonia accuracy (testing)</td><td>0.74419</td></tr><tr><td>_runtime</td><td>6493</td></tr><tr><td>_timestamp</td><td>1620752642</td></tr><tr><td>_step</td><td>499</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Loss (training)</td><td>█▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Accuracy (training)</td><td>▁▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>COVID accuracy (training)</td><td>▄▁▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>Lung Opacity accuracy (training)</td><td>▁▄▅▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███████</td></tr><tr><td>Normal accuracy (training)</td><td>▁▃▂▄▅▆▆▆▆▆▇▇▇▇▇▇█▇██████████████████████</td></tr><tr><td>Viral Pneumonia accuracy (training)</td><td>▁▁▂▃▄▅▅▅▅▆▇▆▆▇▇▇▇▇▇▇▇██████████▇█▇▇▇▇█▇█</td></tr><tr><td>Loss (testing)</td><td>█▇▆▆▅▄▄▄▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁</td></tr><tr><td>Accuracy (testing)</td><td>▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>COVID accuracy (testing)</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███▇▇█▇█▇████▇</td></tr><tr><td>Lung Opacity accuracy (testing)</td><td>▁▆▆▅▅▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█</td></tr><tr><td>Normal accuracy (testing)</td><td>█▁▁▄▆▆▆▆▆▆▇▇▇▇▆▇▇▆▇▇█▇▇▇▇▇▇▆▇▇█▇█▇▇▇▇▆▇▇</td></tr><tr><td>Viral Pneumonia accuracy (testing)</td><td>▄▂▃▃▁▃▅▅▅▆▅▅▆▅▂▇▇▅▆▇▇██▇█▇▇█▇▇▇▇▆▆▆▄▇▆▆▄</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1001 media file(s), 1000 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">WithUpsampling_16Batch1</strong>: <a href=\"https://wandb.ai/tecai/MLP/runs/1s5r545r\" target=\"_blank\">https://wandb.ai/tecai/MLP/runs/1s5r545r</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLP2UYw3KDG7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}